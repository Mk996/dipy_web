{"parents": [{"link": "../../documentation/", "title": "Documentation"}, {"link": "../", "title": "API Reference"}], "prev": {"link": "../dipy.io/", "title": "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">io</span></code>"}, "next": {"link": "../dipy.reconst/", "title": "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">reconst</span></code>"}, "title": "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">nn</span></code>", "meta": {}, "body": "<section id=\"module-dipy.nn\">\n<span id=\"nn\"></span><h1><code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">nn</span></code><a class=\"headerlink\" href=\"#module-dipy.nn\" title=\"Permalink to this headline\">\u00b6</a></h1>\n<table class=\"longtable docutils align-default\">\n<colgroup>\n<col style=\"width: 10%\" />\n<col style=\"width: 90%\" />\n</colgroup>\n<tbody>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.bench\" title=\"dipy.nn.bench\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">bench</span></code></a>([label,\u00a0verbose,\u00a0extra_argv])</p></td>\n<td><p>Run benchmarks for module using nose.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.test\" title=\"dipy.nn.test\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">test</span></code></a>([label,\u00a0verbose,\u00a0extra_argv,\u00a0doctests,\u00a0...])</p></td>\n<td><p>Run tests for module using nose.</p></td>\n</tr>\n</tbody>\n</table>\n<section id=\"module-dipy.nn.histo_resdnn\">\n<span id=\"module-nn-histo-resdnn\"></span><h2>Module: <code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">nn.histo_resdnn</span></code><a class=\"headerlink\" href=\"#module-dipy.nn.histo_resdnn\" title=\"Permalink to this headline\">\u00b6</a></h2>\n<p>Class and helper functions for fitting the Histological ResDNN model.</p>\n<table class=\"longtable docutils align-default\">\n<colgroup>\n<col style=\"width: 10%\" />\n<col style=\"width: 90%\" />\n</colgroup>\n<tbody>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Add\" title=\"dipy.nn.histo_resdnn.Add\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">Add</span></code></a>(*args,\u00a0**kwargs)</p></td>\n<td><p>Layer that adds a list of inputs.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Dense\" title=\"dipy.nn.histo_resdnn.Dense\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">Dense</span></code></a>(*args,\u00a0**kwargs)</p></td>\n<td><p>Just your regular densely-connected NN layer.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.HemiSphere\" title=\"dipy.nn.histo_resdnn.HemiSphere\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">HemiSphere</span></code></a>([x,\u00a0y,\u00a0z,\u00a0theta,\u00a0phi,\u00a0xyz,\u00a0...])</p></td>\n<td><p>Points on the unit sphere.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.HistoResDNN\" title=\"dipy.nn.histo_resdnn.HistoResDNN\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">HistoResDNN</span></code></a>([sh_order,\u00a0basis_type,\u00a0verbose])</p></td>\n<td><p>This class is intended for the ResDNN Histology Network model.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model\" title=\"dipy.nn.histo_resdnn.Model\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">Model</span></code></a>(*args,\u00a0**kwargs)</p></td>\n<td><p><cite>Model</cite> groups layers into an object with training and inference features.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Version\" title=\"dipy.nn.histo_resdnn.Version\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">Version</span></code></a>(version)</p></td>\n<td><p><dl class=\"field-list simple\">\n<dt class=\"field-odd\">Attributes</dt>\n<dd class=\"field-odd\"><p></p></dd>\n</dl>\n</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Input\" title=\"dipy.nn.histo_resdnn.Input\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">Input</span></code></a>([shape,\u00a0batch_size,\u00a0name,\u00a0dtype,\u00a0...])</p></td>\n<td><p><cite>Input()</cite> is used to instantiate a Keras tensor.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.doctest_skip_parser\" title=\"dipy.nn.histo_resdnn.doctest_skip_parser\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">doctest_skip_parser</span></code></a>(func)</p></td>\n<td><p>Decorator replaces custom skip test markup in doctests.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.get_bval_indices\" title=\"dipy.nn.histo_resdnn.get_bval_indices\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">get_bval_indices</span></code></a>(bvals,\u00a0bval[,\u00a0tol])</p></td>\n<td><p>Get indices where the b-value is <cite>bval</cite></p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.get_fnames\" title=\"dipy.nn.histo_resdnn.get_fnames\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">get_fnames</span></code></a>([name])</p></td>\n<td><p>Provide full paths to example or test datasets.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.get_sphere\" title=\"dipy.nn.histo_resdnn.get_sphere\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">get_sphere</span></code></a>([name])</p></td>\n<td><p>provide triangulated spheres</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.optional_package\" title=\"dipy.nn.histo_resdnn.optional_package\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">optional_package</span></code></a>(name[,\u00a0trip_msg])</p></td>\n<td><p>Return package-like thing and module setup for package <cite>name</cite></p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.set_logger_level\" title=\"dipy.nn.histo_resdnn.set_logger_level\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">set_logger_level</span></code></a>(log_level)</p></td>\n<td><p>Change the logger of the HistoResDNN to one on the following: DEBUG, INFO, WARNING, CRITICAL, ERROR</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.sf_to_sh\" title=\"dipy.nn.histo_resdnn.sf_to_sh\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">sf_to_sh</span></code></a>(sf,\u00a0sphere[,\u00a0sh_order,\u00a0basis_type,\u00a0...])</p></td>\n<td><p>Spherical function to spherical harmonics (SH).</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.sh_to_sf\" title=\"dipy.nn.histo_resdnn.sh_to_sf\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">sh_to_sf</span></code></a>(sh,\u00a0sphere[,\u00a0sh_order,\u00a0basis_type,\u00a0...])</p></td>\n<td><p>Spherical harmonics (SH) to spherical function (SF).</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.sph_harm_ind_list\" title=\"dipy.nn.histo_resdnn.sph_harm_ind_list\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">sph_harm_ind_list</span></code></a>(sh_order[,\u00a0full_basis])</p></td>\n<td><p>Returns the degree (<code class=\"docutils literal notranslate\"><span class=\"pre\">m</span></code>) and order (<code class=\"docutils literal notranslate\"><span class=\"pre\">n</span></code>) of all the symmetric spherical harmonics of degree less then or equal to <code class=\"docutils literal notranslate\"><span class=\"pre\">sh_order</span></code>.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.unique_bvals_magnitude\" title=\"dipy.nn.histo_resdnn.unique_bvals_magnitude\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">unique_bvals_magnitude</span></code></a>(bvals[,\u00a0bmag,\u00a0rbvals])</p></td>\n<td><p>This function gives the unique rounded b-values of the data</p></td>\n</tr>\n</tbody>\n</table>\n</section>\n<section id=\"module-dipy.nn.model\">\n<span id=\"module-nn-model\"></span><h2>Module: <code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">nn.model</span></code><a class=\"headerlink\" href=\"#module-dipy.nn.model\" title=\"Permalink to this headline\">\u00b6</a></h2>\n<table class=\"longtable docutils align-default\">\n<colgroup>\n<col style=\"width: 10%\" />\n<col style=\"width: 90%\" />\n</colgroup>\n<tbody>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.model.MultipleLayerPercepton\" title=\"dipy.nn.model.MultipleLayerPercepton\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">MultipleLayerPercepton</span></code></a>([input_shape,\u00a0...])</p></td>\n<td><p><p class=\"rubric\">Methods</p>\n</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.model.SingleLayerPerceptron\" title=\"dipy.nn.model.SingleLayerPerceptron\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">SingleLayerPerceptron</span></code></a>([input_shape,\u00a0...])</p></td>\n<td><p><p class=\"rubric\">Methods</p>\n</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.model.Version\" title=\"dipy.nn.model.Version\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">Version</span></code></a>(version)</p></td>\n<td><p><dl class=\"field-list simple\">\n<dt class=\"field-odd\">Attributes</dt>\n<dd class=\"field-odd\"><p></p></dd>\n</dl>\n</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.model.optional_package\" title=\"dipy.nn.model.optional_package\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">optional_package</span></code></a>(name[,\u00a0trip_msg])</p></td>\n<td><p>Return package-like thing and module setup for package <cite>name</cite></p></td>\n</tr>\n</tbody>\n</table>\n<section id=\"bench\">\n<h3>bench<a class=\"headerlink\" href=\"#bench\" title=\"Permalink to this headline\">\u00b6</a></h3>\n<dl class=\"py function\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.bench\">\n<span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.</span></span><span class=\"sig-name descname\"><span class=\"pre\">bench</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">label</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'fast'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">verbose</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">1</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">extra_argv</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.bench\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Run benchmarks for module using nose.</p>\n<dl class=\"field-list simple\">\n<dt class=\"field-odd\">Parameters</dt>\n<dd class=\"field-odd\"><dl class=\"simple\">\n<dt><strong>label</strong><span class=\"classifier\">{\u2018fast\u2019, \u2018full\u2019, \u2018\u2019, attribute identifier}, optional</span></dt><dd><p>Identifies the benchmarks to run. This can be a string to pass to\nthe nosetests executable with the \u2018-A\u2019 option, or one of several\nspecial values.  Special values are:</p>\n<ul class=\"simple\">\n<li><p>\u2018fast\u2019 - the default - which corresponds to the <code class=\"docutils literal notranslate\"><span class=\"pre\">nosetests</span> <span class=\"pre\">-A</span></code>\noption of \u2018not slow\u2019.</p></li>\n<li><p>\u2018full\u2019 - fast (as above) and slow benchmarks as in the\n\u2018no -A\u2019 option to nosetests - this is the same as \u2018\u2019.</p></li>\n<li><p>None or \u2018\u2019 - run all tests.</p></li>\n<li><p>attribute_identifier - string passed directly to nosetests as \u2018-A\u2019.</p></li>\n</ul>\n</dd>\n<dt><strong>verbose</strong><span class=\"classifier\">int, optional</span></dt><dd><p>Verbosity value for benchmark outputs, in the range 1-10. Default is 1.</p>\n</dd>\n<dt><strong>extra_argv</strong><span class=\"classifier\">list, optional</span></dt><dd><p>List with any extra arguments to pass to nosetests.</p>\n</dd>\n</dl>\n</dd>\n<dt class=\"field-even\">Returns</dt>\n<dd class=\"field-even\"><dl class=\"simple\">\n<dt><strong>success</strong><span class=\"classifier\">bool</span></dt><dd><p>Returns True if running the benchmarks works, False if an error\noccurred.</p>\n</dd>\n</dl>\n</dd>\n</dl>\n<p class=\"rubric\">Notes</p>\n<p>Benchmarks are like tests, but have names starting with \u201cbench\u201d instead\nof \u201ctest\u201d, and can be found under the \u201cbenchmarks\u201d sub-directory of the\nmodule.</p>\n<p>Each NumPy module exposes <cite>bench</cite> in its namespace to run all benchmarks\nfor it.</p>\n<p class=\"rubric\">Examples</p>\n<div class=\"doctest highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">success</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">lib</span><span class=\"o\">.</span><span class=\"n\">bench</span><span class=\"p\">()</span> \n<span class=\"go\">Running benchmarks for numpy.lib</span>\n<span class=\"gp\">...</span>\n<span class=\"go\">using 562341 items:</span>\n<span class=\"go\">unique:</span>\n<span class=\"go\">0.11</span>\n<span class=\"go\">unique1d:</span>\n<span class=\"go\">0.11</span>\n<span class=\"go\">ratio: 1.0</span>\n<span class=\"go\">nUnique: 56230 == 56230</span>\n<span class=\"gp\">...</span>\n<span class=\"go\">OK</span>\n</pre></div>\n</div>\n<div class=\"doctest highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">success</span> \n<span class=\"go\">True</span>\n</pre></div>\n</div>\n</dd></dl>\n\n</section>\n<section id=\"test\">\n<h3>test<a class=\"headerlink\" href=\"#test\" title=\"Permalink to this headline\">\u00b6</a></h3>\n<dl class=\"py function\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.test\">\n<span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.</span></span><span class=\"sig-name descname\"><span class=\"pre\">test</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">label</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'fast'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">verbose</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">1</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">extra_argv</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">doctests</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">coverage</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">raise_warnings</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">timer</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.test\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Run tests for module using nose.</p>\n<dl class=\"field-list simple\">\n<dt class=\"field-odd\">Parameters</dt>\n<dd class=\"field-odd\"><dl class=\"simple\">\n<dt><strong>label</strong><span class=\"classifier\">{\u2018fast\u2019, \u2018full\u2019, \u2018\u2019, attribute identifier}, optional</span></dt><dd><p>Identifies the tests to run. This can be a string to pass to\nthe nosetests executable with the \u2018-A\u2019 option, or one of several\nspecial values.  Special values are:</p>\n<ul class=\"simple\">\n<li><p>\u2018fast\u2019 - the default - which corresponds to the <code class=\"docutils literal notranslate\"><span class=\"pre\">nosetests</span> <span class=\"pre\">-A</span></code>\noption of \u2018not slow\u2019.</p></li>\n<li><p>\u2018full\u2019 - fast (as above) and slow tests as in the\n\u2018no -A\u2019 option to nosetests - this is the same as \u2018\u2019.</p></li>\n<li><p>None or \u2018\u2019 - run all tests.</p></li>\n<li><p>attribute_identifier - string passed directly to nosetests as \u2018-A\u2019.</p></li>\n</ul>\n</dd>\n<dt><strong>verbose</strong><span class=\"classifier\">int, optional</span></dt><dd><p>Verbosity value for test outputs, in the range 1-10. Default is 1.</p>\n</dd>\n<dt><strong>extra_argv</strong><span class=\"classifier\">list, optional</span></dt><dd><p>List with any extra arguments to pass to nosetests.</p>\n</dd>\n<dt><strong>doctests</strong><span class=\"classifier\">bool, optional</span></dt><dd><p>If True, run doctests in module. Default is False.</p>\n</dd>\n<dt><strong>coverage</strong><span class=\"classifier\">bool, optional</span></dt><dd><p>If True, report coverage of NumPy code. Default is False.\n(This requires the\n<a class=\"reference external\" href=\"https://pypi.org/project/coverage/\">coverage module</a>).</p>\n</dd>\n<dt><strong>raise_warnings</strong><span class=\"classifier\">None, str or sequence of warnings, optional</span></dt><dd><p>This specifies which warnings to configure as \u2018raise\u2019 instead\nof being shown once during the test execution. Valid strings are:</p>\n<ul class=\"simple\">\n<li><p>\u201cdevelop\u201d : equals <code class=\"docutils literal notranslate\"><span class=\"pre\">(Warning,)</span></code></p></li>\n<li><p>\u201crelease\u201d : equals <code class=\"docutils literal notranslate\"><span class=\"pre\">()</span></code>, do not raise on any warnings.</p></li>\n</ul>\n</dd>\n<dt><strong>timer</strong><span class=\"classifier\">bool or int, optional</span></dt><dd><p>Timing of individual tests with <code class=\"docutils literal notranslate\"><span class=\"pre\">nose-timer</span></code> (which needs to be\ninstalled).  If True, time tests and report on all of them.\nIf an integer (say <code class=\"docutils literal notranslate\"><span class=\"pre\">N</span></code>), report timing results for <code class=\"docutils literal notranslate\"><span class=\"pre\">N</span></code> slowest\ntests.</p>\n</dd>\n</dl>\n</dd>\n<dt class=\"field-even\">Returns</dt>\n<dd class=\"field-even\"><dl class=\"simple\">\n<dt><strong>result</strong><span class=\"classifier\">object</span></dt><dd><p>Returns the result of running the tests as a\n<code class=\"docutils literal notranslate\"><span class=\"pre\">nose.result.TextTestResult</span></code> object.</p>\n</dd>\n</dl>\n</dd>\n</dl>\n<p class=\"rubric\">Notes</p>\n<p>Each NumPy module exposes <cite>test</cite> in its namespace to run all tests for it.\nFor example, to run all tests for numpy.lib:</p>\n<div class=\"doctest highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">lib</span><span class=\"o\">.</span><span class=\"n\">test</span><span class=\"p\">()</span> \n</pre></div>\n</div>\n<p class=\"rubric\">Examples</p>\n<div class=\"doctest highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">lib</span><span class=\"o\">.</span><span class=\"n\">test</span><span class=\"p\">()</span> \n<span class=\"go\">Running unit tests for numpy.lib</span>\n<span class=\"gp\">...</span>\n<span class=\"go\">Ran 976 tests in 3.933s</span>\n</pre></div>\n</div>\n<p>OK</p>\n<div class=\"doctest highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">result</span><span class=\"o\">.</span><span class=\"n\">errors</span> \n<span class=\"go\">[]</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">result</span><span class=\"o\">.</span><span class=\"n\">knownfail</span> \n<span class=\"go\">[]</span>\n</pre></div>\n</div>\n</dd></dl>\n\n</section>\n<section id=\"add\">\n<h3><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Add\" title=\"dipy.nn.histo_resdnn.Add\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Add</span></code></a><a class=\"headerlink\" href=\"#add\" title=\"Permalink to this headline\">\u00b6</a></h3>\n<dl class=\"py class\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Add\">\n<em class=\"property\"><span class=\"pre\">class</span><span class=\"w\"> </span></em><span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.histo_resdnn.</span></span><span class=\"sig-name descname\"><span class=\"pre\">Add</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"o\"><span class=\"pre\">*</span></span><span class=\"n\"><span class=\"pre\">args</span></span></em>, <em class=\"sig-param\"><span class=\"o\"><span class=\"pre\">**</span></span><span class=\"n\"><span class=\"pre\">kwargs</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Add\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Bases: <code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">keras.layers.merge._Merge</span></code></p>\n<p>Layer that adds a list of inputs.</p>\n<p>It takes as input a list of tensors,\nall of the same shape, and returns\na single tensor (also of the same shape).</p>\n<p>Examples:</p>\n<div class=\"doctest highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">input_shape</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">x1</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">normal</span><span class=\"p\">(</span><span class=\"n\">input_shape</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">x2</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">normal</span><span class=\"p\">(</span><span class=\"n\">input_shape</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Add</span><span class=\"p\">()([</span><span class=\"n\">x1</span><span class=\"p\">,</span> <span class=\"n\">x2</span><span class=\"p\">])</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">y</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">)</span>\n<span class=\"go\">(2, 3, 4)</span>\n</pre></div>\n</div>\n<p>Used in a functional model:</p>\n<div class=\"doctest highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">input1</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Input</span><span class=\"p\">(</span><span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">16</span><span class=\"p\">,))</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">x1</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s1\">&#39;relu&#39;</span><span class=\"p\">)(</span><span class=\"n\">input1</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">input2</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Input</span><span class=\"p\">(</span><span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">32</span><span class=\"p\">,))</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">x2</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s1\">&#39;relu&#39;</span><span class=\"p\">)(</span><span class=\"n\">input2</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"c1\"># equivalent to `added = tf.keras.layers.add([x1, x2])`</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">added</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Add</span><span class=\"p\">()([</span><span class=\"n\">x1</span><span class=\"p\">,</span> <span class=\"n\">x2</span><span class=\"p\">])</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">out</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">)(</span><span class=\"n\">added</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">models</span><span class=\"o\">.</span><span class=\"n\">Model</span><span class=\"p\">(</span><span class=\"n\">inputs</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">input1</span><span class=\"p\">,</span> <span class=\"n\">input2</span><span class=\"p\">],</span> <span class=\"n\">outputs</span><span class=\"o\">=</span><span class=\"n\">out</span><span class=\"p\">)</span>\n</pre></div>\n</div>\n<dl class=\"field-list simple\">\n<dt class=\"field-odd\">Attributes</dt>\n<dd class=\"field-odd\"><dl class=\"simple\">\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">activity_regularizer</span></code></dt><dd><p>Optional regularizer function for the output of this layer.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">compute_dtype</span></code></dt><dd><p>The dtype of the layer\u2019s computations.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">dtype</span></code></dt><dd><p>The dtype of the layer weights.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">dtype_policy</span></code></dt><dd><p>The dtype policy associated with this layer.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">dynamic</span></code></dt><dd><p>Whether the layer is dynamic (eager-only); set in the constructor.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">inbound_nodes</span></code></dt><dd><p>Deprecated, do NOT use! Only for compatibility with external Keras.</p>\n</dd>\n<dt><a class=\"reference external\" href=\"https://docs.python.org/3/library/functions.html#input\" title=\"(in Python v3.10)\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">input</span></code></a></dt><dd><p>Retrieves the input tensor(s) of a layer.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">input_mask</span></code></dt><dd><p>Retrieves the input mask tensor(s) of a layer.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">input_shape</span></code></dt><dd><p>Retrieves the input shape(s) of a layer.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">input_spec</span></code></dt><dd><p><cite>InputSpec</cite> instance(s) describing the input format for this layer.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">losses</span></code></dt><dd><p>List of losses added using the <cite>add_loss()</cite> API.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">metrics</span></code></dt><dd><p>List of metrics added using the <cite>add_metric()</cite> API.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">name</span></code></dt><dd><p>Name of the layer (string), set in the constructor.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">name_scope</span></code></dt><dd><p>Returns a <cite>tf.name_scope</cite> instance for this class.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">non_trainable_variables</span></code></dt><dd><p>Sequence of non-trainable variables owned by this module and its submodules.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">non_trainable_weights</span></code></dt><dd><p>List of all non-trainable weights tracked by this layer.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">outbound_nodes</span></code></dt><dd><p>Deprecated, do NOT use! Only for compatibility with external Keras.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">output</span></code></dt><dd><p>Retrieves the output tensor(s) of a layer.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">output_mask</span></code></dt><dd><p>Retrieves the output mask tensor(s) of a layer.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">output_shape</span></code></dt><dd><p>Retrieves the output shape(s) of a layer.</p>\n</dd>\n<dt><strong>stateful</strong></dt><dd></dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">submodules</span></code></dt><dd><p>Sequence of all sub-modules.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">supports_masking</span></code></dt><dd><p>Whether this layer supports computing a mask using <cite>compute_mask</cite>.</p>\n</dd>\n<dt><strong>trainable</strong></dt><dd></dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">trainable_variables</span></code></dt><dd><p>Sequence of trainable variables owned by this module and its submodules.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">trainable_weights</span></code></dt><dd><p>List of all trainable weights tracked by this layer.</p>\n</dd>\n<dt><strong>updates</strong></dt><dd></dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">variable_dtype</span></code></dt><dd><p>Alias of <cite>Layer.dtype</cite>, the dtype of the weights.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">variables</span></code></dt><dd><p>Returns the list of all layer variables/weights.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">weights</span></code></dt><dd><p>Returns the list of all layer variables/weights.</p>\n</dd>\n</dl>\n</dd>\n</dl>\n<p class=\"rubric\">Methods</p>\n<table class=\"longtable docutils align-default\">\n<colgroup>\n<col style=\"width: 10%\" />\n<col style=\"width: 90%\" />\n</colgroup>\n<tbody>\n<tr class=\"row-odd\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">__call__</span></code>(*args,\u00a0**kwargs)</p></td>\n<td><p>Wraps <cite>call</cite>, applying pre- and post-processing steps.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">add_loss</span></code>(losses,\u00a0**kwargs)</p></td>\n<td><p>Add loss tensor(s), potentially dependent on layer inputs.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">add_metric</span></code>(value[,\u00a0name])</p></td>\n<td><p>Adds metric tensor to the layer.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">add_update</span></code>(updates[,\u00a0inputs])</p></td>\n<td><p>Add update op(s), potentially dependent on layer inputs.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">add_variable</span></code>(*args,\u00a0**kwargs)</p></td>\n<td><p>Deprecated, do NOT use! Alias for <cite>add_weight</cite>.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">add_weight</span></code>([name,\u00a0shape,\u00a0dtype,\u00a0...])</p></td>\n<td><p>Adds a new variable to the layer.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">apply</span></code>(inputs,\u00a0*args,\u00a0**kwargs)</p></td>\n<td><p>Deprecated, do NOT use!</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">call</span></code>(inputs)</p></td>\n<td><p>This is where the layer's logic lives.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">compute_mask</span></code>(inputs[,\u00a0mask])</p></td>\n<td><p>Computes an output mask tensor.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">compute_output_signature</span></code>(input_signature)</p></td>\n<td><p>Compute the output tensor signature of the layer based on the inputs.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">count_params</span></code>()</p></td>\n<td><p>Count the total number of scalars composing the weights.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">finalize_state</span></code>()</p></td>\n<td><p>Finalizes the layers state after updating layer weights.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">from_config</span></code>(config)</p></td>\n<td><p>Creates a layer from its config.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">get_config</span></code>()</p></td>\n<td><p>Returns the config of the layer.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">get_input_at</span></code>(node_index)</p></td>\n<td><p>Retrieves the input tensor(s) of a layer at a given node.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">get_input_mask_at</span></code>(node_index)</p></td>\n<td><p>Retrieves the input mask tensor(s) of a layer at a given node.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">get_input_shape_at</span></code>(node_index)</p></td>\n<td><p>Retrieves the input shape(s) of a layer at a given node.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">get_losses_for</span></code>(inputs)</p></td>\n<td><p>Deprecated, do NOT use!</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">get_output_at</span></code>(node_index)</p></td>\n<td><p>Retrieves the output tensor(s) of a layer at a given node.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">get_output_mask_at</span></code>(node_index)</p></td>\n<td><p>Retrieves the output mask tensor(s) of a layer at a given node.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">get_output_shape_at</span></code>(node_index)</p></td>\n<td><p>Retrieves the output shape(s) of a layer at a given node.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">get_updates_for</span></code>(inputs)</p></td>\n<td><p>Deprecated, do NOT use!</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">get_weights</span></code>()</p></td>\n<td><p>Returns the current weights of the layer, as NumPy arrays.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">set_weights</span></code>(weights)</p></td>\n<td><p>Sets the weights of the layer, from NumPy arrays.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">with_name_scope</span></code>(method)</p></td>\n<td><p>Decorator to automatically enter the module name scope.</p></td>\n</tr>\n</tbody>\n</table>\n<table class=\"docutils align-default\">\n<colgroup>\n<col style=\"width: 71%\" />\n<col style=\"width: 29%\" />\n</colgroup>\n<tbody>\n<tr class=\"row-odd\"><td><p><strong>build</strong></p></td>\n<td></td>\n</tr>\n<tr class=\"row-even\"><td><p><strong>compute_output_shape</strong></p></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Add.__init__\">\n<span class=\"sig-name descname\"><span class=\"pre\">__init__</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"o\"><span class=\"pre\">**</span></span><span class=\"n\"><span class=\"pre\">kwargs</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Add.__init__\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Initializes a Merge layer.</p>\n<dl class=\"simple\">\n<dt>Args:</dt><dd><p><a href=\"#id1\"><span class=\"problematic\" id=\"id2\">**</span></a>kwargs: standard layer keyword arguments.</p>\n</dd>\n</dl>\n</dd></dl>\n\n</dd></dl>\n\n</section>\n<section id=\"dense\">\n<h3><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Dense\" title=\"dipy.nn.histo_resdnn.Dense\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Dense</span></code></a><a class=\"headerlink\" href=\"#dense\" title=\"Permalink to this headline\">\u00b6</a></h3>\n<dl class=\"py class\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Dense\">\n<em class=\"property\"><span class=\"pre\">class</span><span class=\"w\"> </span></em><span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.histo_resdnn.</span></span><span class=\"sig-name descname\"><span class=\"pre\">Dense</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"o\"><span class=\"pre\">*</span></span><span class=\"n\"><span class=\"pre\">args</span></span></em>, <em class=\"sig-param\"><span class=\"o\"><span class=\"pre\">**</span></span><span class=\"n\"><span class=\"pre\">kwargs</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Dense\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Bases: <code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">keras.engine.base_layer.Layer</span></code></p>\n<p>Just your regular densely-connected NN layer.</p>\n<p><cite>Dense</cite> implements the operation:\n<cite>output = activation(dot(input, kernel) + bias)</cite>\nwhere <cite>activation</cite> is the element-wise activation function\npassed as the <cite>activation</cite> argument, <cite>kernel</cite> is a weights matrix\ncreated by the layer, and <cite>bias</cite> is a bias vector created by the layer\n(only applicable if <cite>use_bias</cite> is <cite>True</cite>). These are all attributes of\n<cite>Dense</cite>.</p>\n<p>Note: If the input to the layer has a rank greater than 2, then <cite>Dense</cite>\ncomputes the dot product between the <cite>inputs</cite> and the <cite>kernel</cite> along the\nlast axis of the <cite>inputs</cite> and axis 0 of the <cite>kernel</cite> (using <cite>tf.tensordot</cite>).\nFor example, if input has dimensions <cite>(batch_size, d0, d1)</cite>,\nthen we create a <cite>kernel</cite> with shape <cite>(d1, units)</cite>, and the <cite>kernel</cite> operates\nalong axis 2 of the <cite>input</cite>, on every sub-tensor of shape <cite>(1, 1, d1)</cite>\n(there are <cite>batch_size * d0</cite> such sub-tensors).\nThe output in this case will have shape <cite>(batch_size, d0, units)</cite>.</p>\n<p>Besides, layer attributes cannot be modified after the layer has been called\nonce (except the <cite>trainable</cite> attribute).\nWhen a popular kwarg <cite>input_shape</cite> is passed, then keras will create\nan input layer to insert before the current layer. This can be treated\nequivalent to explicitly defining an <cite>InputLayer</cite>.</p>\n<p>Example:</p>\n<div class=\"doctest highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"c1\"># Create a `Sequential` model and add a Dense layer as the first layer.</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">models</span><span class=\"o\">.</span><span class=\"n\">Sequential</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">Input</span><span class=\"p\">(</span><span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">16</span><span class=\"p\">,)))</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s1\">&#39;relu&#39;</span><span class=\"p\">))</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"c1\"># Now the model will take as input arrays of shape (None, 16)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"c1\"># and output arrays of shape (None, 32).</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"c1\"># Note that after the first layer, you don&#39;t need to specify</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"c1\"># the size of the input anymore:</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">32</span><span class=\"p\">))</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">output_shape</span>\n<span class=\"go\">(None, 32)</span>\n</pre></div>\n</div>\n<dl>\n<dt>Args:</dt><dd><p>units: Positive integer, dimensionality of the output space.\nactivation: Activation function to use.</p>\n<blockquote>\n<div><p>If you don\u2019t specify anything, no activation is applied\n(ie. \u201clinear\u201d activation: <cite>a(x) = x</cite>).</p>\n</div></blockquote>\n<p>use_bias: Boolean, whether the layer uses a bias vector.\nkernel_initializer: Initializer for the <cite>kernel</cite> weights matrix.\nbias_initializer: Initializer for the bias vector.\nkernel_regularizer: Regularizer function applied to</p>\n<blockquote>\n<div><p>the <cite>kernel</cite> weights matrix.</p>\n</div></blockquote>\n<p>bias_regularizer: Regularizer function applied to the bias vector.\nactivity_regularizer: Regularizer function applied to</p>\n<blockquote>\n<div><p>the output of the layer (its \u201cactivation\u201d).</p>\n</div></blockquote>\n<dl class=\"simple\">\n<dt>kernel_constraint: Constraint function applied to</dt><dd><p>the <cite>kernel</cite> weights matrix.</p>\n</dd>\n</dl>\n<p>bias_constraint: Constraint function applied to the bias vector.</p>\n</dd>\n<dt>Input shape:</dt><dd><p>N-D tensor with shape: <cite>(batch_size, \u2026, input_dim)</cite>.\nThe most common situation would be\na 2D input with shape <cite>(batch_size, input_dim)</cite>.</p>\n</dd>\n<dt>Output shape:</dt><dd><p>N-D tensor with shape: <cite>(batch_size, \u2026, units)</cite>.\nFor instance, for a 2D input with shape <cite>(batch_size, input_dim)</cite>,\nthe output would have shape <cite>(batch_size, units)</cite>.</p>\n</dd>\n</dl>\n<dl class=\"field-list simple\">\n<dt class=\"field-odd\">Attributes</dt>\n<dd class=\"field-odd\"><dl class=\"simple\">\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">activity_regularizer</span></code></dt><dd><p>Optional regularizer function for the output of this layer.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">compute_dtype</span></code></dt><dd><p>The dtype of the layer\u2019s computations.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">dtype</span></code></dt><dd><p>The dtype of the layer weights.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">dtype_policy</span></code></dt><dd><p>The dtype policy associated with this layer.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">dynamic</span></code></dt><dd><p>Whether the layer is dynamic (eager-only); set in the constructor.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">inbound_nodes</span></code></dt><dd><p>Deprecated, do NOT use! Only for compatibility with external Keras.</p>\n</dd>\n<dt><a class=\"reference external\" href=\"https://docs.python.org/3/library/functions.html#input\" title=\"(in Python v3.10)\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">input</span></code></a></dt><dd><p>Retrieves the input tensor(s) of a layer.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">input_mask</span></code></dt><dd><p>Retrieves the input mask tensor(s) of a layer.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">input_shape</span></code></dt><dd><p>Retrieves the input shape(s) of a layer.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">input_spec</span></code></dt><dd><p><cite>InputSpec</cite> instance(s) describing the input format for this layer.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">losses</span></code></dt><dd><p>List of losses added using the <cite>add_loss()</cite> API.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">metrics</span></code></dt><dd><p>List of metrics added using the <cite>add_metric()</cite> API.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">name</span></code></dt><dd><p>Name of the layer (string), set in the constructor.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">name_scope</span></code></dt><dd><p>Returns a <cite>tf.name_scope</cite> instance for this class.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">non_trainable_variables</span></code></dt><dd><p>Sequence of non-trainable variables owned by this module and its submodules.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">non_trainable_weights</span></code></dt><dd><p>List of all non-trainable weights tracked by this layer.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">outbound_nodes</span></code></dt><dd><p>Deprecated, do NOT use! Only for compatibility with external Keras.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">output</span></code></dt><dd><p>Retrieves the output tensor(s) of a layer.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">output_mask</span></code></dt><dd><p>Retrieves the output mask tensor(s) of a layer.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">output_shape</span></code></dt><dd><p>Retrieves the output shape(s) of a layer.</p>\n</dd>\n<dt><strong>stateful</strong></dt><dd></dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">submodules</span></code></dt><dd><p>Sequence of all sub-modules.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">supports_masking</span></code></dt><dd><p>Whether this layer supports computing a mask using <cite>compute_mask</cite>.</p>\n</dd>\n<dt><strong>trainable</strong></dt><dd></dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">trainable_variables</span></code></dt><dd><p>Sequence of trainable variables owned by this module and its submodules.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">trainable_weights</span></code></dt><dd><p>List of all trainable weights tracked by this layer.</p>\n</dd>\n<dt><strong>updates</strong></dt><dd></dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">variable_dtype</span></code></dt><dd><p>Alias of <cite>Layer.dtype</cite>, the dtype of the weights.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">variables</span></code></dt><dd><p>Returns the list of all layer variables/weights.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">weights</span></code></dt><dd><p>Returns the list of all layer variables/weights.</p>\n</dd>\n</dl>\n</dd>\n</dl>\n<p class=\"rubric\">Methods</p>\n<table class=\"longtable docutils align-default\">\n<colgroup>\n<col style=\"width: 10%\" />\n<col style=\"width: 90%\" />\n</colgroup>\n<tbody>\n<tr class=\"row-odd\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">__call__</span></code>(*args,\u00a0**kwargs)</p></td>\n<td><p>Wraps <cite>call</cite>, applying pre- and post-processing steps.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">add_loss</span></code>(losses,\u00a0**kwargs)</p></td>\n<td><p>Add loss tensor(s), potentially dependent on layer inputs.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">add_metric</span></code>(value[,\u00a0name])</p></td>\n<td><p>Adds metric tensor to the layer.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">add_update</span></code>(updates[,\u00a0inputs])</p></td>\n<td><p>Add update op(s), potentially dependent on layer inputs.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">add_variable</span></code>(*args,\u00a0**kwargs)</p></td>\n<td><p>Deprecated, do NOT use! Alias for <cite>add_weight</cite>.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">add_weight</span></code>([name,\u00a0shape,\u00a0dtype,\u00a0...])</p></td>\n<td><p>Adds a new variable to the layer.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">apply</span></code>(inputs,\u00a0*args,\u00a0**kwargs)</p></td>\n<td><p>Deprecated, do NOT use!</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Dense.build\" title=\"dipy.nn.histo_resdnn.Dense.build\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">build</span></code></a>(input_shape)</p></td>\n<td><p>Creates the variables of the layer (optional, for subclass implementers).</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Dense.call\" title=\"dipy.nn.histo_resdnn.Dense.call\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">call</span></code></a>(inputs)</p></td>\n<td><p>This is where the layer's logic lives.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">compute_mask</span></code>(inputs[,\u00a0mask])</p></td>\n<td><p>Computes an output mask tensor.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Dense.compute_output_shape\" title=\"dipy.nn.histo_resdnn.Dense.compute_output_shape\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">compute_output_shape</span></code></a>(input_shape)</p></td>\n<td><p>Computes the output shape of the layer.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">compute_output_signature</span></code>(input_signature)</p></td>\n<td><p>Compute the output tensor signature of the layer based on the inputs.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">count_params</span></code>()</p></td>\n<td><p>Count the total number of scalars composing the weights.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">finalize_state</span></code>()</p></td>\n<td><p>Finalizes the layers state after updating layer weights.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">from_config</span></code>(config)</p></td>\n<td><p>Creates a layer from its config.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Dense.get_config\" title=\"dipy.nn.histo_resdnn.Dense.get_config\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">get_config</span></code></a>()</p></td>\n<td><p>Returns the config of the layer.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">get_input_at</span></code>(node_index)</p></td>\n<td><p>Retrieves the input tensor(s) of a layer at a given node.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">get_input_mask_at</span></code>(node_index)</p></td>\n<td><p>Retrieves the input mask tensor(s) of a layer at a given node.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">get_input_shape_at</span></code>(node_index)</p></td>\n<td><p>Retrieves the input shape(s) of a layer at a given node.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">get_losses_for</span></code>(inputs)</p></td>\n<td><p>Deprecated, do NOT use!</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">get_output_at</span></code>(node_index)</p></td>\n<td><p>Retrieves the output tensor(s) of a layer at a given node.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">get_output_mask_at</span></code>(node_index)</p></td>\n<td><p>Retrieves the output mask tensor(s) of a layer at a given node.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">get_output_shape_at</span></code>(node_index)</p></td>\n<td><p>Retrieves the output shape(s) of a layer at a given node.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">get_updates_for</span></code>(inputs)</p></td>\n<td><p>Deprecated, do NOT use!</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">get_weights</span></code>()</p></td>\n<td><p>Returns the current weights of the layer, as NumPy arrays.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">set_weights</span></code>(weights)</p></td>\n<td><p>Sets the weights of the layer, from NumPy arrays.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">with_name_scope</span></code>(method)</p></td>\n<td><p>Decorator to automatically enter the module name scope.</p></td>\n</tr>\n</tbody>\n</table>\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Dense.__init__\">\n<span class=\"sig-name descname\"><span class=\"pre\">__init__</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">units</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">activation</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">use_bias</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">True</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">kernel_initializer</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'glorot_uniform'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">bias_initializer</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'zeros'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">kernel_regularizer</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">bias_regularizer</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">activity_regularizer</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">kernel_constraint</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">bias_constraint</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"o\"><span class=\"pre\">**</span></span><span class=\"n\"><span class=\"pre\">kwargs</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Dense.__init__\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Dense.build\">\n<span class=\"sig-name descname\"><span class=\"pre\">build</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">input_shape</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Dense.build\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Creates the variables of the layer (optional, for subclass implementers).</p>\n<p>This is a method that implementers of subclasses of <cite>Layer</cite> or <cite>Model</cite>\ncan override if they need a state-creation step in-between\nlayer instantiation and layer call. It is invoked automatically before\nthe first execution of <cite>call()</cite>.</p>\n<p>This is typically used to create the weights of <cite>Layer</cite> subclasses\n(at the discretion of the subclass implementer).</p>\n<dl class=\"simple\">\n<dt>Args:</dt><dd><dl class=\"simple\">\n<dt>input_shape: Instance of <cite>TensorShape</cite>, or list of instances of</dt><dd><p><cite>TensorShape</cite> if the layer expects a list of inputs\n(one instance per input).</p>\n</dd>\n</dl>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Dense.call\">\n<span class=\"sig-name descname\"><span class=\"pre\">call</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">inputs</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Dense.call\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>This is where the layer\u2019s logic lives.</p>\n<p>The <cite>call()</cite> method may not create state (except in its first invocation,\nwrapping the creation of variables or other resources in <cite>tf.init_scope()</cite>).\nIt is recommended to create state in <cite>__init__()</cite>, or the <cite>build()</cite> method\nthat is called automatically before <cite>call()</cite> executes the first time.</p>\n<dl>\n<dt>Args:</dt><dd><dl>\n<dt>inputs: Input tensor, or dict/list/tuple of input tensors.</dt><dd><p>The first positional <cite>inputs</cite> argument is subject to special rules:\n- <cite>inputs</cite> must be explicitly passed. A layer cannot have zero</p>\n<blockquote>\n<div><p>arguments, and <cite>inputs</cite> cannot be provided via the default value\nof a keyword argument.</p>\n</div></blockquote>\n<ul class=\"simple\">\n<li><p>NumPy array or Python scalar values in <cite>inputs</cite> get cast as tensors.</p></li>\n<li><p>Keras mask metadata is only collected from <cite>inputs</cite>.</p></li>\n<li><p>Layers are built (<cite>build(input_shape)</cite> method)\nusing shape info from <cite>inputs</cite> only.</p></li>\n<li><p><cite>input_spec</cite> compatibility is only checked against <cite>inputs</cite>.</p></li>\n<li><p>Mixed precision input casting is only applied to <cite>inputs</cite>.\nIf a layer has tensor arguments in <cite>*args</cite> or <cite>**kwargs</cite>, their\ncasting behavior in mixed precision should be handled manually.</p></li>\n<li><p>The SavedModel input specification is generated using <cite>inputs</cite> only.</p></li>\n<li><p>Integration with various ecosystem packages like TFMOT, TFLite,\nTF.js, etc is only supported for <cite>inputs</cite> and not for tensors in\npositional and keyword arguments.</p></li>\n</ul>\n</dd>\n<dt><a href=\"#id3\"><span class=\"problematic\" id=\"id4\">*</span></a>args: Additional positional arguments. May contain tensors, although</dt><dd><p>this is not recommended, for the reasons above.</p>\n</dd>\n<dt><a href=\"#id5\"><span class=\"problematic\" id=\"id6\">**</span></a>kwargs: Additional keyword arguments. May contain tensors, although</dt><dd><p>this is not recommended, for the reasons above.\nThe following optional keyword arguments are reserved:\n- <cite>training</cite>: Boolean scalar tensor of Python boolean indicating</p>\n<blockquote>\n<div><p>whether the <cite>call</cite> is meant for training or inference.</p>\n</div></blockquote>\n<ul class=\"simple\">\n<li><p><cite>mask</cite>: Boolean input mask. If the layer\u2019s <cite>call()</cite> method takes a\n<cite>mask</cite> argument, its default value will be set to the mask generated\nfor <cite>inputs</cite> by the previous layer (if <cite>input</cite> did come from a layer\nthat generated a corresponding mask, i.e. if it came from a Keras\nlayer with masking support).</p></li>\n</ul>\n</dd>\n</dl>\n</dd>\n<dt>Returns:</dt><dd><p>A tensor or list/tuple of tensors.</p>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Dense.compute_output_shape\">\n<span class=\"sig-name descname\"><span class=\"pre\">compute_output_shape</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">input_shape</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Dense.compute_output_shape\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Computes the output shape of the layer.</p>\n<p>This method will cause the layer\u2019s state to be built, if that has not\nhappened before. This requires that the layer will later be used with\ninputs that match the input shape provided here.</p>\n<dl class=\"simple\">\n<dt>Args:</dt><dd><dl class=\"simple\">\n<dt>input_shape: Shape tuple (tuple of integers)</dt><dd><p>or list of shape tuples (one per output tensor of the layer).\nShape tuples can include None for free dimensions,\ninstead of an integer.</p>\n</dd>\n</dl>\n</dd>\n<dt>Returns:</dt><dd><p>An input shape tuple.</p>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Dense.get_config\">\n<span class=\"sig-name descname\"><span class=\"pre\">get_config</span></span><span class=\"sig-paren\">(</span><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Dense.get_config\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Returns the config of the layer.</p>\n<p>A layer config is a Python dictionary (serializable)\ncontaining the configuration of a layer.\nThe same layer can be reinstantiated later\n(without its trained weights) from this configuration.</p>\n<p>The config of a layer does not include connectivity\ninformation, nor the layer class name. These are handled\nby <cite>Network</cite> (one layer of abstraction above).</p>\n<p>Note that <cite>get_config()</cite> does not guarantee to return a fresh copy of dict\nevery time it is called. The callers should make a copy of the returned dict\nif they want to modify it.</p>\n<dl class=\"simple\">\n<dt>Returns:</dt><dd><p>Python dictionary.</p>\n</dd>\n</dl>\n</dd></dl>\n\n</dd></dl>\n\n</section>\n<section id=\"hemisphere\">\n<h3><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.HemiSphere\" title=\"dipy.nn.histo_resdnn.HemiSphere\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">HemiSphere</span></code></a><a class=\"headerlink\" href=\"#hemisphere\" title=\"Permalink to this headline\">\u00b6</a></h3>\n<dl class=\"py class\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.HemiSphere\">\n<em class=\"property\"><span class=\"pre\">class</span><span class=\"w\"> </span></em><span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.histo_resdnn.</span></span><span class=\"sig-name descname\"><span class=\"pre\">HemiSphere</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">x</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">y</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">z</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">theta</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">phi</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">xyz</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">faces</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">edges</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">tol</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">1e-05</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.HemiSphere\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Bases: <a class=\"reference internal\" href=\"../dipy.core/#dipy.core.sphere.Sphere\" title=\"dipy.core.sphere.Sphere\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">dipy.core.sphere.Sphere</span></code></a></p>\n<p>Points on the unit sphere.</p>\n<p>A HemiSphere is similar to a Sphere but it takes antipodal symmetry into\naccount. Antipodal symmetry means that point v on a HemiSphere is the same\nas the point -v. Duplicate points are discarded when constructing a\nHemiSphere (including antipodal duplicates). <cite>edges</cite> and <cite>faces</cite> are\nremapped to the remaining points as closely as possible.</p>\n<p>The HemiSphere can be constructed using one of three conventions:</p>\n<div class=\"highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"n\">HemiSphere</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">z</span><span class=\"p\">)</span>\n<span class=\"n\">HemiSphere</span><span class=\"p\">(</span><span class=\"n\">xyz</span><span class=\"o\">=</span><span class=\"n\">xyz</span><span class=\"p\">)</span>\n<span class=\"n\">HemiSphere</span><span class=\"p\">(</span><span class=\"n\">theta</span><span class=\"o\">=</span><span class=\"n\">theta</span><span class=\"p\">,</span> <span class=\"n\">phi</span><span class=\"o\">=</span><span class=\"n\">phi</span><span class=\"p\">)</span>\n</pre></div>\n</div>\n<dl class=\"field-list simple\">\n<dt class=\"field-odd\">Parameters</dt>\n<dd class=\"field-odd\"><dl class=\"simple\">\n<dt><strong>x, y, z</strong><span class=\"classifier\">1-D array_like</span></dt><dd><p>Vertices as x-y-z coordinates.</p>\n</dd>\n<dt><strong>theta, phi</strong><span class=\"classifier\">1-D array_like</span></dt><dd><p>Vertices as spherical coordinates.  Theta and phi are the inclination\nand azimuth angles respectively.</p>\n</dd>\n<dt><strong>xyz</strong><span class=\"classifier\">(N, 3) ndarray</span></dt><dd><p>Vertices as x-y-z coordinates.</p>\n</dd>\n<dt><strong>faces</strong><span class=\"classifier\">(N, 3) ndarray</span></dt><dd><p>Indices into vertices that form triangular faces.  If unspecified,\nthe faces are computed using a Delaunay triangulation.</p>\n</dd>\n<dt><strong>edges</strong><span class=\"classifier\">(N, 2) ndarray</span></dt><dd><p>Edges between vertices.  If unspecified, the edges are\nderived from the faces.</p>\n</dd>\n<dt><strong>tol</strong><span class=\"classifier\">float</span></dt><dd><p>Angle in degrees. Vertices that are less than tol degrees apart are\ntreated as duplicates.</p>\n</dd>\n</dl>\n</dd>\n</dl>\n<div class=\"admonition seealso\">\n<p class=\"admonition-title\">See also</p>\n<dl class=\"simple\">\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">Sphere</span></code></dt><dd></dd>\n</dl>\n</div>\n<dl class=\"field-list simple\">\n<dt class=\"field-odd\">Attributes</dt>\n<dd class=\"field-odd\"><dl class=\"simple\">\n<dt><strong>x</strong></dt><dd></dd>\n<dt><strong>y</strong></dt><dd></dd>\n<dt><strong>z</strong></dt><dd></dd>\n</dl>\n</dd>\n</dl>\n<p class=\"rubric\">Methods</p>\n<table class=\"longtable docutils align-default\">\n<colgroup>\n<col style=\"width: 10%\" />\n<col style=\"width: 90%\" />\n</colgroup>\n<tbody>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.HemiSphere.find_closest\" title=\"dipy.nn.histo_resdnn.HemiSphere.find_closest\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">find_closest</span></code></a>(xyz)</p></td>\n<td><p>Find the index of the vertex in the Sphere closest to the input vector, taking into account antipodal symmetry</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.HemiSphere.from_sphere\" title=\"dipy.nn.histo_resdnn.HemiSphere.from_sphere\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">from_sphere</span></code></a>(sphere[,\u00a0tol])</p></td>\n<td><p>Create instance from a Sphere</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.HemiSphere.mirror\" title=\"dipy.nn.histo_resdnn.HemiSphere.mirror\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">mirror</span></code></a>()</p></td>\n<td><p>Create a full Sphere from a HemiSphere</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.HemiSphere.subdivide\" title=\"dipy.nn.histo_resdnn.HemiSphere.subdivide\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">subdivide</span></code></a>([n])</p></td>\n<td><p>Create a more subdivided HemiSphere</p></td>\n</tr>\n</tbody>\n</table>\n<table class=\"docutils align-default\">\n<colgroup>\n<col style=\"width: 55%\" />\n<col style=\"width: 45%\" />\n</colgroup>\n<tbody>\n<tr class=\"row-odd\"><td><p><strong>edges</strong></p></td>\n<td></td>\n</tr>\n<tr class=\"row-even\"><td><p><strong>faces</strong></p></td>\n<td></td>\n</tr>\n<tr class=\"row-odd\"><td><p><strong>vertices</strong></p></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.HemiSphere.__init__\">\n<span class=\"sig-name descname\"><span class=\"pre\">__init__</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">x</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">y</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">z</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">theta</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">phi</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">xyz</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">faces</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">edges</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">tol</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">1e-05</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.HemiSphere.__init__\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Create a HemiSphere from points</p>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.HemiSphere.faces\">\n<span class=\"sig-name descname\"><span class=\"pre\">faces</span></span><span class=\"sig-paren\">(</span><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.HemiSphere.faces\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.HemiSphere.find_closest\">\n<span class=\"sig-name descname\"><span class=\"pre\">find_closest</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">xyz</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.HemiSphere.find_closest\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Find the index of the vertex in the Sphere closest to the input vector,\ntaking into account antipodal symmetry</p>\n<dl class=\"field-list simple\">\n<dt class=\"field-odd\">Parameters</dt>\n<dd class=\"field-odd\"><dl class=\"simple\">\n<dt><strong>xyz</strong><span class=\"classifier\">array-like, 3 elements</span></dt><dd><p>A unit vector</p>\n</dd>\n</dl>\n</dd>\n<dt class=\"field-even\">Returns</dt>\n<dd class=\"field-even\"><dl class=\"simple\">\n<dt><strong>idx</strong><span class=\"classifier\">int</span></dt><dd><p>The index into the Sphere.vertices array that gives the closest\nvertex (in angle).</p>\n</dd>\n</dl>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.HemiSphere.from_sphere\">\n<em class=\"property\"><span class=\"pre\">classmethod</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">from_sphere</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">sphere</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">tol</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">1e-05</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.HemiSphere.from_sphere\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Create instance from a Sphere</p>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.HemiSphere.mirror\">\n<span class=\"sig-name descname\"><span class=\"pre\">mirror</span></span><span class=\"sig-paren\">(</span><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.HemiSphere.mirror\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Create a full Sphere from a HemiSphere</p>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.HemiSphere.subdivide\">\n<span class=\"sig-name descname\"><span class=\"pre\">subdivide</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">n</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">1</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.HemiSphere.subdivide\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Create a more subdivided HemiSphere</p>\n<p>See Sphere.subdivide for full documentation.</p>\n</dd></dl>\n\n</dd></dl>\n\n</section>\n<section id=\"historesdnn\">\n<h3><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.HistoResDNN\" title=\"dipy.nn.histo_resdnn.HistoResDNN\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">HistoResDNN</span></code></a><a class=\"headerlink\" href=\"#historesdnn\" title=\"Permalink to this headline\">\u00b6</a></h3>\n<dl class=\"py class\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.HistoResDNN\">\n<em class=\"property\"><span class=\"pre\">class</span><span class=\"w\"> </span></em><span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.histo_resdnn.</span></span><span class=\"sig-name descname\"><span class=\"pre\">HistoResDNN</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">sh_order</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">8</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">basis_type</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'tournier07'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">verbose</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.HistoResDNN\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Bases: <a class=\"reference external\" href=\"https://docs.python.org/3/library/functions.html#object\" title=\"(in Python v3.10)\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">object</span></code></a></p>\n<p>This class is intended for the ResDNN Histology Network model.</p>\n<p class=\"rubric\">Methods</p>\n<table class=\"longtable docutils align-default\">\n<colgroup>\n<col style=\"width: 10%\" />\n<col style=\"width: 90%\" />\n</colgroup>\n<tbody>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.HistoResDNN.fetch_default_weights\" title=\"dipy.nn.histo_resdnn.HistoResDNN.fetch_default_weights\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">fetch_default_weights</span></code></a>()</p></td>\n<td><p>Load the model pre-training weights to use for the fitting.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.HistoResDNN.load_model_weights\" title=\"dipy.nn.histo_resdnn.HistoResDNN.load_model_weights\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">load_model_weights</span></code></a>(weights_path)</p></td>\n<td><p>Load the custom pre-training weights to use for the fitting.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.HistoResDNN.predict\" title=\"dipy.nn.histo_resdnn.HistoResDNN.predict\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">predict</span></code></a>(data,\u00a0gtab[,\u00a0mask,\u00a0chunk_size])</p></td>\n<td><p>Wrapper function to faciliate prediction of larger dataset.</p></td>\n</tr>\n</tbody>\n</table>\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.HistoResDNN.__init__\">\n<span class=\"sig-name descname\"><span class=\"pre\">__init__</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">sh_order</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">8</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">basis_type</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'tournier07'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">verbose</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.HistoResDNN.__init__\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>The model was re-trained for usage with a different basis function\n(\u2018tournier07\u2019) like the proposed model in [1, 2].</p>\n<p>To obtain the pre-trained model, use::\n&gt;&gt;&gt; resdnn_model = HistoResDNN()\n&gt;&gt;&gt; fetch_model_weights_path = get_fnames(\u2018histo_resdnn_weights\u2019)\n&gt;&gt;&gt; resdnn_model.load_model_weights(fetch_model_weights_path)</p>\n<p>This model is designed to take as input raw DWI signal on a sphere\n(ODF) represented as SH of order 8 in the tournier basis and predict\nfODF of order 8 in the tournier basis. Effectively, this model is\nmimicking a CSD fit.</p>\n<dl class=\"field-list simple\">\n<dt class=\"field-odd\">Parameters</dt>\n<dd class=\"field-odd\"><dl class=\"simple\">\n<dt><strong>sh_order</strong><span class=\"classifier\">int, optional</span></dt><dd><p>Maximum SH order in the SH fit.  For <code class=\"docutils literal notranslate\"><span class=\"pre\">sh_order</span></code>, there will be\n<code class=\"docutils literal notranslate\"><span class=\"pre\">(sh_order</span> <span class=\"pre\">+</span> <span class=\"pre\">1)</span> <span class=\"pre\">*</span> <span class=\"pre\">(sh_order</span> <span class=\"pre\">+</span> <span class=\"pre\">2)</span> <span class=\"pre\">/</span> <span class=\"pre\">2</span></code> SH coefficients for a\nsymmetric basis. Default: 8</p>\n</dd>\n<dt><strong>basis_type</strong><span class=\"classifier\">{\u2018tournier07\u2019, \u2018descoteaux07\u2019}, optional</span></dt><dd><p><code class=\"docutils literal notranslate\"><span class=\"pre\">tournier07</span></code> (default) or <code class=\"docutils literal notranslate\"><span class=\"pre\">descoteaux07</span></code>.</p>\n</dd>\n<dt><strong>verbose</strong><span class=\"classifier\">bool (optional)</span></dt><dd><p>Whether to show information about the processing.\nDefault: False</p>\n</dd>\n</dl>\n</dd>\n</dl>\n<p class=\"rubric\">References</p>\n<dl class=\"footnote brackets\">\n<dt class=\"label\" id=\"id7\"><span class=\"brackets\">1</span></dt>\n<dd><p>Nath, V., Schilling, K. G., Parvathaneni, P., Hansen,\nC. B., Hainline, A. E., Huo, Y., \u2026 &amp; Stepniewska, I. (2019).\nDeep learning reveals untapped information for local white-matter\nfiber reconstruction in diffusion-weighted MRI.\nMagnetic resonance imaging, 62, 220-227.</p>\n</dd>\n<dt class=\"label\" id=\"id8\"><span class=\"brackets\">2</span></dt>\n<dd><p>Nath, V., Schilling, K. G., Hansen, C. B., Parvathaneni,\nP., Hainline, A. E., Bermudez, C., \u2026 &amp; St\u0119pniewska, I. (2019).\nDeep learning captures more accurate diffusion fiber orientations\ndistributions than constrained spherical deconvolution.\narXiv preprint arXiv:1911.07927.</p>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.HistoResDNN.fetch_default_weights\">\n<span class=\"sig-name descname\"><span class=\"pre\">fetch_default_weights</span></span><span class=\"sig-paren\">(</span><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.HistoResDNN.fetch_default_weights\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Load the model pre-training weights to use for the fitting.\nWill not work if the declared SH_ORDER does not match the weights\nexpected input.</p>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.HistoResDNN.load_model_weights\">\n<span class=\"sig-name descname\"><span class=\"pre\">load_model_weights</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">weights_path</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.HistoResDNN.load_model_weights\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Load the custom pre-training weights to use for the fitting.\nWill not work if the declared SH_ORDER does not match the weights\nexpected input.</p>\n<dl class=\"simple\">\n<dt>The weights for a sh_order of 8 can be obtained via the function:</dt><dd><p>get_fnames(\u2018histo_resdnn_weights\u2019).</p>\n</dd>\n</dl>\n<dl class=\"field-list simple\">\n<dt class=\"field-odd\">Parameters</dt>\n<dd class=\"field-odd\"><dl class=\"simple\">\n<dt><strong>weights_path</strong><span class=\"classifier\">str</span></dt><dd><p>Path to the file containing the weights (hdf5, saved by tensorflow)</p>\n</dd>\n</dl>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.HistoResDNN.predict\">\n<span class=\"sig-name descname\"><span class=\"pre\">predict</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">data</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">gtab</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">mask</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">chunk_size</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">1000</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.HistoResDNN.predict\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Wrapper function to faciliate prediction of larger dataset.\nThe function will mask, normalize, split, predict and \u2018re-assemble\u2019\nthe data as a volume.</p>\n<dl class=\"field-list simple\">\n<dt class=\"field-odd\">Parameters</dt>\n<dd class=\"field-odd\"><dl class=\"simple\">\n<dt><strong>data</strong><span class=\"classifier\">np.ndarray</span></dt><dd><p>DWI signal in a 4D array</p>\n</dd>\n<dt><strong>gtab</strong><span class=\"classifier\">GradientTable class instance</span></dt><dd><p>The acquisition scheme matching the data (must contain at least\none b0)</p>\n</dd>\n<dt><strong>mask</strong><span class=\"classifier\">np.ndarray (optional)</span></dt><dd><p>Binary mask of the brain to avoid unnecessary computation and\nunreliable prediction outside the brain.\nDefault: Compute prediction only for nonzero voxels (with at least\none nonzero DWI value).</p>\n</dd>\n</dl>\n</dd>\n<dt class=\"field-even\">Returns</dt>\n<dd class=\"field-even\"><dl class=\"simple\">\n<dt><strong>pred_sh_coef</strong><span class=\"classifier\">np.ndarray (x, y, z, M)</span></dt><dd><p>Predicted fODF (as SH). The volume has matching shape to the input\ndata, but with <code class=\"docutils literal notranslate\"><span class=\"pre\">(sh_order</span> <span class=\"pre\">+</span> <span class=\"pre\">1)</span> <span class=\"pre\">*</span> <span class=\"pre\">(sh_order</span> <span class=\"pre\">+</span> <span class=\"pre\">2)</span> <span class=\"pre\">/</span> <span class=\"pre\">2</span></code> as a last\ndimension.</p>\n</dd>\n</dl>\n</dd>\n</dl>\n</dd></dl>\n\n</dd></dl>\n\n</section>\n<section id=\"model\">\n<h3><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model\" title=\"dipy.nn.histo_resdnn.Model\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Model</span></code></a><a class=\"headerlink\" href=\"#model\" title=\"Permalink to this headline\">\u00b6</a></h3>\n<dl class=\"py class\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model\">\n<em class=\"property\"><span class=\"pre\">class</span><span class=\"w\"> </span></em><span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.histo_resdnn.</span></span><span class=\"sig-name descname\"><span class=\"pre\">Model</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"o\"><span class=\"pre\">*</span></span><span class=\"n\"><span class=\"pre\">args</span></span></em>, <em class=\"sig-param\"><span class=\"o\"><span class=\"pre\">**</span></span><span class=\"n\"><span class=\"pre\">kwargs</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Bases: <code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">keras.engine.base_layer.Layer</span></code>, <code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">keras.utils.version_utils.ModelVersionSelector</span></code></p>\n<p><cite>Model</cite> groups layers into an object with training and inference features.</p>\n<dl>\n<dt>Args:</dt><dd><dl class=\"simple\">\n<dt>inputs: The input(s) of the model: a <cite>keras.Input</cite> object or list of</dt><dd><p><cite>keras.Input</cite> objects.</p>\n</dd>\n</dl>\n<p>outputs: The output(s) of the model. See Functional API example below.\nname: String, the name of the model.</p>\n</dd>\n</dl>\n<p>There are two ways to instantiate a <cite>Model</cite>:</p>\n<p>1 - With the \u201cFunctional API\u201d, where you start from <cite>Input</cite>,\nyou chain layer calls to specify the model\u2019s forward pass,\nand finally you create your model from inputs and outputs:</p>\n<p><a href=\"#id9\"><span class=\"problematic\" id=\"id10\">``</span></a><a href=\"#id11\"><span class=\"problematic\" id=\"id12\">`</span></a>python\nimport tensorflow as tf</p>\n<p>inputs = tf.keras.Input(shape=(3,))\nx = tf.keras.layers.Dense(4, activation=tf.nn.relu)(inputs)\noutputs = tf.keras.layers.Dense(5, activation=tf.nn.softmax)(x)\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n<a href=\"#id13\"><span class=\"problematic\" id=\"id14\">``</span></a><a href=\"#id15\"><span class=\"problematic\" id=\"id16\">`</span></a></p>\n<p>Note: Only dicts, lists, and tuples of input tensors are supported. Nested\ninputs are not supported (e.g. lists of list or dicts of dict).</p>\n<p>A new Functional API model can also be created by using the\nintermediate tensors. This enables you to quickly extract sub-components\nof the model.</p>\n<p>Example:</p>\n<p><a href=\"#id17\"><span class=\"problematic\" id=\"id18\">``</span></a><a href=\"#id19\"><span class=\"problematic\" id=\"id20\">`</span></a>python\ninputs = keras.Input(shape=(None, None, 3))\nprocessed = keras.layers.RandomCrop(width=32, height=32)(inputs)\nconv = keras.layers.Conv2D(filters=2, kernel_size=3)(processed)\npooling = keras.layers.GlobalAveragePooling2D()(conv)\nfeature = keras.layers.Dense(10)(pooling)</p>\n<p>full_model = keras.Model(inputs, feature)\nbackbone = keras.Model(processed, conv)\nactivations = keras.Model(conv, feature)\n<a href=\"#id21\"><span class=\"problematic\" id=\"id22\">``</span></a><a href=\"#id23\"><span class=\"problematic\" id=\"id24\">`</span></a></p>\n<p>Note that the <cite>backbone</cite> and <cite>activations</cite> models are not\ncreated with <cite>keras.Input</cite> objects, but with the tensors that are originated\nfrom <cite>keras.Inputs</cite> objects. Under the hood, the layers and weights will\nbe shared across these models, so that user can train the <cite>full_model</cite>, and\nuse <cite>backbone</cite> or <cite>activations</cite> to do feature extraction.\nThe inputs and outputs of the model can be nested structures of tensors as\nwell, and the created models are standard Functional API models that support\nall the existing APIs.</p>\n<p>2 - By subclassing the <cite>Model</cite> class: in that case, you should define your\nlayers in <cite>__init__()</cite> and you should implement the model\u2019s forward pass\nin <cite>call()</cite>.</p>\n<p><a href=\"#id25\"><span class=\"problematic\" id=\"id26\">``</span></a><a href=\"#id27\"><span class=\"problematic\" id=\"id28\">`</span></a>python\nimport tensorflow as tf</p>\n<p>class MyModel(tf.keras.Model):</p>\n<blockquote>\n<div><dl class=\"simple\">\n<dt>def __init__(self):</dt><dd><p>super().__init__()\nself.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)\nself.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)</p>\n</dd>\n<dt>def call(self, inputs):</dt><dd><p>x = self.dense1(inputs)\nreturn self.dense2(x)</p>\n</dd>\n</dl>\n</div></blockquote>\n<p>model = MyModel()\n<a href=\"#id29\"><span class=\"problematic\" id=\"id30\">``</span></a><a href=\"#id31\"><span class=\"problematic\" id=\"id32\">`</span></a></p>\n<p>If you subclass <cite>Model</cite>, you can optionally have\na <cite>training</cite> argument (boolean) in <cite>call()</cite>, which you can use to specify\na different behavior in training and inference:</p>\n<p><a href=\"#id33\"><span class=\"problematic\" id=\"id34\">``</span></a><a href=\"#id35\"><span class=\"problematic\" id=\"id36\">`</span></a>python\nimport tensorflow as tf</p>\n<p>class MyModel(tf.keras.Model):</p>\n<blockquote>\n<div><dl>\n<dt>def __init__(self):</dt><dd><p>super().__init__()\nself.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)\nself.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)\nself.dropout = tf.keras.layers.Dropout(0.5)</p>\n</dd>\n<dt>def call(self, inputs, training=False):</dt><dd><p>x = self.dense1(inputs)\nif training:</p>\n<blockquote>\n<div><p>x = self.dropout(x, training=training)</p>\n</div></blockquote>\n<p>return self.dense2(x)</p>\n</dd>\n</dl>\n</div></blockquote>\n<p>model = MyModel()\n<a href=\"#id37\"><span class=\"problematic\" id=\"id38\">``</span></a><a href=\"#id39\"><span class=\"problematic\" id=\"id40\">`</span></a></p>\n<p>Once the model is created, you can config the model with losses and metrics\nwith <cite>model.compile()</cite>, train the model with <cite>model.fit()</cite>, or use the model\nto do prediction with <cite>model.predict()</cite>.</p>\n<dl class=\"field-list simple\">\n<dt class=\"field-odd\">Attributes</dt>\n<dd class=\"field-odd\"><dl class=\"simple\">\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">activity_regularizer</span></code></dt><dd><p>Optional regularizer function for the output of this layer.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">compute_dtype</span></code></dt><dd><p>The dtype of the layer\u2019s computations.</p>\n</dd>\n<dt><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.distribute_strategy\" title=\"dipy.nn.histo_resdnn.Model.distribute_strategy\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">distribute_strategy</span></code></a></dt><dd><p>The <cite>tf.distribute.Strategy</cite> this model was created under.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">dtype</span></code></dt><dd><p>The dtype of the layer weights.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">dtype_policy</span></code></dt><dd><p>The dtype policy associated with this layer.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">dynamic</span></code></dt><dd><p>Whether the layer is dynamic (eager-only); set in the constructor.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">inbound_nodes</span></code></dt><dd><p>Deprecated, do NOT use! Only for compatibility with external Keras.</p>\n</dd>\n<dt><a class=\"reference external\" href=\"https://docs.python.org/3/library/functions.html#input\" title=\"(in Python v3.10)\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">input</span></code></a></dt><dd><p>Retrieves the input tensor(s) of a layer.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">input_mask</span></code></dt><dd><p>Retrieves the input mask tensor(s) of a layer.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">input_shape</span></code></dt><dd><p>Retrieves the input shape(s) of a layer.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">input_spec</span></code></dt><dd><p><cite>InputSpec</cite> instance(s) describing the input format for this layer.</p>\n</dd>\n<dt><strong>layers</strong></dt><dd></dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">losses</span></code></dt><dd><p>List of losses added using the <cite>add_loss()</cite> API.</p>\n</dd>\n<dt><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.metrics\" title=\"dipy.nn.histo_resdnn.Model.metrics\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">metrics</span></code></a></dt><dd><p>Returns the model\u2019s metrics added using <cite>compile()</cite>, <cite>add_metric()</cite> APIs.</p>\n</dd>\n<dt><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.metrics_names\" title=\"dipy.nn.histo_resdnn.Model.metrics_names\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">metrics_names</span></code></a></dt><dd><p>Returns the model\u2019s display labels for all outputs.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">name</span></code></dt><dd><p>Name of the layer (string), set in the constructor.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">name_scope</span></code></dt><dd><p>Returns a <cite>tf.name_scope</cite> instance for this class.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">non_trainable_variables</span></code></dt><dd><p>Sequence of non-trainable variables owned by this module and its submodules.</p>\n</dd>\n<dt><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.non_trainable_weights\" title=\"dipy.nn.histo_resdnn.Model.non_trainable_weights\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">non_trainable_weights</span></code></a></dt><dd><p>List of all non-trainable weights tracked by this layer.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">outbound_nodes</span></code></dt><dd><p>Deprecated, do NOT use! Only for compatibility with external Keras.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">output</span></code></dt><dd><p>Retrieves the output tensor(s) of a layer.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">output_mask</span></code></dt><dd><p>Retrieves the output mask tensor(s) of a layer.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">output_shape</span></code></dt><dd><p>Retrieves the output shape(s) of a layer.</p>\n</dd>\n<dt><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.run_eagerly\" title=\"dipy.nn.histo_resdnn.Model.run_eagerly\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">run_eagerly</span></code></a></dt><dd><p>Settable attribute indicating whether the model should run eagerly.</p>\n</dd>\n<dt><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.state_updates\" title=\"dipy.nn.histo_resdnn.Model.state_updates\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">state_updates</span></code></a></dt><dd><p>Deprecated, do NOT use!</p>\n</dd>\n<dt><strong>stateful</strong></dt><dd></dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">submodules</span></code></dt><dd><p>Sequence of all sub-modules.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">supports_masking</span></code></dt><dd><p>Whether this layer supports computing a mask using <cite>compute_mask</cite>.</p>\n</dd>\n<dt><strong>trainable</strong></dt><dd></dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">trainable_variables</span></code></dt><dd><p>Sequence of trainable variables owned by this module and its submodules.</p>\n</dd>\n<dt><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.trainable_weights\" title=\"dipy.nn.histo_resdnn.Model.trainable_weights\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">trainable_weights</span></code></a></dt><dd><p>List of all trainable weights tracked by this layer.</p>\n</dd>\n<dt><strong>updates</strong></dt><dd></dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">variable_dtype</span></code></dt><dd><p>Alias of <cite>Layer.dtype</cite>, the dtype of the weights.</p>\n</dd>\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">variables</span></code></dt><dd><p>Returns the list of all layer variables/weights.</p>\n</dd>\n<dt><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.weights\" title=\"dipy.nn.histo_resdnn.Model.weights\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">weights</span></code></a></dt><dd><p>Returns the list of all layer variables/weights.</p>\n</dd>\n</dl>\n</dd>\n</dl>\n<p class=\"rubric\">Methods</p>\n<table class=\"longtable docutils align-default\">\n<colgroup>\n<col style=\"width: 10%\" />\n<col style=\"width: 90%\" />\n</colgroup>\n<tbody>\n<tr class=\"row-odd\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">__call__</span></code>(*args,\u00a0**kwargs)</p></td>\n<td><p>Wraps <cite>call</cite>, applying pre- and post-processing steps.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">add_loss</span></code>(losses,\u00a0**kwargs)</p></td>\n<td><p>Add loss tensor(s), potentially dependent on layer inputs.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">add_metric</span></code>(value[,\u00a0name])</p></td>\n<td><p>Adds metric tensor to the layer.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">add_update</span></code>(updates[,\u00a0inputs])</p></td>\n<td><p>Add update op(s), potentially dependent on layer inputs.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">add_variable</span></code>(*args,\u00a0**kwargs)</p></td>\n<td><p>Deprecated, do NOT use! Alias for <cite>add_weight</cite>.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">add_weight</span></code>([name,\u00a0shape,\u00a0dtype,\u00a0...])</p></td>\n<td><p>Adds a new variable to the layer.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">apply</span></code>(inputs,\u00a0*args,\u00a0**kwargs)</p></td>\n<td><p>Deprecated, do NOT use!</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.build\" title=\"dipy.nn.histo_resdnn.Model.build\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">build</span></code></a>(input_shape)</p></td>\n<td><p>Builds the model based on input shapes received.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.call\" title=\"dipy.nn.histo_resdnn.Model.call\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">call</span></code></a>(inputs[,\u00a0training,\u00a0mask])</p></td>\n<td><p>Calls the model on new inputs and returns the outputs as tensors.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.compile\" title=\"dipy.nn.histo_resdnn.Model.compile\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">compile</span></code></a>([optimizer,\u00a0loss,\u00a0metrics,\u00a0...])</p></td>\n<td><p>Configures the model for training.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.compute_loss\" title=\"dipy.nn.histo_resdnn.Model.compute_loss\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">compute_loss</span></code></a>([x,\u00a0y,\u00a0y_pred,\u00a0sample_weight])</p></td>\n<td><p>Compute the total loss, validate it, and return it.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">compute_mask</span></code>(inputs[,\u00a0mask])</p></td>\n<td><p>Computes an output mask tensor.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.compute_metrics\" title=\"dipy.nn.histo_resdnn.Model.compute_metrics\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">compute_metrics</span></code></a>(x,\u00a0y,\u00a0y_pred,\u00a0sample_weight)</p></td>\n<td><p>Update metric states and collect all metrics to be returned.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">compute_output_shape</span></code>(input_shape)</p></td>\n<td><p>Computes the output shape of the layer.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">compute_output_signature</span></code>(input_signature)</p></td>\n<td><p>Compute the output tensor signature of the layer based on the inputs.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">count_params</span></code>()</p></td>\n<td><p>Count the total number of scalars composing the weights.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.evaluate\" title=\"dipy.nn.histo_resdnn.Model.evaluate\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">evaluate</span></code></a>([x,\u00a0y,\u00a0batch_size,\u00a0verbose,\u00a0...])</p></td>\n<td><p>Returns the loss value &amp; metrics values for the model in test mode.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.evaluate_generator\" title=\"dipy.nn.histo_resdnn.Model.evaluate_generator\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">evaluate_generator</span></code></a>(generator[,\u00a0steps,\u00a0...])</p></td>\n<td><p>Evaluates the model on a data generator.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">finalize_state</span></code>()</p></td>\n<td><p>Finalizes the layers state after updating layer weights.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.fit\" title=\"dipy.nn.histo_resdnn.Model.fit\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">fit</span></code></a>([x,\u00a0y,\u00a0batch_size,\u00a0epochs,\u00a0verbose,\u00a0...])</p></td>\n<td><p>Trains the model for a fixed number of epochs (iterations on a dataset).</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.fit_generator\" title=\"dipy.nn.histo_resdnn.Model.fit_generator\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">fit_generator</span></code></a>(generator[,\u00a0steps_per_epoch,\u00a0...])</p></td>\n<td><p>Fits the model on data yielded batch-by-batch by a Python generator.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.from_config\" title=\"dipy.nn.histo_resdnn.Model.from_config\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">from_config</span></code></a>(config[,\u00a0custom_objects])</p></td>\n<td><p>Creates a layer from its config.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.get_config\" title=\"dipy.nn.histo_resdnn.Model.get_config\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">get_config</span></code></a>()</p></td>\n<td><p>Returns the config of the layer.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">get_input_at</span></code>(node_index)</p></td>\n<td><p>Retrieves the input tensor(s) of a layer at a given node.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">get_input_mask_at</span></code>(node_index)</p></td>\n<td><p>Retrieves the input mask tensor(s) of a layer at a given node.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">get_input_shape_at</span></code>(node_index)</p></td>\n<td><p>Retrieves the input shape(s) of a layer at a given node.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.get_layer\" title=\"dipy.nn.histo_resdnn.Model.get_layer\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">get_layer</span></code></a>([name,\u00a0index])</p></td>\n<td><p>Retrieves a layer based on either its name (unique) or index.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">get_losses_for</span></code>(inputs)</p></td>\n<td><p>Deprecated, do NOT use!</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">get_output_at</span></code>(node_index)</p></td>\n<td><p>Retrieves the output tensor(s) of a layer at a given node.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">get_output_mask_at</span></code>(node_index)</p></td>\n<td><p>Retrieves the output mask tensor(s) of a layer at a given node.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">get_output_shape_at</span></code>(node_index)</p></td>\n<td><p>Retrieves the output shape(s) of a layer at a given node.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">get_updates_for</span></code>(inputs)</p></td>\n<td><p>Deprecated, do NOT use!</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.get_weights\" title=\"dipy.nn.histo_resdnn.Model.get_weights\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">get_weights</span></code></a>()</p></td>\n<td><p>Retrieves the weights of the model.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.load_weights\" title=\"dipy.nn.histo_resdnn.Model.load_weights\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">load_weights</span></code></a>(filepath[,\u00a0by_name,\u00a0...])</p></td>\n<td><p>Loads all layer weights, either from a TensorFlow or an HDF5 weight file.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.make_predict_function\" title=\"dipy.nn.histo_resdnn.Model.make_predict_function\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">make_predict_function</span></code></a>([force])</p></td>\n<td><p>Creates a function that executes one step of inference.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.make_test_function\" title=\"dipy.nn.histo_resdnn.Model.make_test_function\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">make_test_function</span></code></a>([force])</p></td>\n<td><p>Creates a function that executes one step of evaluation.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.make_train_function\" title=\"dipy.nn.histo_resdnn.Model.make_train_function\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">make_train_function</span></code></a>([force])</p></td>\n<td><p>Creates a function that executes one step of training.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.predict\" title=\"dipy.nn.histo_resdnn.Model.predict\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">predict</span></code></a>(x[,\u00a0batch_size,\u00a0verbose,\u00a0steps,\u00a0...])</p></td>\n<td><p>Generates output predictions for the input samples.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.predict_generator\" title=\"dipy.nn.histo_resdnn.Model.predict_generator\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">predict_generator</span></code></a>(generator[,\u00a0steps,\u00a0...])</p></td>\n<td><p>Generates predictions for the input samples from a data generator.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.predict_on_batch\" title=\"dipy.nn.histo_resdnn.Model.predict_on_batch\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">predict_on_batch</span></code></a>(x)</p></td>\n<td><p>Returns predictions for a single batch of samples.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.predict_step\" title=\"dipy.nn.histo_resdnn.Model.predict_step\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">predict_step</span></code></a>(data)</p></td>\n<td><p>The logic for one inference step.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.reset_metrics\" title=\"dipy.nn.histo_resdnn.Model.reset_metrics\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">reset_metrics</span></code></a>()</p></td>\n<td><p>Resets the state of all the metrics in the model.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.save\" title=\"dipy.nn.histo_resdnn.Model.save\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">save</span></code></a>(filepath[,\u00a0overwrite,\u00a0...])</p></td>\n<td><p>Saves the model to Tensorflow SavedModel or a single HDF5 file.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.save_spec\" title=\"dipy.nn.histo_resdnn.Model.save_spec\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">save_spec</span></code></a>([dynamic_batch])</p></td>\n<td><p>Returns the <cite>tf.TensorSpec</cite> of call inputs as a tuple <cite>(args, kwargs)</cite>.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.save_weights\" title=\"dipy.nn.histo_resdnn.Model.save_weights\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">save_weights</span></code></a>(filepath[,\u00a0overwrite,\u00a0...])</p></td>\n<td><p>Saves all layer weights.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">set_weights</span></code>(weights)</p></td>\n<td><p>Sets the weights of the layer, from NumPy arrays.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.summary\" title=\"dipy.nn.histo_resdnn.Model.summary\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">summary</span></code></a>([line_length,\u00a0positions,\u00a0print_fn,\u00a0...])</p></td>\n<td><p>Prints a string summary of the network.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.test_on_batch\" title=\"dipy.nn.histo_resdnn.Model.test_on_batch\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">test_on_batch</span></code></a>(x[,\u00a0y,\u00a0sample_weight,\u00a0...])</p></td>\n<td><p>Test the model on a single batch of samples.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.test_step\" title=\"dipy.nn.histo_resdnn.Model.test_step\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">test_step</span></code></a>(data)</p></td>\n<td><p>The logic for one evaluation step.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.to_json\" title=\"dipy.nn.histo_resdnn.Model.to_json\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">to_json</span></code></a>(**kwargs)</p></td>\n<td><p>Returns a JSON string containing the network configuration.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.to_yaml\" title=\"dipy.nn.histo_resdnn.Model.to_yaml\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">to_yaml</span></code></a>(**kwargs)</p></td>\n<td><p>Returns a yaml string containing the network configuration.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.train_on_batch\" title=\"dipy.nn.histo_resdnn.Model.train_on_batch\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">train_on_batch</span></code></a>(x[,\u00a0y,\u00a0sample_weight,\u00a0...])</p></td>\n<td><p>Runs a single gradient update on a single batch of data.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Model.train_step\" title=\"dipy.nn.histo_resdnn.Model.train_step\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">train_step</span></code></a>(data)</p></td>\n<td><p>The logic for one training step.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">with_name_scope</span></code>(method)</p></td>\n<td><p>Decorator to automatically enter the module name scope.</p></td>\n</tr>\n</tbody>\n</table>\n<table class=\"docutils align-default\">\n<colgroup>\n<col style=\"width: 62%\" />\n<col style=\"width: 38%\" />\n</colgroup>\n<tbody>\n<tr class=\"row-odd\"><td><p><strong>reset_states</strong></p></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.__init__\">\n<span class=\"sig-name descname\"><span class=\"pre\">__init__</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"o\"><span class=\"pre\">*</span></span><span class=\"n\"><span class=\"pre\">args</span></span></em>, <em class=\"sig-param\"><span class=\"o\"><span class=\"pre\">**</span></span><span class=\"n\"><span class=\"pre\">kwargs</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.__init__\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.build\">\n<span class=\"sig-name descname\"><span class=\"pre\">build</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">input_shape</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.build\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Builds the model based on input shapes received.</p>\n<p>This is to be used for subclassed models, which do not know at instantiation\ntime what their inputs look like.</p>\n<p>This method only exists for users who want to call <cite>model.build()</cite> in a\nstandalone way (as a substitute for calling the model on real data to\nbuild it). It will never be called by the framework (and thus it will\nnever throw unexpected errors in an unrelated workflow).</p>\n<dl>\n<dt>Args:</dt><dd><dl class=\"simple\">\n<dt>input_shape: Single tuple, <cite>TensorShape</cite> instance, or list/dict of shapes,</dt><dd><p>where shapes are tuples, integers, or <cite>TensorShape</cite> instances.</p>\n</dd>\n</dl>\n</dd>\n<dt>Raises:</dt><dd><dl class=\"simple\">\n<dt>ValueError:</dt><dd><ol class=\"arabic simple\">\n<li><p>In case of invalid user-provided data (not of type tuple,\nlist, <cite>TensorShape</cite>, or dict).</p></li>\n<li><p>If the model requires call arguments that are agnostic\nto the input shapes (positional or keyword arg in call signature).</p></li>\n<li><p>If not all layers were properly built.</p></li>\n<li><p>If float type inputs are not supported within the layers.</p></li>\n</ol>\n</dd>\n</dl>\n<p>In each of these cases, the user should build their model by calling it\non real tensor data.</p>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.call\">\n<span class=\"sig-name descname\"><span class=\"pre\">call</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">inputs</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">training</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">mask</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.call\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Calls the model on new inputs and returns the outputs as tensors.</p>\n<p>In this case <cite>call()</cite> just reapplies\nall ops in the graph to the new inputs\n(e.g. build a new computational graph from the provided inputs).</p>\n<p>Note: This method should not be called directly. It is only meant to be\noverridden when subclassing <cite>tf.keras.Model</cite>.\nTo call a model on an input, always use the <cite>__call__()</cite> method,\ni.e. <cite>model(inputs)</cite>, which relies on the underlying <cite>call()</cite> method.</p>\n<dl>\n<dt>Args:</dt><dd><p>inputs: Input tensor, or dict/list/tuple of input tensors.\ntraining: Boolean or boolean scalar tensor, indicating whether to run</p>\n<blockquote>\n<div><p>the <cite>Network</cite> in training mode or inference mode.</p>\n</div></blockquote>\n<dl class=\"simple\">\n<dt>mask: A mask or list of masks. A mask can be either a boolean tensor or</dt><dd><dl class=\"simple\">\n<dt>None (no mask). For more details, check the guide</dt><dd><p>[here](<a class=\"reference external\" href=\"https://www.tensorflow.org/guide/keras/masking_and_padding\">https://www.tensorflow.org/guide/keras/masking_and_padding</a>).</p>\n</dd>\n</dl>\n</dd>\n</dl>\n</dd>\n<dt>Returns:</dt><dd><p>A tensor if there is a single output, or\na list of tensors if there are more than one outputs.</p>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.compile\">\n<span class=\"sig-name descname\"><span class=\"pre\">compile</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">optimizer</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'rmsprop'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">loss</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">metrics</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">loss_weights</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">weighted_metrics</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">run_eagerly</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">steps_per_execution</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">jit_compile</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"o\"><span class=\"pre\">**</span></span><span class=\"n\"><span class=\"pre\">kwargs</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.compile\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Configures the model for training.</p>\n<p>Example:</p>\n<p><a href=\"#id41\"><span class=\"problematic\" id=\"id42\">``</span></a><a href=\"#id43\"><span class=\"problematic\" id=\"id44\">`</span></a>python\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),</p>\n<blockquote>\n<div><p>loss=tf.keras.losses.BinaryCrossentropy(),\nmetrics=[tf.keras.metrics.BinaryAccuracy(),</p>\n<blockquote>\n<div><p>tf.keras.metrics.FalseNegatives()])</p>\n</div></blockquote>\n</div></blockquote>\n<p><a href=\"#id45\"><span class=\"problematic\" id=\"id46\">``</span></a><a href=\"#id47\"><span class=\"problematic\" id=\"id48\">`</span></a></p>\n<dl>\n<dt>Args:</dt><dd><dl>\n<dt>optimizer: String (name of optimizer) or optimizer instance. See</dt><dd><p><cite>tf.keras.optimizers</cite>.</p>\n</dd>\n<dt>loss: Loss function. Maybe be a string (name of loss function), or</dt><dd><p>a <cite>tf.keras.losses.Loss</cite> instance. See <cite>tf.keras.losses</cite>. A loss\nfunction is any callable with the signature <cite>loss = fn(y_true,\ny_pred)</cite>, where <cite>y_true</cite> are the ground truth values, and\n<cite>y_pred</cite> are the model\u2019s predictions.\n<cite>y_true</cite> should have shape\n<cite>(batch_size, d0, .. dN)</cite> (except in the case of\nsparse loss functions such as\nsparse categorical crossentropy which expects integer arrays of shape\n<cite>(batch_size, d0, .. dN-1)</cite>).\n<cite>y_pred</cite> should have shape <cite>(batch_size, d0, .. dN)</cite>.\nThe loss function should return a float tensor.\nIf a custom <cite>Loss</cite> instance is\nused and reduction is set to <cite>None</cite>, return value has shape\n<cite>(batch_size, d0, .. dN-1)</cite> i.e. per-sample or per-timestep loss\nvalues; otherwise, it is a scalar. If the model has multiple outputs,\nyou can use a different loss on each output by passing a dictionary\nor a list of losses. The loss value that will be minimized by the\nmodel will then be the sum of all individual losses, unless\n<cite>loss_weights</cite> is specified.</p>\n</dd>\n<dt>metrics: List of metrics to be evaluated by the model during training</dt><dd><p>and testing. Each of this can be a string (name of a built-in\nfunction), function or a <cite>tf.keras.metrics.Metric</cite> instance. See\n<cite>tf.keras.metrics</cite>. Typically you will use <cite>metrics=[\u2018accuracy\u2019]</cite>. A\nfunction is any callable with the signature <cite>result = fn(y_true,\ny_pred)</cite>. To specify different metrics for different outputs of a\nmulti-output model, you could also pass a dictionary, such as\n<cite>metrics={\u2018output_a\u2019: \u2018accuracy\u2019, \u2018output_b\u2019: [\u2018accuracy\u2019, \u2018mse\u2019]}</cite>.\nYou can also pass a list to specify a metric or a list of metrics\nfor each output, such as <cite>metrics=[[\u2018accuracy\u2019], [\u2018accuracy\u2019, \u2018mse\u2019]]</cite>\nor <cite>metrics=[\u2018accuracy\u2019, [\u2018accuracy\u2019, \u2018mse\u2019]]</cite>. When you pass the\nstrings \u2018accuracy\u2019 or \u2018acc\u2019, we convert this to one of\n<cite>tf.keras.metrics.BinaryAccuracy</cite>,\n<cite>tf.keras.metrics.CategoricalAccuracy</cite>,\n<cite>tf.keras.metrics.SparseCategoricalAccuracy</cite> based on the loss\nfunction used and the model output shape. We do a similar\nconversion for the strings \u2018crossentropy\u2019 and \u2018ce\u2019 as well.</p>\n</dd>\n<dt>loss_weights: Optional list or dictionary specifying scalar coefficients</dt><dd><p>(Python floats) to weight the loss contributions of different model\noutputs. The loss value that will be minimized by the model will then\nbe the <em>weighted sum</em> of all individual losses, weighted by the\n<cite>loss_weights</cite> coefficients.</p>\n<blockquote>\n<div><dl class=\"simple\">\n<dt>If a list, it is expected to have a 1:1 mapping to the model\u2019s</dt><dd><p>outputs. If a dict, it is expected to map output names (strings)\nto scalar coefficients.</p>\n</dd>\n</dl>\n</div></blockquote>\n</dd>\n<dt>weighted_metrics: List of metrics to be evaluated and weighted by</dt><dd><p><cite>sample_weight</cite> or <cite>class_weight</cite> during training and testing.</p>\n</dd>\n<dt>run_eagerly: Bool. Defaults to <cite>False</cite>. If <cite>True</cite>, this <cite>Model</cite>\u2019s</dt><dd><p>logic will not be wrapped in a <cite>tf.function</cite>. Recommended to leave\nthis as <cite>None</cite> unless your <cite>Model</cite> cannot be run inside a\n<cite>tf.function</cite>. <cite>run_eagerly=True</cite> is not supported when using\n<cite>tf.distribute.experimental.ParameterServerStrategy</cite>.</p>\n</dd>\n<dt>steps_per_execution: Int. Defaults to 1. The number of batches to run</dt><dd><p>during each <cite>tf.function</cite> call. Running multiple batches inside a\nsingle <cite>tf.function</cite> call can greatly improve performance on TPUs or\nsmall models with a large Python overhead. At most, one full epoch\nwill be run each execution. If a number larger than the size of the\nepoch is passed, the execution will be truncated to the size of the\nepoch. Note that if <cite>steps_per_execution</cite> is set to <cite>N</cite>,\n<cite>Callback.on_batch_begin</cite> and <cite>Callback.on_batch_end</cite> methods will\nonly be called every <cite>N</cite> batches (i.e. before/after each <cite>tf.function</cite>\nexecution).</p>\n</dd>\n<dt>jit_compile: If <cite>True</cite>, compile the model training step with XLA.</dt><dd><p>[XLA](<a class=\"reference external\" href=\"https://www.tensorflow.org/xla\">https://www.tensorflow.org/xla</a>) is an optimizing compiler for\nmachine learning.\n<cite>jit_compile</cite> is not enabled for by default.\nThis option cannot be enabled with <cite>run_eagerly=True</cite>.\nNote that <cite>jit_compile=True</cite> is\nmay not necessarily work for all models.\nFor more information on supported operations please refer to the\n[XLA documentation](<a class=\"reference external\" href=\"https://www.tensorflow.org/xla\">https://www.tensorflow.org/xla</a>).\nAlso refer to\n[known XLA issues](<a class=\"reference external\" href=\"https://www.tensorflow.org/xla/known_issues\">https://www.tensorflow.org/xla/known_issues</a>) for\nmore details.</p>\n</dd>\n</dl>\n<p><a href=\"#id49\"><span class=\"problematic\" id=\"id50\">**</span></a>kwargs: Arguments supported for backwards compatibility only.</p>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.compute_loss\">\n<span class=\"sig-name descname\"><span class=\"pre\">compute_loss</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">x</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">y</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">y_pred</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">sample_weight</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.compute_loss\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Compute the total loss, validate it, and return it.</p>\n<p>Subclasses can optionally override this method to provide custom loss\ncomputation logic.</p>\n<p>Example:\n<a href=\"#id51\"><span class=\"problematic\" id=\"id52\">``</span></a><a href=\"#id53\"><span class=\"problematic\" id=\"id54\">`</span></a>python\nclass MyModel(tf.keras.Model):</p>\n<blockquote>\n<div><dl class=\"simple\">\n<dt>def __init__(self, <a href=\"#id55\"><span class=\"problematic\" id=\"id56\">*</span></a>args, <a href=\"#id57\"><span class=\"problematic\" id=\"id58\">**</span></a>kwargs):</dt><dd><p>super(MyModel, self).__init__(<a href=\"#id59\"><span class=\"problematic\" id=\"id60\">*</span></a>args, <a href=\"#id61\"><span class=\"problematic\" id=\"id62\">**</span></a>kwargs)\nself.loss_tracker = tf.keras.metrics.Mean(name=\u2019loss\u2019)</p>\n</dd>\n<dt>def compute_loss(self, x, y, y_pred, sample_weight):</dt><dd><p>loss = tf.reduce_mean(tf.math.squared_difference(y_pred, y))\nloss += tf.add_n(self.losses)\nself.loss_tracker.update_state(loss)\nreturn loss</p>\n</dd>\n<dt>def reset_metrics(self):</dt><dd><p>self.loss_tracker.reset_states()</p>\n</dd>\n</dl>\n<p>&#64;property\ndef metrics(self):</p>\n<blockquote>\n<div><p>return [self.loss_tracker]</p>\n</div></blockquote>\n</div></blockquote>\n<p>tensors = tf.random.uniform((10, 10)), tf.random.uniform((10,))\ndataset = tf.data.Dataset.from_tensor_slices(tensors).repeat().batch(1)</p>\n<p>inputs = tf.keras.layers.Input(shape=(10,), name=\u2019my_input\u2019)\noutputs = tf.keras.layers.Dense(10)(inputs)\nmodel = MyModel(inputs, outputs)\nmodel.add_loss(tf.reduce_sum(outputs))</p>\n<p>optimizer = tf.keras.optimizers.SGD()\nmodel.compile(optimizer, loss=\u2019mse\u2019, steps_per_execution=10)\nmodel.fit(dataset, epochs=2, steps_per_epoch=10)\nprint(\u2018My custom loss: \u2018, model.loss_tracker.result().numpy())\n<a href=\"#id63\"><span class=\"problematic\" id=\"id64\">``</span></a><a href=\"#id65\"><span class=\"problematic\" id=\"id66\">`</span></a></p>\n<dl class=\"simple\">\n<dt>Args:</dt><dd><p>x: Input data.\ny: Target data.\ny_pred: Predictions returned by the model (output of <cite>model(x)</cite>)\nsample_weight: Sample weights for weighting the loss function.</p>\n</dd>\n<dt>Returns:</dt><dd><p>The total loss as a <cite>tf.Tensor</cite>, or <cite>None</cite> if no loss results (which is\nthe case when called by <cite>Model.test_step</cite>).</p>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.compute_metrics\">\n<span class=\"sig-name descname\"><span class=\"pre\">compute_metrics</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">x</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">y</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">y_pred</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">sample_weight</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.compute_metrics\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Update metric states and collect all metrics to be returned.</p>\n<p>Subclasses can optionally override this method to provide custom metric\nupdating and collection logic.</p>\n<p>Example:\n<a href=\"#id67\"><span class=\"problematic\" id=\"id68\">``</span></a><a href=\"#id69\"><span class=\"problematic\" id=\"id70\">`</span></a>python\nclass MyModel(tf.keras.Sequential):</p>\n<blockquote>\n<div><p>def compute_metrics(self, x, y, y_pred, sample_weight):</p>\n<blockquote>\n<div><p># This super call updates <cite>self.compiled_metrics</cite> and returns results\n# for all metrics listed in <cite>self.metrics</cite>.\nmetric_results = super(MyModel, self).compute_metrics(</p>\n<blockquote>\n<div><p>x, y, y_pred, sample_weight)</p>\n</div></blockquote>\n<p># Note that <cite>self.custom_metric</cite> is not listed in <cite>self.metrics</cite>.\nself.custom_metric.update_state(x, y, y_pred, sample_weight)\nmetric_results[\u2018custom_metric_name\u2019] = self.custom_metric.result()\nreturn metric_results</p>\n</div></blockquote>\n</div></blockquote>\n<p><a href=\"#id71\"><span class=\"problematic\" id=\"id72\">``</span></a><a href=\"#id73\"><span class=\"problematic\" id=\"id74\">`</span></a></p>\n<dl class=\"simple\">\n<dt>Args:</dt><dd><p>x: Input data.\ny: Target data.\ny_pred: Predictions returned by the model (output of <cite>model.call(x)</cite>)\nsample_weight: Sample weights for weighting the loss function.</p>\n</dd>\n<dt>Returns:</dt><dd><p>A <cite>dict</cite> containing values that will be passed to\n<cite>tf.keras.callbacks.CallbackList.on_train_batch_end()</cite>. Typically, the\nvalues of the metrics listed in <cite>self.metrics</cite> are returned. Example:\n<cite>{\u2018loss\u2019: 0.2, \u2018accuracy\u2019: 0.7}</cite>.</p>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py property\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.distribute_strategy\">\n<em class=\"property\"><span class=\"pre\">property</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">distribute_strategy</span></span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.distribute_strategy\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>The <cite>tf.distribute.Strategy</cite> this model was created under.</p>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.evaluate\">\n<span class=\"sig-name descname\"><span class=\"pre\">evaluate</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">x</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">y</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">batch_size</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">verbose</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">1</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">sample_weight</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">steps</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">callbacks</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">max_queue_size</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">10</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">workers</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">1</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">use_multiprocessing</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">return_dict</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em>, <em class=\"sig-param\"><span class=\"o\"><span class=\"pre\">**</span></span><span class=\"n\"><span class=\"pre\">kwargs</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.evaluate\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Returns the loss value &amp; metrics values for the model in test mode.</p>\n<p>Computation is done in batches (see the <cite>batch_size</cite> arg.)</p>\n<dl>\n<dt>Args:</dt><dd><dl>\n<dt>x: Input data. It could be:</dt><dd><ul class=\"simple\">\n<li><p>A Numpy array (or array-like), or a list of arrays\n(in case the model has multiple inputs).</p></li>\n<li><p>A TensorFlow tensor, or a list of tensors\n(in case the model has multiple inputs).</p></li>\n<li><p>A dict mapping input names to the corresponding array/tensors,\nif the model has named inputs.</p></li>\n<li><p>A <cite>tf.data</cite> dataset. Should return a tuple\nof either <cite>(inputs, targets)</cite> or\n<cite>(inputs, targets, sample_weights)</cite>.</p></li>\n<li><p>A generator or <cite>keras.utils.Sequence</cite> returning <cite>(inputs, targets)</cite>\nor <cite>(inputs, targets, sample_weights)</cite>.</p></li>\n</ul>\n<p>A more detailed description of unpacking behavior for iterator types\n(Dataset, generator, Sequence) is given in the <cite>Unpacking behavior\nfor iterator-like inputs</cite> section of <cite>Model.fit</cite>.</p>\n</dd>\n<dt>y: Target data. Like the input data <cite>x</cite>, it could be either Numpy</dt><dd><p>array(s) or TensorFlow tensor(s). It should be consistent with <cite>x</cite>\n(you cannot have Numpy inputs and tensor targets, or inversely). If\n<cite>x</cite> is a dataset, generator or <cite>keras.utils.Sequence</cite> instance, <cite>y</cite>\nshould not be specified (since targets will be obtained from the\niterator/dataset).</p>\n</dd>\n<dt>batch_size: Integer or <cite>None</cite>. Number of samples per batch of</dt><dd><p>computation. If unspecified, <cite>batch_size</cite> will default to 32. Do not\nspecify the <cite>batch_size</cite> if your data is in the form of a dataset,\ngenerators, or <cite>keras.utils.Sequence</cite> instances (since they generate\nbatches).</p>\n</dd>\n</dl>\n<p>verbose: 0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.\nsample_weight: Optional Numpy array of weights for the test samples,</p>\n<blockquote>\n<div><p>used for weighting the loss function. You can either pass a flat (1D)\nNumpy array with the same length as the input samples</p>\n<blockquote>\n<div><dl class=\"simple\">\n<dt>(1:1 mapping between weights and samples), or in the case of</dt><dd><p>temporal data, you can pass a 2D array with shape <cite>(samples,\nsequence_length)</cite>, to apply a different weight to every timestep\nof every sample. This argument is not supported when <cite>x</cite> is a\ndataset, instead pass sample weights as the third element of <cite>x</cite>.</p>\n</dd>\n</dl>\n</div></blockquote>\n</div></blockquote>\n<dl class=\"simple\">\n<dt>steps: Integer or <cite>None</cite>. Total number of steps (batches of samples)</dt><dd><p>before declaring the evaluation round finished. Ignored with the\ndefault value of <cite>None</cite>. If x is a <cite>tf.data</cite> dataset and <cite>steps</cite> is\nNone, \u2018evaluate\u2019 will run until the dataset is exhausted. This\nargument is not supported with array inputs.</p>\n</dd>\n<dt>callbacks: List of <cite>keras.callbacks.Callback</cite> instances. List of</dt><dd><p>callbacks to apply during evaluation. See\n[callbacks](/api_docs/python/tf/keras/callbacks).</p>\n</dd>\n<dt>max_queue_size: Integer. Used for generator or <cite>keras.utils.Sequence</cite></dt><dd><p>input only. Maximum size for the generator queue. If unspecified,\n<cite>max_queue_size</cite> will default to 10.</p>\n</dd>\n<dt>workers: Integer. Used for generator or <cite>keras.utils.Sequence</cite> input</dt><dd><p>only. Maximum number of processes to spin up when using process-based\nthreading. If unspecified, <cite>workers</cite> will default to 1.</p>\n</dd>\n<dt>use_multiprocessing: Boolean. Used for generator or</dt><dd><p><cite>keras.utils.Sequence</cite> input only. If <cite>True</cite>, use process-based\nthreading. If unspecified, <cite>use_multiprocessing</cite> will default to\n<cite>False</cite>. Note that because this implementation relies on\nmultiprocessing, you should not pass non-picklable arguments to the\ngenerator as they can\u2019t be passed easily to children processes.</p>\n</dd>\n<dt>return_dict: If <cite>True</cite>, loss and metric results are returned as a dict,</dt><dd><p>with each key being the name of the metric. If <cite>False</cite>, they are\nreturned as a list.</p>\n</dd>\n</dl>\n<p><a href=\"#id75\"><span class=\"problematic\" id=\"id76\">**</span></a>kwargs: Unused at this time.</p>\n</dd>\n</dl>\n<p>See the discussion of <cite>Unpacking behavior for iterator-like inputs</cite> for\n<cite>Model.fit</cite>.</p>\n<dl class=\"simple\">\n<dt>Returns:</dt><dd><p>Scalar test loss (if the model has a single output and no metrics)\nor list of scalars (if the model has multiple outputs\nand/or metrics). The attribute <cite>model.metrics_names</cite> will give you\nthe display labels for the scalar outputs.</p>\n</dd>\n<dt>Raises:</dt><dd><p>RuntimeError: If <cite>model.evaluate</cite> is wrapped in a <cite>tf.function</cite>.</p>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.evaluate_generator\">\n<span class=\"sig-name descname\"><span class=\"pre\">evaluate_generator</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">generator</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">steps</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">callbacks</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">max_queue_size</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">10</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">workers</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">1</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">use_multiprocessing</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">verbose</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">0</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.evaluate_generator\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Evaluates the model on a data generator.</p>\n<dl class=\"simple\">\n<dt>DEPRECATED:</dt><dd><p><cite>Model.evaluate</cite> now supports generators, so there is no longer any need\nto use this endpoint.</p>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.fit\">\n<span class=\"sig-name descname\"><span class=\"pre\">fit</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">x</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">y</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">batch_size</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">epochs</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">1</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">verbose</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'auto'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">callbacks</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">validation_split</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">0.0</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">validation_data</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">shuffle</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">True</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">class_weight</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">sample_weight</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">initial_epoch</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">0</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">steps_per_epoch</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">validation_steps</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">validation_batch_size</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">validation_freq</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">1</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">max_queue_size</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">10</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">workers</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">1</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">use_multiprocessing</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.fit\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Trains the model for a fixed number of epochs (iterations on a dataset).</p>\n<dl>\n<dt>Args:</dt><dd><dl>\n<dt>x: Input data. It could be:</dt><dd><ul class=\"simple\">\n<li><p>A Numpy array (or array-like), or a list of arrays\n(in case the model has multiple inputs).</p></li>\n<li><p>A TensorFlow tensor, or a list of tensors\n(in case the model has multiple inputs).</p></li>\n<li><p>A dict mapping input names to the corresponding array/tensors,\nif the model has named inputs.</p></li>\n<li><p>A <cite>tf.data</cite> dataset. Should return a tuple\nof either <cite>(inputs, targets)</cite> or\n<cite>(inputs, targets, sample_weights)</cite>.</p></li>\n<li><p>A generator or <cite>keras.utils.Sequence</cite> returning <cite>(inputs, targets)</cite>\nor <cite>(inputs, targets, sample_weights)</cite>.</p></li>\n<li><p>A <cite>tf.keras.utils.experimental.DatasetCreator</cite>, which wraps a\ncallable that takes a single argument of type\n<cite>tf.distribute.InputContext</cite>, and returns a <cite>tf.data.Dataset</cite>.\n<cite>DatasetCreator</cite> should be used when users prefer to specify the\nper-replica batching and sharding logic for the <cite>Dataset</cite>.\nSee <cite>tf.keras.utils.experimental.DatasetCreator</cite> doc for more\ninformation.</p></li>\n</ul>\n<p>A more detailed description of unpacking behavior for iterator types\n(Dataset, generator, Sequence) is given below. If using\n<cite>tf.distribute.experimental.ParameterServerStrategy</cite>, only\n<cite>DatasetCreator</cite> type is supported for <cite>x</cite>.</p>\n</dd>\n<dt>y: Target data. Like the input data <cite>x</cite>,</dt><dd><p>it could be either Numpy array(s) or TensorFlow tensor(s).\nIt should be consistent with <cite>x</cite> (you cannot have Numpy inputs and\ntensor targets, or inversely). If <cite>x</cite> is a dataset, generator,\nor <cite>keras.utils.Sequence</cite> instance, <cite>y</cite> should\nnot be specified (since targets will be obtained from <cite>x</cite>).</p>\n</dd>\n<dt>batch_size: Integer or <cite>None</cite>.</dt><dd><p>Number of samples per gradient update.\nIf unspecified, <cite>batch_size</cite> will default to 32.\nDo not specify the <cite>batch_size</cite> if your data is in the\nform of datasets, generators, or <cite>keras.utils.Sequence</cite> instances\n(since they generate batches).</p>\n</dd>\n<dt>epochs: Integer. Number of epochs to train the model.</dt><dd><p>An epoch is an iteration over the entire <cite>x</cite> and <cite>y</cite>\ndata provided\n(unless the <cite>steps_per_epoch</cite> flag is set to\nsomething other than None).\nNote that in conjunction with <cite>initial_epoch</cite>,\n<cite>epochs</cite> is to be understood as \u201cfinal epoch\u201d.\nThe model is not trained for a number of iterations\ngiven by <cite>epochs</cite>, but merely until the epoch\nof index <cite>epochs</cite> is reached.</p>\n</dd>\n<dt>verbose: \u2018auto\u2019, 0, 1, or 2. Verbosity mode.</dt><dd><p>0 = silent, 1 = progress bar, 2 = one line per epoch.\n\u2018auto\u2019 defaults to 1 for most cases, but 2 when used with\n<cite>ParameterServerStrategy</cite>. Note that the progress bar is not\nparticularly useful when logged to a file, so verbose=2 is\nrecommended when not running interactively (eg, in a production\nenvironment).</p>\n</dd>\n<dt>callbacks: List of <cite>keras.callbacks.Callback</cite> instances.</dt><dd><p>List of callbacks to apply during training.\nSee <cite>tf.keras.callbacks</cite>. Note <cite>tf.keras.callbacks.ProgbarLogger</cite>\nand <cite>tf.keras.callbacks.History</cite> callbacks are created automatically\nand need not be passed into <cite>model.fit</cite>.\n<cite>tf.keras.callbacks.ProgbarLogger</cite> is created or not based on\n<cite>verbose</cite> argument to <cite>model.fit</cite>.\nCallbacks with batch-level calls are currently unsupported with\n<cite>tf.distribute.experimental.ParameterServerStrategy</cite>, and users are\nadvised to implement epoch-level calls instead with an appropriate\n<cite>steps_per_epoch</cite> value.</p>\n</dd>\n<dt>validation_split: Float between 0 and 1.</dt><dd><blockquote>\n<div><p>Fraction of the training data to be used as validation data.\nThe model will set apart this fraction of the training data,\nwill not train on it, and will evaluate\nthe loss and any model metrics\non this data at the end of each epoch.\nThe validation data is selected from the last samples\nin the <cite>x</cite> and <cite>y</cite> data provided, before shuffling. This argument is\nnot supported when <cite>x</cite> is a dataset, generator or</p>\n</div></blockquote>\n<dl class=\"simple\">\n<dt><cite>keras.utils.Sequence</cite> instance.</dt><dd><p><cite>validation_split</cite> is not yet supported with\n<cite>tf.distribute.experimental.ParameterServerStrategy</cite>.</p>\n</dd>\n</dl>\n</dd>\n<dt>validation_data: Data on which to evaluate</dt><dd><p>the loss and any model metrics at the end of each epoch.\nThe model will not be trained on this data. Thus, note the fact\nthat the validation loss of data provided using <cite>validation_split</cite>\nor <cite>validation_data</cite> is not affected by regularization layers like\nnoise and dropout.\n<cite>validation_data</cite> will override <cite>validation_split</cite>.\n<cite>validation_data</cite> could be:</p>\n<blockquote>\n<div><ul class=\"simple\">\n<li><p>A tuple <cite>(x_val, y_val)</cite> of Numpy arrays or tensors.</p></li>\n<li><p>A tuple <cite>(x_val, y_val, val_sample_weights)</cite> of NumPy arrays.</p></li>\n<li><p>A <cite>tf.data.Dataset</cite>.</p></li>\n<li><p>A Python generator or <cite>keras.utils.Sequence</cite> returning</p></li>\n</ul>\n<p><cite>(inputs, targets)</cite> or <cite>(inputs, targets, sample_weights)</cite>.</p>\n</div></blockquote>\n<p><cite>validation_data</cite> is not yet supported with\n<cite>tf.distribute.experimental.ParameterServerStrategy</cite>.</p>\n</dd>\n<dt>shuffle: Boolean (whether to shuffle the training data</dt><dd><p>before each epoch) or str (for \u2018batch\u2019). This argument is ignored\nwhen <cite>x</cite> is a generator or an object of tf.data.Dataset.\n\u2018batch\u2019 is a special option for dealing\nwith the limitations of HDF5 data; it shuffles in batch-sized\nchunks. Has no effect when <cite>steps_per_epoch</cite> is not <cite>None</cite>.</p>\n</dd>\n<dt>class_weight: Optional dictionary mapping class indices (integers)</dt><dd><p>to a weight (float) value, used for weighting the loss function\n(during training only).\nThis can be useful to tell the model to\n\u201cpay more attention\u201d to samples from\nan under-represented class.</p>\n</dd>\n<dt>sample_weight: Optional Numpy array of weights for</dt><dd><blockquote>\n<div><p>the training samples, used for weighting the loss function\n(during training only). You can either pass a flat (1D)\nNumpy array with the same length as the input samples\n(1:1 mapping between weights and samples),\nor in the case of temporal data,\nyou can pass a 2D array with shape\n<cite>(samples, sequence_length)</cite>,\nto apply a different weight to every timestep of every sample. This\nargument is not supported when <cite>x</cite> is a dataset, generator, or</p>\n</div></blockquote>\n<dl class=\"simple\">\n<dt><cite>keras.utils.Sequence</cite> instance, instead provide the sample_weights</dt><dd><p>as the third element of <cite>x</cite>.</p>\n</dd>\n</dl>\n</dd>\n<dt>initial_epoch: Integer.</dt><dd><p>Epoch at which to start training\n(useful for resuming a previous training run).</p>\n</dd>\n<dt>steps_per_epoch: Integer or <cite>None</cite>.</dt><dd><p>Total number of steps (batches of samples)\nbefore declaring one epoch finished and starting the\nnext epoch. When training with input tensors such as\nTensorFlow data tensors, the default <cite>None</cite> is equal to\nthe number of samples in your dataset divided by\nthe batch size, or 1 if that cannot be determined. If x is a\n<cite>tf.data</cite> dataset, and \u2018steps_per_epoch\u2019\nis None, the epoch will run until the input dataset is exhausted.\nWhen passing an infinitely repeating dataset, you must specify the\n<cite>steps_per_epoch</cite> argument. If <cite>steps_per_epoch=-1</cite> the training\nwill run indefinitely with an infinitely repeating dataset.\nThis argument is not supported with array inputs.\nWhen using <cite>tf.distribute.experimental.ParameterServerStrategy</cite>:</p>\n<blockquote>\n<div><ul class=\"simple\">\n<li><p><cite>steps_per_epoch=None</cite> is not supported.</p></li>\n</ul>\n</div></blockquote>\n</dd>\n<dt>validation_steps: Only relevant if <cite>validation_data</cite> is provided and</dt><dd><p>is a <cite>tf.data</cite> dataset. Total number of steps (batches of\nsamples) to draw before stopping when performing validation\nat the end of every epoch. If \u2018validation_steps\u2019 is None, validation\nwill run until the <cite>validation_data</cite> dataset is exhausted. In the\ncase of an infinitely repeated dataset, it will run into an\ninfinite loop. If \u2018validation_steps\u2019 is specified and only part of\nthe dataset will be consumed, the evaluation will start from the\nbeginning of the dataset at each epoch. This ensures that the same\nvalidation samples are used every time.</p>\n</dd>\n<dt>validation_batch_size: Integer or <cite>None</cite>.</dt><dd><p>Number of samples per validation batch.\nIf unspecified, will default to <cite>batch_size</cite>.\nDo not specify the <cite>validation_batch_size</cite> if your data is in the\nform of datasets, generators, or <cite>keras.utils.Sequence</cite> instances\n(since they generate batches).</p>\n</dd>\n<dt>validation_freq: Only relevant if validation data is provided. Integer</dt><dd><p>or <cite>collections.abc.Container</cite> instance (e.g. list, tuple, etc.).\nIf an integer, specifies how many training epochs to run before a\nnew validation run is performed, e.g. <cite>validation_freq=2</cite> runs\nvalidation every 2 epochs. If a Container, specifies the epochs on\nwhich to run validation, e.g. <cite>validation_freq=[1, 2, 10]</cite> runs\nvalidation at the end of the 1st, 2nd, and 10th epochs.</p>\n</dd>\n<dt>max_queue_size: Integer. Used for generator or <cite>keras.utils.Sequence</cite></dt><dd><p>input only. Maximum size for the generator queue.\nIf unspecified, <cite>max_queue_size</cite> will default to 10.</p>\n</dd>\n<dt>workers: Integer. Used for generator or <cite>keras.utils.Sequence</cite> input</dt><dd><p>only. Maximum number of processes to spin up\nwhen using process-based threading. If unspecified, <cite>workers</cite>\nwill default to 1.</p>\n</dd>\n<dt>use_multiprocessing: Boolean. Used for generator or</dt><dd><p><cite>keras.utils.Sequence</cite> input only. If <cite>True</cite>, use process-based\nthreading. If unspecified, <cite>use_multiprocessing</cite> will default to\n<cite>False</cite>. Note that because this implementation relies on\nmultiprocessing, you should not pass non-picklable arguments to\nthe generator as they can\u2019t be passed easily to children processes.</p>\n</dd>\n</dl>\n</dd>\n<dt>Unpacking behavior for iterator-like inputs:</dt><dd><blockquote>\n<div><p>A common pattern is to pass a tf.data.Dataset, generator, or</p>\n</div></blockquote>\n<p>tf.keras.utils.Sequence to the <cite>x</cite> argument of fit, which will in fact\nyield not only features (x) but optionally targets (y) and sample weights.\nKeras requires that the output of such iterator-likes be unambiguous. The\niterator should return a tuple of length 1, 2, or 3, where the optional\nsecond and third elements will be used for y and sample_weight\nrespectively. Any other type provided will be wrapped in a length one\ntuple, effectively treating everything as \u2018x\u2019. When yielding dicts, they\nshould still adhere to the top-level tuple structure.\ne.g. <cite>({\u201cx0\u201d: x0, \u201cx1\u201d: x1}, y)</cite>. Keras will not attempt to separate\nfeatures, targets, and weights from the keys of a single dict.</p>\n<blockquote>\n<div><p>A notable unsupported data type is the namedtuple. The reason is that</p>\n</div></blockquote>\n<p>it behaves like both an ordered datatype (tuple) and a mapping\ndatatype (dict). So given a namedtuple of the form:</p>\n<blockquote>\n<div><p><cite>namedtuple(\u201cexample_tuple\u201d, [\u201cy\u201d, \u201cx\u201d])</cite></p>\n</div></blockquote>\n<p>it is ambiguous whether to reverse the order of the elements when\ninterpreting the value. Even worse is a tuple of the form:</p>\n<blockquote>\n<div><p><cite>namedtuple(\u201cother_tuple\u201d, [\u201cx\u201d, \u201cy\u201d, \u201cz\u201d])</cite></p>\n</div></blockquote>\n<p>where it is unclear if the tuple was intended to be unpacked into x, y,\nand sample_weight or passed through as a single element to <cite>x</cite>. As a\nresult the data processing code will simply raise a ValueError if it\nencounters a namedtuple. (Along with instructions to remedy the issue.)</p>\n</dd>\n<dt>Returns:</dt><dd><p>A <cite>History</cite> object. Its <cite>History.history</cite> attribute is\na record of training loss values and metrics values\nat successive epochs, as well as validation loss values\nand validation metrics values (if applicable).</p>\n</dd>\n<dt>Raises:</dt><dd><p>RuntimeError: 1. If the model was never compiled or,\n2. If <cite>model.fit</cite> is  wrapped in <cite>tf.function</cite>.</p>\n<dl class=\"simple\">\n<dt>ValueError: In case of mismatch between the provided input data</dt><dd><p>and what the model expects or when the input data is empty.</p>\n</dd>\n</dl>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.fit_generator\">\n<span class=\"sig-name descname\"><span class=\"pre\">fit_generator</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">generator</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">steps_per_epoch</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">epochs</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">1</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">verbose</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">1</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">callbacks</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">validation_data</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">validation_steps</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">validation_freq</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">1</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">class_weight</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">max_queue_size</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">10</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">workers</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">1</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">use_multiprocessing</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">shuffle</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">True</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">initial_epoch</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">0</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.fit_generator\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Fits the model on data yielded batch-by-batch by a Python generator.</p>\n<dl class=\"simple\">\n<dt>DEPRECATED:</dt><dd><p><cite>Model.fit</cite> now supports generators, so there is no longer any need to use\nthis endpoint.</p>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.from_config\">\n<em class=\"property\"><span class=\"pre\">classmethod</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">from_config</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">config</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">custom_objects</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.from_config\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Creates a layer from its config.</p>\n<p>This method is the reverse of <cite>get_config</cite>,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by <cite>set_weights</cite>).</p>\n<dl class=\"simple\">\n<dt>Args:</dt><dd><dl class=\"simple\">\n<dt>config: A Python dictionary, typically the</dt><dd><p>output of get_config.</p>\n</dd>\n</dl>\n</dd>\n<dt>Returns:</dt><dd><p>A layer instance.</p>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.get_config\">\n<span class=\"sig-name descname\"><span class=\"pre\">get_config</span></span><span class=\"sig-paren\">(</span><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.get_config\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Returns the config of the layer.</p>\n<p>A layer config is a Python dictionary (serializable)\ncontaining the configuration of a layer.\nThe same layer can be reinstantiated later\n(without its trained weights) from this configuration.</p>\n<p>The config of a layer does not include connectivity\ninformation, nor the layer class name. These are handled\nby <cite>Network</cite> (one layer of abstraction above).</p>\n<p>Note that <cite>get_config()</cite> does not guarantee to return a fresh copy of dict\nevery time it is called. The callers should make a copy of the returned dict\nif they want to modify it.</p>\n<dl class=\"simple\">\n<dt>Returns:</dt><dd><p>Python dictionary.</p>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.get_layer\">\n<span class=\"sig-name descname\"><span class=\"pre\">get_layer</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">name</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">index</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.get_layer\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Retrieves a layer based on either its name (unique) or index.</p>\n<p>If <cite>name</cite> and <cite>index</cite> are both provided, <cite>index</cite> will take precedence.\nIndices are based on order of horizontal graph traversal (bottom-up).</p>\n<dl class=\"simple\">\n<dt>Args:</dt><dd><p>name: String, name of layer.\nindex: Integer, index of layer.</p>\n</dd>\n<dt>Returns:</dt><dd><p>A layer instance.</p>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.get_weights\">\n<span class=\"sig-name descname\"><span class=\"pre\">get_weights</span></span><span class=\"sig-paren\">(</span><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.get_weights\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Retrieves the weights of the model.</p>\n<dl class=\"simple\">\n<dt>Returns:</dt><dd><p>A flat list of Numpy arrays.</p>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py property\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.layers\">\n<em class=\"property\"><span class=\"pre\">property</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">layers</span></span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.layers\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.load_weights\">\n<span class=\"sig-name descname\"><span class=\"pre\">load_weights</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">filepath</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">by_name</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">skip_mismatch</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">options</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.load_weights\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Loads all layer weights, either from a TensorFlow or an HDF5 weight file.</p>\n<p>If <cite>by_name</cite> is False weights are loaded based on the network\u2019s\ntopology. This means the architecture should be the same as when the weights\nwere saved.  Note that layers that don\u2019t have weights are not taken into\naccount in the topological ordering, so adding or removing layers is fine as\nlong as they don\u2019t have weights.</p>\n<p>If <cite>by_name</cite> is True, weights are loaded into layers only if they share the\nsame name. This is useful for fine-tuning or transfer-learning models where\nsome of the layers have changed.</p>\n<p>Only topological loading (<cite>by_name=False</cite>) is supported when loading weights\nfrom the TensorFlow format. Note that topological loading differs slightly\nbetween TensorFlow and HDF5 formats for user-defined classes inheriting from\n<cite>tf.keras.Model</cite>: HDF5 loads based on a flattened list of weights, while the\nTensorFlow format loads based on the object-local names of attributes to\nwhich layers are assigned in the <cite>Model</cite>\u2019s constructor.</p>\n<dl>\n<dt>Args:</dt><dd><dl class=\"simple\">\n<dt>filepath: String, path to the weights file to load. For weight files in</dt><dd><p>TensorFlow format, this is the file prefix (the same as was passed\nto <cite>save_weights</cite>). This can also be a path to a SavedModel\nsaved from <cite>model.save</cite>.</p>\n</dd>\n<dt>by_name: Boolean, whether to load weights by name or by topological</dt><dd><p>order. Only topological loading is supported for weight files in\nTensorFlow format.</p>\n</dd>\n<dt>skip_mismatch: Boolean, whether to skip loading of layers where there is</dt><dd><p>a mismatch in the number of weights, or a mismatch in the shape of\nthe weight (only valid when <cite>by_name=True</cite>).</p>\n</dd>\n<dt>options: Optional <cite>tf.train.CheckpointOptions</cite> object that specifies</dt><dd><p>options for loading weights.</p>\n</dd>\n</dl>\n</dd>\n<dt>Returns:</dt><dd><p>When loading a weight file in TensorFlow format, returns the same status\nobject as <cite>tf.train.Checkpoint.restore</cite>. When graph building, restore\nops are run automatically as soon as the network is built (on first call\nfor user-defined classes inheriting from <cite>Model</cite>, immediately if it is\nalready built).</p>\n<p>When loading weights in HDF5 format, returns <cite>None</cite>.</p>\n</dd>\n<dt>Raises:</dt><dd><dl class=\"simple\">\n<dt>ImportError: If <cite>h5py</cite> is not available and the weight file is in HDF5</dt><dd><p>format.</p>\n</dd>\n<dt>ValueError: If <cite>skip_mismatch</cite> is set to <cite>True</cite> when <cite>by_name</cite> is</dt><dd><p><cite>False</cite>.</p>\n</dd>\n</dl>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.make_predict_function\">\n<span class=\"sig-name descname\"><span class=\"pre\">make_predict_function</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">force</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.make_predict_function\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Creates a function that executes one step of inference.</p>\n<p>This method can be overridden to support custom inference logic.\nThis method is called by <cite>Model.predict</cite> and <cite>Model.predict_on_batch</cite>.</p>\n<p>Typically, this method directly controls <cite>tf.function</cite> and\n<cite>tf.distribute.Strategy</cite> settings, and delegates the actual evaluation\nlogic to <cite>Model.predict_step</cite>.</p>\n<p>This function is cached the first time <cite>Model.predict</cite> or\n<cite>Model.predict_on_batch</cite> is called. The cache is cleared whenever\n<cite>Model.compile</cite> is called. You can skip the cache and generate again the\nfunction with <cite>force=True</cite>.</p>\n<dl class=\"simple\">\n<dt>Args:</dt><dd><dl class=\"simple\">\n<dt>force: Whether to regenerate the predict function and skip the cached</dt><dd><p>function if available.</p>\n</dd>\n</dl>\n</dd>\n<dt>Returns:</dt><dd><p>Function. The function created by this method should accept a\n<cite>tf.data.Iterator</cite>, and return the outputs of the <cite>Model</cite>.</p>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.make_test_function\">\n<span class=\"sig-name descname\"><span class=\"pre\">make_test_function</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">force</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.make_test_function\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Creates a function that executes one step of evaluation.</p>\n<p>This method can be overridden to support custom evaluation logic.\nThis method is called by <cite>Model.evaluate</cite> and <cite>Model.test_on_batch</cite>.</p>\n<p>Typically, this method directly controls <cite>tf.function</cite> and\n<cite>tf.distribute.Strategy</cite> settings, and delegates the actual evaluation\nlogic to <cite>Model.test_step</cite>.</p>\n<p>This function is cached the first time <cite>Model.evaluate</cite> or\n<cite>Model.test_on_batch</cite> is called. The cache is cleared whenever\n<cite>Model.compile</cite> is called. You can skip the cache and generate again the\nfunction with <cite>force=True</cite>.</p>\n<dl class=\"simple\">\n<dt>Args:</dt><dd><dl class=\"simple\">\n<dt>force: Whether to regenerate the test function and skip the cached</dt><dd><p>function if available.</p>\n</dd>\n</dl>\n</dd>\n<dt>Returns:</dt><dd><p>Function. The function created by this method should accept a\n<cite>tf.data.Iterator</cite>, and return a <cite>dict</cite> containing values that will\nbe passed to <cite>tf.keras.Callbacks.on_test_batch_end</cite>.</p>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.make_train_function\">\n<span class=\"sig-name descname\"><span class=\"pre\">make_train_function</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">force</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.make_train_function\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Creates a function that executes one step of training.</p>\n<p>This method can be overridden to support custom training logic.\nThis method is called by <cite>Model.fit</cite> and <cite>Model.train_on_batch</cite>.</p>\n<p>Typically, this method directly controls <cite>tf.function</cite> and\n<cite>tf.distribute.Strategy</cite> settings, and delegates the actual training\nlogic to <cite>Model.train_step</cite>.</p>\n<p>This function is cached the first time <cite>Model.fit</cite> or\n<cite>Model.train_on_batch</cite> is called. The cache is cleared whenever\n<cite>Model.compile</cite> is called. You can skip the cache and generate again the\nfunction with <cite>force=True</cite>.</p>\n<dl class=\"simple\">\n<dt>Args:</dt><dd><dl class=\"simple\">\n<dt>force: Whether to regenerate the train function and skip the cached</dt><dd><p>function if available.</p>\n</dd>\n</dl>\n</dd>\n<dt>Returns:</dt><dd><p>Function. The function created by this method should accept a\n<cite>tf.data.Iterator</cite>, and return a <cite>dict</cite> containing values that will\nbe passed to <cite>tf.keras.Callbacks.on_train_batch_end</cite>, such as\n<cite>{\u2018loss\u2019: 0.2, \u2018accuracy\u2019: 0.7}</cite>.</p>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py property\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.metrics\">\n<em class=\"property\"><span class=\"pre\">property</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">metrics</span></span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.metrics\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Returns the model\u2019s metrics added using <cite>compile()</cite>, <cite>add_metric()</cite> APIs.</p>\n<p>Note: Metrics passed to <cite>compile()</cite> are available only after a <cite>keras.Model</cite>\nhas been trained/evaluated on actual data.</p>\n<p>Examples:</p>\n<div class=\"doctest highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">inputs</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Input</span><span class=\"p\">(</span><span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">,))</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">outputs</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">)(</span><span class=\"n\">inputs</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">models</span><span class=\"o\">.</span><span class=\"n\">Model</span><span class=\"p\">(</span><span class=\"n\">inputs</span><span class=\"o\">=</span><span class=\"n\">inputs</span><span class=\"p\">,</span> <span class=\"n\">outputs</span><span class=\"o\">=</span><span class=\"n\">outputs</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">compile</span><span class=\"p\">(</span><span class=\"n\">optimizer</span><span class=\"o\">=</span><span class=\"s2\">&quot;Adam&quot;</span><span class=\"p\">,</span> <span class=\"n\">loss</span><span class=\"o\">=</span><span class=\"s2\">&quot;mse&quot;</span><span class=\"p\">,</span> <span class=\"n\">metrics</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s2\">&quot;mae&quot;</span><span class=\"p\">])</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"o\">.</span><span class=\"n\">name</span> <span class=\"k\">for</span> <span class=\"n\">m</span> <span class=\"ow\">in</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">metrics</span><span class=\"p\">]</span>\n<span class=\"go\">[]</span>\n</pre></div>\n</div>\n<div class=\"doctest highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"p\">((</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">))</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">randint</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">))</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"o\">.</span><span class=\"n\">name</span> <span class=\"k\">for</span> <span class=\"n\">m</span> <span class=\"ow\">in</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">metrics</span><span class=\"p\">]</span>\n<span class=\"go\">[&#39;loss&#39;, &#39;mae&#39;]</span>\n</pre></div>\n</div>\n<div class=\"doctest highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">inputs</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Input</span><span class=\"p\">(</span><span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">,))</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">d</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;out&#39;</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">output_1</span> <span class=\"o\">=</span> <span class=\"n\">d</span><span class=\"p\">(</span><span class=\"n\">inputs</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">output_2</span> <span class=\"o\">=</span> <span class=\"n\">d</span><span class=\"p\">(</span><span class=\"n\">inputs</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">models</span><span class=\"o\">.</span><span class=\"n\">Model</span><span class=\"p\">(</span>\n<span class=\"gp\">... </span>   <span class=\"n\">inputs</span><span class=\"o\">=</span><span class=\"n\">inputs</span><span class=\"p\">,</span> <span class=\"n\">outputs</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">output_1</span><span class=\"p\">,</span> <span class=\"n\">output_2</span><span class=\"p\">])</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">add_metric</span><span class=\"p\">(</span>\n<span class=\"gp\">... </span>   <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">reduce_sum</span><span class=\"p\">(</span><span class=\"n\">output_2</span><span class=\"p\">),</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;mean&#39;</span><span class=\"p\">,</span> <span class=\"n\">aggregation</span><span class=\"o\">=</span><span class=\"s1\">&#39;mean&#39;</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">compile</span><span class=\"p\">(</span><span class=\"n\">optimizer</span><span class=\"o\">=</span><span class=\"s2\">&quot;Adam&quot;</span><span class=\"p\">,</span> <span class=\"n\">loss</span><span class=\"o\">=</span><span class=\"s2\">&quot;mse&quot;</span><span class=\"p\">,</span> <span class=\"n\">metrics</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s2\">&quot;mae&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;acc&quot;</span><span class=\"p\">])</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">))</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"p\">[</span><span class=\"n\">m</span><span class=\"o\">.</span><span class=\"n\">name</span> <span class=\"k\">for</span> <span class=\"n\">m</span> <span class=\"ow\">in</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">metrics</span><span class=\"p\">]</span>\n<span class=\"go\">[&#39;loss&#39;, &#39;out_loss&#39;, &#39;out_1_loss&#39;, &#39;out_mae&#39;, &#39;out_acc&#39;, &#39;out_1_mae&#39;,</span>\n<span class=\"go\">&#39;out_1_acc&#39;, &#39;mean&#39;]</span>\n</pre></div>\n</div>\n</dd></dl>\n\n<dl class=\"py property\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.metrics_names\">\n<em class=\"property\"><span class=\"pre\">property</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">metrics_names</span></span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.metrics_names\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Returns the model\u2019s display labels for all outputs.</p>\n<p>Note: <cite>metrics_names</cite> are available only after a <cite>keras.Model</cite> has been\ntrained/evaluated on actual data.</p>\n<p>Examples:</p>\n<div class=\"doctest highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">inputs</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Input</span><span class=\"p\">(</span><span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">,))</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">outputs</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">)(</span><span class=\"n\">inputs</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">models</span><span class=\"o\">.</span><span class=\"n\">Model</span><span class=\"p\">(</span><span class=\"n\">inputs</span><span class=\"o\">=</span><span class=\"n\">inputs</span><span class=\"p\">,</span> <span class=\"n\">outputs</span><span class=\"o\">=</span><span class=\"n\">outputs</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">compile</span><span class=\"p\">(</span><span class=\"n\">optimizer</span><span class=\"o\">=</span><span class=\"s2\">&quot;Adam&quot;</span><span class=\"p\">,</span> <span class=\"n\">loss</span><span class=\"o\">=</span><span class=\"s2\">&quot;mse&quot;</span><span class=\"p\">,</span> <span class=\"n\">metrics</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s2\">&quot;mae&quot;</span><span class=\"p\">])</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">metrics_names</span>\n<span class=\"go\">[]</span>\n</pre></div>\n</div>\n<div class=\"doctest highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"p\">((</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">))</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">randint</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">))</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">metrics_names</span>\n<span class=\"go\">[&#39;loss&#39;, &#39;mae&#39;]</span>\n</pre></div>\n</div>\n<div class=\"doctest highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">inputs</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Input</span><span class=\"p\">(</span><span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">,))</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">d</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">&#39;out&#39;</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">output_1</span> <span class=\"o\">=</span> <span class=\"n\">d</span><span class=\"p\">(</span><span class=\"n\">inputs</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">output_2</span> <span class=\"o\">=</span> <span class=\"n\">d</span><span class=\"p\">(</span><span class=\"n\">inputs</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">models</span><span class=\"o\">.</span><span class=\"n\">Model</span><span class=\"p\">(</span>\n<span class=\"gp\">... </span>   <span class=\"n\">inputs</span><span class=\"o\">=</span><span class=\"n\">inputs</span><span class=\"p\">,</span> <span class=\"n\">outputs</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">output_1</span><span class=\"p\">,</span> <span class=\"n\">output_2</span><span class=\"p\">])</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">compile</span><span class=\"p\">(</span><span class=\"n\">optimizer</span><span class=\"o\">=</span><span class=\"s2\">&quot;Adam&quot;</span><span class=\"p\">,</span> <span class=\"n\">loss</span><span class=\"o\">=</span><span class=\"s2\">&quot;mse&quot;</span><span class=\"p\">,</span> <span class=\"n\">metrics</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s2\">&quot;mae&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;acc&quot;</span><span class=\"p\">])</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">))</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">metrics_names</span>\n<span class=\"go\">[&#39;loss&#39;, &#39;out_loss&#39;, &#39;out_1_loss&#39;, &#39;out_mae&#39;, &#39;out_acc&#39;, &#39;out_1_mae&#39;,</span>\n<span class=\"go\">&#39;out_1_acc&#39;]</span>\n</pre></div>\n</div>\n</dd></dl>\n\n<dl class=\"py property\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.non_trainable_weights\">\n<em class=\"property\"><span class=\"pre\">property</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">non_trainable_weights</span></span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.non_trainable_weights\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>List of all non-trainable weights tracked by this layer.</p>\n<p>Non-trainable weights are <em>not</em> updated during training. They are expected\nto be updated manually in <cite>call()</cite>.</p>\n<dl class=\"simple\">\n<dt>Returns:</dt><dd><p>A list of non-trainable variables.</p>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.predict\">\n<span class=\"sig-name descname\"><span class=\"pre\">predict</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">x</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">batch_size</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">verbose</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">0</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">steps</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">callbacks</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">max_queue_size</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">10</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">workers</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">1</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">use_multiprocessing</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.predict\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Generates output predictions for the input samples.</p>\n<p>Computation is done in batches. This method is designed for batch processing\nof large numbers of inputs. It is not intended for use inside of loops\nthat iterate over your data and process small numbers of inputs at a time.</p>\n<p>For small numbers of inputs that fit in one batch,\ndirectly use <cite>__call__()</cite> for faster execution, e.g.,\n<cite>model(x)</cite>, or <cite>model(x, training=False)</cite> if you have layers such as\n<cite>tf.keras.layers.BatchNormalization</cite> that behave differently during\ninference. You may pair the individual model call with a <cite>tf.function</cite>\nfor additional performance inside your inner loop.\nIf you need access to numpy array values instead of tensors after your\nmodel call, you can use <cite>tensor.numpy()</cite> to get the numpy array value of\nan eager tensor.</p>\n<p>Also, note the fact that test loss is not affected by\nregularization layers like noise and dropout.</p>\n<p>Note: See [this FAQ entry](\n<a class=\"reference external\" href=\"https://keras.io/getting_started/faq/#whats-the-difference-between-model-methods-predict-and-call\">https://keras.io/getting_started/faq/#whats-the-difference-between-model-methods-predict-and-call</a>)\nfor more details about the difference between <cite>Model</cite> methods <cite>predict()</cite>\nand <cite>__call__()</cite>.</p>\n<dl>\n<dt>Args:</dt><dd><dl>\n<dt>x: Input samples. It could be:</dt><dd><ul class=\"simple\">\n<li><p>A Numpy array (or array-like), or a list of arrays\n(in case the model has multiple inputs).</p></li>\n<li><p>A TensorFlow tensor, or a list of tensors\n(in case the model has multiple inputs).</p></li>\n<li><p>A <cite>tf.data</cite> dataset.</p></li>\n<li><p>A generator or <cite>keras.utils.Sequence</cite> instance.</p></li>\n</ul>\n<p>A more detailed description of unpacking behavior for iterator types\n(Dataset, generator, Sequence) is given in the <cite>Unpacking behavior\nfor iterator-like inputs</cite> section of <cite>Model.fit</cite>.</p>\n</dd>\n<dt>batch_size: Integer or <cite>None</cite>.</dt><dd><p>Number of samples per batch.\nIf unspecified, <cite>batch_size</cite> will default to 32.\nDo not specify the <cite>batch_size</cite> if your data is in the\nform of dataset, generators, or <cite>keras.utils.Sequence</cite> instances\n(since they generate batches).</p>\n</dd>\n</dl>\n<p>verbose: Verbosity mode, 0 or 1.\nsteps: Total number of steps (batches of samples)</p>\n<blockquote>\n<div><p>before declaring the prediction round finished.\nIgnored with the default value of <cite>None</cite>. If x is a <cite>tf.data</cite>\ndataset and <cite>steps</cite> is None, <cite>predict()</cite> will\nrun until the input dataset is exhausted.</p>\n</div></blockquote>\n<dl class=\"simple\">\n<dt>callbacks: List of <cite>keras.callbacks.Callback</cite> instances.</dt><dd><p>List of callbacks to apply during prediction.\nSee [callbacks](/api_docs/python/tf/keras/callbacks).</p>\n</dd>\n<dt>max_queue_size: Integer. Used for generator or <cite>keras.utils.Sequence</cite></dt><dd><p>input only. Maximum size for the generator queue.\nIf unspecified, <cite>max_queue_size</cite> will default to 10.</p>\n</dd>\n<dt>workers: Integer. Used for generator or <cite>keras.utils.Sequence</cite> input</dt><dd><p>only. Maximum number of processes to spin up when using\nprocess-based threading. If unspecified, <cite>workers</cite> will default\nto 1.</p>\n</dd>\n<dt>use_multiprocessing: Boolean. Used for generator or</dt><dd><p><cite>keras.utils.Sequence</cite> input only. If <cite>True</cite>, use process-based\nthreading. If unspecified, <cite>use_multiprocessing</cite> will default to\n<cite>False</cite>. Note that because this implementation relies on\nmultiprocessing, you should not pass non-picklable arguments to\nthe generator as they can\u2019t be passed easily to children processes.</p>\n</dd>\n</dl>\n</dd>\n</dl>\n<p>See the discussion of <cite>Unpacking behavior for iterator-like inputs</cite> for\n<cite>Model.fit</cite>. Note that Model.predict uses the same interpretation rules as\n<cite>Model.fit</cite> and <cite>Model.evaluate</cite>, so inputs must be unambiguous for all\nthree methods.</p>\n<dl>\n<dt>Returns:</dt><dd><p>Numpy array(s) of predictions.</p>\n</dd>\n<dt>Raises:</dt><dd><p>RuntimeError: If <cite>model.predict</cite> is wrapped in a <cite>tf.function</cite>.\nValueError: In case of mismatch between the provided</p>\n<blockquote>\n<div><p>input data and the model\u2019s expectations,\nor in case a stateful model receives a number of samples\nthat is not a multiple of the batch size.</p>\n</div></blockquote>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.predict_generator\">\n<span class=\"sig-name descname\"><span class=\"pre\">predict_generator</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">generator</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">steps</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">callbacks</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">max_queue_size</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">10</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">workers</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">1</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">use_multiprocessing</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">verbose</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">0</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.predict_generator\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Generates predictions for the input samples from a data generator.</p>\n<dl class=\"simple\">\n<dt>DEPRECATED:</dt><dd><p><cite>Model.predict</cite> now supports generators, so there is no longer any need\nto use this endpoint.</p>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.predict_on_batch\">\n<span class=\"sig-name descname\"><span class=\"pre\">predict_on_batch</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">x</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.predict_on_batch\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Returns predictions for a single batch of samples.</p>\n<dl class=\"simple\">\n<dt>Args:</dt><dd><dl class=\"simple\">\n<dt>x: Input data. It could be:</dt><dd><ul class=\"simple\">\n<li><dl class=\"simple\">\n<dt>A Numpy array (or array-like), or a list of arrays (in case the</dt><dd><p>model has multiple inputs).</p>\n</dd>\n</dl>\n</li>\n<li><dl class=\"simple\">\n<dt>A TensorFlow tensor, or a list of tensors (in case the model has</dt><dd><p>multiple inputs).</p>\n</dd>\n</dl>\n</li>\n</ul>\n</dd>\n</dl>\n</dd>\n<dt>Returns:</dt><dd><p>Numpy array(s) of predictions.</p>\n</dd>\n<dt>Raises:</dt><dd><p>RuntimeError: If <cite>model.predict_on_batch</cite> is wrapped in a <cite>tf.function</cite>.</p>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.predict_step\">\n<span class=\"sig-name descname\"><span class=\"pre\">predict_step</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">data</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.predict_step\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>The logic for one inference step.</p>\n<p>This method can be overridden to support custom inference logic.\nThis method is called by <cite>Model.make_predict_function</cite>.</p>\n<p>This method should contain the mathematical logic for one step of inference.\nThis typically includes the forward pass.</p>\n<p>Configuration details for <em>how</em> this logic is run (e.g. <cite>tf.function</cite> and\n<cite>tf.distribute.Strategy</cite> settings), should be left to\n<cite>Model.make_predict_function</cite>, which can also be overridden.</p>\n<dl class=\"simple\">\n<dt>Args:</dt><dd><p>data: A nested structure of <a href=\"#id77\"><span class=\"problematic\" id=\"id78\">`</span></a>Tensor`s.</p>\n</dd>\n<dt>Returns:</dt><dd><p>The result of one inference step, typically the output of calling the\n<cite>Model</cite> on data.</p>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.reset_metrics\">\n<span class=\"sig-name descname\"><span class=\"pre\">reset_metrics</span></span><span class=\"sig-paren\">(</span><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.reset_metrics\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Resets the state of all the metrics in the model.</p>\n<p>Examples:</p>\n<div class=\"doctest highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">inputs</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Input</span><span class=\"p\">(</span><span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">,))</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">outputs</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">)(</span><span class=\"n\">inputs</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">models</span><span class=\"o\">.</span><span class=\"n\">Model</span><span class=\"p\">(</span><span class=\"n\">inputs</span><span class=\"o\">=</span><span class=\"n\">inputs</span><span class=\"p\">,</span> <span class=\"n\">outputs</span><span class=\"o\">=</span><span class=\"n\">outputs</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">compile</span><span class=\"p\">(</span><span class=\"n\">optimizer</span><span class=\"o\">=</span><span class=\"s2\">&quot;Adam&quot;</span><span class=\"p\">,</span> <span class=\"n\">loss</span><span class=\"o\">=</span><span class=\"s2\">&quot;mse&quot;</span><span class=\"p\">,</span> <span class=\"n\">metrics</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s2\">&quot;mae&quot;</span><span class=\"p\">])</span>\n</pre></div>\n</div>\n<div class=\"doctest highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"p\">((</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">))</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">randint</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">))</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">_</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">verbose</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"k\">assert</span> <span class=\"nb\">all</span><span class=\"p\">(</span><span class=\"nb\">float</span><span class=\"p\">(</span><span class=\"n\">m</span><span class=\"o\">.</span><span class=\"n\">result</span><span class=\"p\">())</span> <span class=\"k\">for</span> <span class=\"n\">m</span> <span class=\"ow\">in</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">metrics</span><span class=\"p\">)</span>\n</pre></div>\n</div>\n<div class=\"doctest highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">reset_metrics</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"k\">assert</span> <span class=\"nb\">all</span><span class=\"p\">(</span><span class=\"nb\">float</span><span class=\"p\">(</span><span class=\"n\">m</span><span class=\"o\">.</span><span class=\"n\">result</span><span class=\"p\">())</span> <span class=\"o\">==</span> <span class=\"mi\">0</span> <span class=\"k\">for</span> <span class=\"n\">m</span> <span class=\"ow\">in</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">metrics</span><span class=\"p\">)</span>\n</pre></div>\n</div>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.reset_states\">\n<span class=\"sig-name descname\"><span class=\"pre\">reset_states</span></span><span class=\"sig-paren\">(</span><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.reset_states\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py property\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.run_eagerly\">\n<em class=\"property\"><span class=\"pre\">property</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">run_eagerly</span></span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.run_eagerly\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Settable attribute indicating whether the model should run eagerly.</p>\n<p>Running eagerly means that your model will be run step by step,\nlike Python code. Your model might run slower, but it should become easier\nfor you to debug it by stepping into individual layer calls.</p>\n<p>By default, we will attempt to compile your model to a static graph to\ndeliver the best execution performance.</p>\n<dl class=\"simple\">\n<dt>Returns:</dt><dd><p>Boolean, whether the model should run eagerly.</p>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.save\">\n<span class=\"sig-name descname\"><span class=\"pre\">save</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">filepath</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">overwrite</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">True</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">include_optimizer</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">True</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">save_format</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">signatures</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">options</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">save_traces</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">True</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.save\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Saves the model to Tensorflow SavedModel or a single HDF5 file.</p>\n<p>Please see <cite>tf.keras.models.save_model</cite> or the\n[Serialization and Saving guide](<a class=\"reference external\" href=\"https://keras.io/guides/serialization_and_saving/\">https://keras.io/guides/serialization_and_saving/</a>)\nfor details.</p>\n<dl>\n<dt>Args:</dt><dd><dl class=\"simple\">\n<dt>filepath: String, PathLike, path to SavedModel or H5 file to save the</dt><dd><p>model.</p>\n</dd>\n<dt>overwrite: Whether to silently overwrite any existing file at the</dt><dd><p>target location, or provide the user with a manual prompt.</p>\n</dd>\n</dl>\n<p>include_optimizer: If True, save optimizer\u2019s state together.\nsave_format: Either <cite>\u2018tf\u2019</cite> or <cite>\u2018h5\u2019</cite>, indicating whether to save the</p>\n<blockquote>\n<div><p>model to Tensorflow SavedModel or HDF5. Defaults to \u2018tf\u2019 in TF 2.X,\nand \u2018h5\u2019 in TF 1.X.</p>\n</div></blockquote>\n<dl class=\"simple\">\n<dt>signatures: Signatures to save with the SavedModel. Applicable to the</dt><dd><p>\u2018tf\u2019 format only. Please see the <cite>signatures</cite> argument in\n<cite>tf.saved_model.save</cite> for details.</p>\n</dd>\n<dt>options: (only applies to SavedModel format)</dt><dd><p><cite>tf.saved_model.SaveOptions</cite> object that specifies options for\nsaving to SavedModel.</p>\n</dd>\n<dt>save_traces: (only applies to SavedModel format) When enabled, the</dt><dd><p>SavedModel will store the function traces for each layer. This\ncan be disabled, so that only the configs of each layer are stored.\nDefaults to <cite>True</cite>. Disabling this will decrease serialization time\nand reduce file size, but it requires that all custom layers/models\nimplement a <cite>get_config()</cite> method.</p>\n</dd>\n</dl>\n</dd>\n</dl>\n<p>Example:</p>\n<p><a href=\"#id79\"><span class=\"problematic\" id=\"id80\">``</span></a><a href=\"#id81\"><span class=\"problematic\" id=\"id82\">`</span></a>python\nfrom keras.models import load_model</p>\n<p>model.save(\u2018my_model.h5\u2019)  # creates a HDF5 file \u2018my_model.h5\u2019\ndel model  # deletes the existing model</p>\n<p># returns a compiled model\n# identical to the previous one\nmodel = load_model(\u2018my_model.h5\u2019)\n<a href=\"#id83\"><span class=\"problematic\" id=\"id84\">``</span></a><a href=\"#id85\"><span class=\"problematic\" id=\"id86\">`</span></a></p>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.save_spec\">\n<span class=\"sig-name descname\"><span class=\"pre\">save_spec</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">dynamic_batch</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">True</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.save_spec\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Returns the <cite>tf.TensorSpec</cite> of call inputs as a tuple <cite>(args, kwargs)</cite>.</p>\n<p>This value is automatically defined after calling the model for the first\ntime. Afterwards, you can use it when exporting the model for serving:</p>\n<p><a href=\"#id87\"><span class=\"problematic\" id=\"id88\">``</span></a><a href=\"#id89\"><span class=\"problematic\" id=\"id90\">`</span></a>python\nmodel = tf.keras.Model(\u2026)</p>\n<p>&#64;tf.function\ndef serve(<a href=\"#id91\"><span class=\"problematic\" id=\"id92\">*</span></a>args, <a href=\"#id93\"><span class=\"problematic\" id=\"id94\">**</span></a>kwargs):</p>\n<blockquote>\n<div><p>outputs = model(<a href=\"#id95\"><span class=\"problematic\" id=\"id96\">*</span></a>args, <a href=\"#id97\"><span class=\"problematic\" id=\"id98\">**</span></a>kwargs)\n# Apply postprocessing steps, or add additional outputs.\n\u2026\nreturn outputs</p>\n</div></blockquote>\n<p># arg_specs is <cite>[tf.TensorSpec(\u2026), \u2026]</cite>. kwarg_specs, in this example, is\n# an empty dict since functional models do not use keyword arguments.\narg_specs, kwarg_specs = model.save_spec()</p>\n<dl class=\"simple\">\n<dt>model.save(path, signatures={</dt><dd><p>\u2018serving_default\u2019: serve.get_concrete_function(<a href=\"#id99\"><span class=\"problematic\" id=\"id100\">*</span></a>arg_specs, <a href=\"#id101\"><span class=\"problematic\" id=\"id102\">**</span></a>kwarg_specs)</p>\n</dd>\n</dl>\n<dl class=\"simple\">\n<dt>Args:</dt><dd><dl class=\"simple\">\n<dt>dynamic_batch: Whether to set the batch sizes of all the returned</dt><dd><p><cite>tf.TensorSpec</cite> to <cite>None</cite>. (Note that when defining functional or\nSequential models with <cite>tf.keras.Input([\u2026], batch_size=X)</cite>, the\nbatch size will always be preserved). Defaults to <cite>True</cite>.</p>\n</dd>\n</dl>\n</dd>\n<dt>Returns:</dt><dd><p>If the model inputs are defined, returns a tuple <cite>(args, kwargs)</cite>. All\nelements in <cite>args</cite> and <cite>kwargs</cite> are <cite>tf.TensorSpec</cite>.\nIf the model inputs are not defined, returns <cite>None</cite>.\nThe model inputs are automatically set when calling the model,\n<cite>model.fit</cite>, <cite>model.evaluate</cite> or <cite>model.predict</cite>.</p>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.save_weights\">\n<span class=\"sig-name descname\"><span class=\"pre\">save_weights</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">filepath</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">overwrite</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">True</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">save_format</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">options</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.save_weights\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Saves all layer weights.</p>\n<p>Either saves in HDF5 or in TensorFlow format based on the <cite>save_format</cite>\nargument.</p>\n<dl class=\"simple\">\n<dt>When saving in HDF5 format, the weight file has:</dt><dd><ul class=\"simple\">\n<li><dl class=\"simple\">\n<dt><cite>layer_names</cite> (attribute), a list of strings</dt><dd><p>(ordered names of model layers).</p>\n</dd>\n</dl>\n</li>\n<li><dl class=\"simple\">\n<dt>For every layer, a <cite>group</cite> named <cite>layer.name</cite></dt><dd><ul>\n<li><dl class=\"simple\">\n<dt>For every such layer group, a group attribute <cite>weight_names</cite>,</dt><dd><p>a list of strings\n(ordered names of weights tensor of the layer).</p>\n</dd>\n</dl>\n</li>\n<li><dl class=\"simple\">\n<dt>For every weight in the layer, a dataset</dt><dd><p>storing the weight value, named after the weight tensor.</p>\n</dd>\n</dl>\n</li>\n</ul>\n</dd>\n</dl>\n</li>\n</ul>\n</dd>\n</dl>\n<p>When saving in TensorFlow format, all objects referenced by the network are\nsaved in the same format as <cite>tf.train.Checkpoint</cite>, including any <cite>Layer</cite>\ninstances or <cite>Optimizer</cite> instances assigned to object attributes. For\nnetworks constructed from inputs and outputs using <cite>tf.keras.Model(inputs,\noutputs)</cite>, <cite>Layer</cite> instances used by the network are tracked/saved\nautomatically. For user-defined classes which inherit from <cite>tf.keras.Model</cite>,\n<cite>Layer</cite> instances must be assigned to object attributes, typically in the\nconstructor. See the documentation of <cite>tf.train.Checkpoint</cite> and\n<cite>tf.keras.Model</cite> for details.</p>\n<p>While the formats are the same, do not mix <cite>save_weights</cite> and\n<cite>tf.train.Checkpoint</cite>. Checkpoints saved by <cite>Model.save_weights</cite> should be\nloaded using <cite>Model.load_weights</cite>. Checkpoints saved using\n<cite>tf.train.Checkpoint.save</cite> should be restored using the corresponding\n<cite>tf.train.Checkpoint.restore</cite>. Prefer <cite>tf.train.Checkpoint</cite> over\n<cite>save_weights</cite> for training checkpoints.</p>\n<p>The TensorFlow format matches objects and variables by starting at a root\nobject, <cite>self</cite> for <cite>save_weights</cite>, and greedily matching attribute\nnames. For <cite>Model.save</cite> this is the <cite>Model</cite>, and for <cite>Checkpoint.save</cite> this\nis the <cite>Checkpoint</cite> even if the <cite>Checkpoint</cite> has a model attached. This\nmeans saving a <cite>tf.keras.Model</cite> using <cite>save_weights</cite> and loading into a\n<cite>tf.train.Checkpoint</cite> with a <cite>Model</cite> attached (or vice versa) will not match\nthe <cite>Model</cite>\u2019s variables. See the\n[guide to training checkpoints](<a class=\"reference external\" href=\"https://www.tensorflow.org/guide/checkpoint\">https://www.tensorflow.org/guide/checkpoint</a>)\nfor details on the TensorFlow format.</p>\n<dl class=\"simple\">\n<dt>Args:</dt><dd><dl class=\"simple\">\n<dt>filepath: String or PathLike, path to the file to save the weights to.</dt><dd><p>When saving in TensorFlow format, this is the prefix used for\ncheckpoint files (multiple files are generated). Note that the \u2018.h5\u2019\nsuffix causes weights to be saved in HDF5 format.</p>\n</dd>\n<dt>overwrite: Whether to silently overwrite any existing file at the</dt><dd><p>target location, or provide the user with a manual prompt.</p>\n</dd>\n<dt>save_format: Either \u2018tf\u2019 or \u2018h5\u2019. A <cite>filepath</cite> ending in \u2018.h5\u2019 or</dt><dd><p>\u2018.keras\u2019 will default to HDF5 if <cite>save_format</cite> is <cite>None</cite>. Otherwise\n<cite>None</cite> defaults to \u2018tf\u2019.</p>\n</dd>\n<dt>options: Optional <cite>tf.train.CheckpointOptions</cite> object that specifies</dt><dd><p>options for saving weights.</p>\n</dd>\n</dl>\n</dd>\n<dt>Raises:</dt><dd><dl class=\"simple\">\n<dt>ImportError: If <cite>h5py</cite> is not available when attempting to save in HDF5</dt><dd><p>format.</p>\n</dd>\n</dl>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py property\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.state_updates\">\n<em class=\"property\"><span class=\"pre\">property</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">state_updates</span></span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.state_updates\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Deprecated, do NOT use!</p>\n<p>Returns the <cite>updates</cite> from all layers that are stateful.</p>\n<p>This is useful for separating training updates and\nstate updates, e.g. when we need to update a layer\u2019s internal state\nduring prediction.</p>\n<dl class=\"simple\">\n<dt>Returns:</dt><dd><p>A list of update ops.</p>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.summary\">\n<span class=\"sig-name descname\"><span class=\"pre\">summary</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">line_length</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">positions</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">print_fn</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">expand_nested</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">show_trainable</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.summary\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Prints a string summary of the network.</p>\n<dl class=\"simple\">\n<dt>Args:</dt><dd><dl class=\"simple\">\n<dt>line_length: Total length of printed lines</dt><dd><p>(e.g. set this to adapt the display to different\nterminal window sizes).</p>\n</dd>\n<dt>positions: Relative or absolute positions of log elements</dt><dd><p>in each line. If not provided,\ndefaults to <cite>[.33, .55, .67, 1.]</cite>.</p>\n</dd>\n<dt>print_fn: Print function to use. Defaults to <cite>print</cite>.</dt><dd><p>It will be called on each line of the summary.\nYou can set it to a custom function\nin order to capture the string summary.</p>\n</dd>\n<dt>expand_nested: Whether to expand the nested models.</dt><dd><p>If not provided, defaults to <cite>False</cite>.</p>\n</dd>\n<dt>show_trainable: Whether to show if a layer is trainable.</dt><dd><p>If not provided, defaults to <cite>False</cite>.</p>\n</dd>\n</dl>\n</dd>\n<dt>Raises:</dt><dd><p>ValueError: if <cite>summary()</cite> is called before the model is built.</p>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.test_on_batch\">\n<span class=\"sig-name descname\"><span class=\"pre\">test_on_batch</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">x</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">y</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">sample_weight</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">reset_metrics</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">True</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">return_dict</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.test_on_batch\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Test the model on a single batch of samples.</p>\n<dl class=\"simple\">\n<dt>Args:</dt><dd><dl class=\"simple\">\n<dt>x: Input data. It could be:</dt><dd><ul class=\"simple\">\n<li><dl class=\"simple\">\n<dt>A Numpy array (or array-like), or a list of arrays (in case the</dt><dd><p>model has multiple inputs).</p>\n</dd>\n</dl>\n</li>\n<li><dl class=\"simple\">\n<dt>A TensorFlow tensor, or a list of tensors (in case the model has</dt><dd><p>multiple inputs).</p>\n</dd>\n</dl>\n</li>\n<li><dl class=\"simple\">\n<dt>A dict mapping input names to the corresponding array/tensors, if</dt><dd><p>the model has named inputs.</p>\n</dd>\n</dl>\n</li>\n</ul>\n</dd>\n<dt>y: Target data. Like the input data <cite>x</cite>, it could be either Numpy</dt><dd><p>array(s) or TensorFlow tensor(s). It should be consistent with <cite>x</cite>\n(you cannot have Numpy inputs and tensor targets, or inversely).</p>\n</dd>\n<dt>sample_weight: Optional array of the same length as x, containing</dt><dd><p>weights to apply to the model\u2019s loss for each sample. In the case of\ntemporal data, you can pass a 2D array with shape (samples,\nsequence_length), to apply a different weight to every timestep of\nevery sample.</p>\n</dd>\n<dt>reset_metrics: If <cite>True</cite>, the metrics returned will be only for this</dt><dd><p>batch. If <cite>False</cite>, the metrics will be statefully accumulated across\nbatches.</p>\n</dd>\n<dt>return_dict: If <cite>True</cite>, loss and metric results are returned as a dict,</dt><dd><p>with each key being the name of the metric. If <cite>False</cite>, they are\nreturned as a list.</p>\n</dd>\n</dl>\n</dd>\n<dt>Returns:</dt><dd><p>Scalar test loss (if the model has a single output and no metrics)\nor list of scalars (if the model has multiple outputs\nand/or metrics). The attribute <cite>model.metrics_names</cite> will give you\nthe display labels for the scalar outputs.</p>\n</dd>\n<dt>Raises:</dt><dd><p>RuntimeError: If <cite>model.test_on_batch</cite> is wrapped in a <cite>tf.function</cite>.</p>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.test_step\">\n<span class=\"sig-name descname\"><span class=\"pre\">test_step</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">data</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.test_step\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>The logic for one evaluation step.</p>\n<p>This method can be overridden to support custom evaluation logic.\nThis method is called by <cite>Model.make_test_function</cite>.</p>\n<p>This function should contain the mathematical logic for one step of\nevaluation.\nThis typically includes the forward pass, loss calculation, and metrics\nupdates.</p>\n<p>Configuration details for <em>how</em> this logic is run (e.g. <cite>tf.function</cite> and\n<cite>tf.distribute.Strategy</cite> settings), should be left to\n<cite>Model.make_test_function</cite>, which can also be overridden.</p>\n<dl class=\"simple\">\n<dt>Args:</dt><dd><p>data: A nested structure of <a href=\"#id103\"><span class=\"problematic\" id=\"id104\">`</span></a>Tensor`s.</p>\n</dd>\n<dt>Returns:</dt><dd><p>A <cite>dict</cite> containing values that will be passed to\n<cite>tf.keras.callbacks.CallbackList.on_train_batch_end</cite>. Typically, the\nvalues of the <cite>Model</cite>\u2019s metrics are returned.</p>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.to_json\">\n<span class=\"sig-name descname\"><span class=\"pre\">to_json</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"o\"><span class=\"pre\">**</span></span><span class=\"n\"><span class=\"pre\">kwargs</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.to_json\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Returns a JSON string containing the network configuration.</p>\n<p>To load a network from a JSON save file, use\n<cite>keras.models.model_from_json(json_string, custom_objects={})</cite>.</p>\n<dl class=\"simple\">\n<dt>Args:</dt><dd><dl class=\"simple\">\n<dt><a href=\"#id105\"><span class=\"problematic\" id=\"id106\">**</span></a>kwargs: Additional keyword arguments</dt><dd><p>to be passed to <cite>json.dumps()</cite>.</p>\n</dd>\n</dl>\n</dd>\n<dt>Returns:</dt><dd><p>A JSON string.</p>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.to_yaml\">\n<span class=\"sig-name descname\"><span class=\"pre\">to_yaml</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"o\"><span class=\"pre\">**</span></span><span class=\"n\"><span class=\"pre\">kwargs</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.to_yaml\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Returns a yaml string containing the network configuration.</p>\n<p>Note: Since TF 2.6, this method is no longer supported and will raise a\nRuntimeError.</p>\n<p>To load a network from a yaml save file, use\n<cite>keras.models.model_from_yaml(yaml_string, custom_objects={})</cite>.</p>\n<p><cite>custom_objects</cite> should be a dictionary mapping\nthe names of custom losses / layers / etc to the corresponding\nfunctions / classes.</p>\n<dl class=\"simple\">\n<dt>Args:</dt><dd><dl class=\"simple\">\n<dt><a href=\"#id107\"><span class=\"problematic\" id=\"id108\">**</span></a>kwargs: Additional keyword arguments</dt><dd><p>to be passed to <cite>yaml.dump()</cite>.</p>\n</dd>\n</dl>\n</dd>\n<dt>Returns:</dt><dd><p>A YAML string.</p>\n</dd>\n<dt>Raises:</dt><dd><p>RuntimeError: announces that the method poses a security risk</p>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.train_on_batch\">\n<span class=\"sig-name descname\"><span class=\"pre\">train_on_batch</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">x</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">y</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">sample_weight</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">class_weight</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">reset_metrics</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">True</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">return_dict</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.train_on_batch\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Runs a single gradient update on a single batch of data.</p>\n<dl class=\"simple\">\n<dt>Args:</dt><dd><dl class=\"simple\">\n<dt>x: Input data. It could be:</dt><dd><ul class=\"simple\">\n<li><dl class=\"simple\">\n<dt>A Numpy array (or array-like), or a list of arrays</dt><dd><p>(in case the model has multiple inputs).</p>\n</dd>\n</dl>\n</li>\n<li><dl class=\"simple\">\n<dt>A TensorFlow tensor, or a list of tensors</dt><dd><p>(in case the model has multiple inputs).</p>\n</dd>\n</dl>\n</li>\n<li><dl class=\"simple\">\n<dt>A dict mapping input names to the corresponding array/tensors,</dt><dd><p>if the model has named inputs.</p>\n</dd>\n</dl>\n</li>\n</ul>\n</dd>\n<dt>y: Target data. Like the input data <cite>x</cite>, it could be either Numpy</dt><dd><p>array(s) or TensorFlow tensor(s). It should be consistent with <cite>x</cite>\n(you cannot have Numpy inputs and tensor targets, or inversely).</p>\n</dd>\n<dt>sample_weight: Optional array of the same length as x, containing</dt><dd><p>weights to apply to the model\u2019s loss for each sample. In the case of\ntemporal data, you can pass a 2D array with shape (samples,\nsequence_length), to apply a different weight to every timestep of\nevery sample.</p>\n</dd>\n<dt>class_weight: Optional dictionary mapping class indices (integers) to a</dt><dd><p>weight (float) to apply to the model\u2019s loss for the samples from this\nclass during training. This can be useful to tell the model to \u201cpay\nmore attention\u201d to samples from an under-represented class.</p>\n</dd>\n<dt>reset_metrics: If <cite>True</cite>, the metrics returned will be only for this</dt><dd><p>batch. If <cite>False</cite>, the metrics will be statefully accumulated across\nbatches.</p>\n</dd>\n<dt>return_dict: If <cite>True</cite>, loss and metric results are returned as a dict,</dt><dd><p>with each key being the name of the metric. If <cite>False</cite>, they are\nreturned as a list.</p>\n</dd>\n</dl>\n</dd>\n<dt>Returns:</dt><dd><p>Scalar training loss\n(if the model has a single output and no metrics)\nor list of scalars (if the model has multiple outputs\nand/or metrics). The attribute <cite>model.metrics_names</cite> will give you\nthe display labels for the scalar outputs.</p>\n</dd>\n<dt>Raises:</dt><dd><p>RuntimeError: If <cite>model.train_on_batch</cite> is wrapped in a <cite>tf.function</cite>.</p>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.train_step\">\n<span class=\"sig-name descname\"><span class=\"pre\">train_step</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">data</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.train_step\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>The logic for one training step.</p>\n<p>This method can be overridden to support custom training logic.\nFor concrete examples of how to override this method see\n[Customizing what happends in fit](<a class=\"reference external\" href=\"https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit\">https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit</a>).\nThis method is called by <cite>Model.make_train_function</cite>.</p>\n<p>This method should contain the mathematical logic for one step of training.\nThis typically includes the forward pass, loss calculation, backpropagation,\nand metric updates.</p>\n<p>Configuration details for <em>how</em> this logic is run (e.g. <cite>tf.function</cite> and\n<cite>tf.distribute.Strategy</cite> settings), should be left to\n<cite>Model.make_train_function</cite>, which can also be overridden.</p>\n<dl class=\"simple\">\n<dt>Args:</dt><dd><p>data: A nested structure of <a href=\"#id109\"><span class=\"problematic\" id=\"id110\">`</span></a>Tensor`s.</p>\n</dd>\n<dt>Returns:</dt><dd><p>A <cite>dict</cite> containing values that will be passed to\n<cite>tf.keras.callbacks.CallbackList.on_train_batch_end</cite>. Typically, the\nvalues of the <cite>Model</cite>\u2019s metrics are returned. Example:\n<cite>{\u2018loss\u2019: 0.2, \u2018accuracy\u2019: 0.7}</cite>.</p>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py property\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.trainable_weights\">\n<em class=\"property\"><span class=\"pre\">property</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">trainable_weights</span></span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.trainable_weights\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>List of all trainable weights tracked by this layer.</p>\n<p>Trainable weights are updated via gradient descent during training.</p>\n<dl class=\"simple\">\n<dt>Returns:</dt><dd><p>A list of trainable variables.</p>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py property\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Model.weights\">\n<em class=\"property\"><span class=\"pre\">property</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">weights</span></span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Model.weights\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Returns the list of all layer variables/weights.</p>\n<p>Note: This will not track the weights of nested <cite>tf.Modules</cite> that are not\nthemselves Keras layers.</p>\n<dl class=\"simple\">\n<dt>Returns:</dt><dd><p>A list of variables.</p>\n</dd>\n</dl>\n</dd></dl>\n\n</dd></dl>\n\n</section>\n<section id=\"version\">\n<h3><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.Version\" title=\"dipy.nn.histo_resdnn.Version\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Version</span></code></a><a class=\"headerlink\" href=\"#version\" title=\"Permalink to this headline\">\u00b6</a></h3>\n<dl class=\"py class\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Version\">\n<em class=\"property\"><span class=\"pre\">class</span><span class=\"w\"> </span></em><span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.histo_resdnn.</span></span><span class=\"sig-name descname\"><span class=\"pre\">Version</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">version</span></span><span class=\"p\"><span class=\"pre\">:</span></span><span class=\"w\"> </span><span class=\"n\"><a class=\"reference external\" href=\"https://docs.python.org/3/library/stdtypes.html#str\" title=\"(in Python v3.10)\"><span class=\"pre\">str</span></a></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Version\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Bases: <code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">packaging.version._BaseVersion</span></code></p>\n<dl class=\"field-list simple\">\n<dt class=\"field-odd\">Attributes</dt>\n<dd class=\"field-odd\"><dl class=\"simple\">\n<dt><strong>base_version</strong></dt><dd></dd>\n<dt><strong>dev</strong></dt><dd></dd>\n<dt><strong>epoch</strong></dt><dd></dd>\n<dt><strong>is_devrelease</strong></dt><dd></dd>\n<dt><strong>is_postrelease</strong></dt><dd></dd>\n<dt><strong>is_prerelease</strong></dt><dd></dd>\n<dt><strong>local</strong></dt><dd></dd>\n<dt><strong>major</strong></dt><dd></dd>\n<dt><strong>micro</strong></dt><dd></dd>\n<dt><strong>minor</strong></dt><dd></dd>\n<dt><strong>post</strong></dt><dd></dd>\n<dt><strong>pre</strong></dt><dd></dd>\n<dt><strong>public</strong></dt><dd></dd>\n<dt><strong>release</strong></dt><dd></dd>\n</dl>\n</dd>\n</dl>\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Version.__init__\">\n<span class=\"sig-name descname\"><span class=\"pre\">__init__</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">version</span></span><span class=\"p\"><span class=\"pre\">:</span></span><span class=\"w\"> </span><span class=\"n\"><a class=\"reference external\" href=\"https://docs.python.org/3/library/stdtypes.html#str\" title=\"(in Python v3.10)\"><span class=\"pre\">str</span></a></span></em><span class=\"sig-paren\">)</span> <span class=\"sig-return\"><span class=\"sig-return-icon\">&#x2192;</span> <span class=\"sig-return-typehint\"><a class=\"reference external\" href=\"https://docs.python.org/3/library/constants.html#None\" title=\"(in Python v3.10)\"><span class=\"pre\">None</span></a></span></span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Version.__init__\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py property\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Version.base_version\">\n<em class=\"property\"><span class=\"pre\">property</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">base_version</span></span><em class=\"property\"><span class=\"p\"><span class=\"pre\">:</span></span><span class=\"w\"> </span><a class=\"reference external\" href=\"https://docs.python.org/3/library/stdtypes.html#str\" title=\"(in Python v3.10)\"><span class=\"pre\">str</span></a></em><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Version.base_version\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py property\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Version.dev\">\n<em class=\"property\"><span class=\"pre\">property</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">dev</span></span><em class=\"property\"><span class=\"p\"><span class=\"pre\">:</span></span><span class=\"w\"> </span><span class=\"pre\">Optional</span><span class=\"p\"><span class=\"pre\">[</span></span><a class=\"reference external\" href=\"https://docs.python.org/3/library/functions.html#int\" title=\"(in Python v3.10)\"><span class=\"pre\">int</span></a><span class=\"p\"><span class=\"pre\">]</span></span></em><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Version.dev\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py property\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Version.epoch\">\n<em class=\"property\"><span class=\"pre\">property</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">epoch</span></span><em class=\"property\"><span class=\"p\"><span class=\"pre\">:</span></span><span class=\"w\"> </span><a class=\"reference external\" href=\"https://docs.python.org/3/library/functions.html#int\" title=\"(in Python v3.10)\"><span class=\"pre\">int</span></a></em><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Version.epoch\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py property\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Version.is_devrelease\">\n<em class=\"property\"><span class=\"pre\">property</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">is_devrelease</span></span><em class=\"property\"><span class=\"p\"><span class=\"pre\">:</span></span><span class=\"w\"> </span><a class=\"reference external\" href=\"https://docs.python.org/3/library/functions.html#bool\" title=\"(in Python v3.10)\"><span class=\"pre\">bool</span></a></em><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Version.is_devrelease\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py property\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Version.is_postrelease\">\n<em class=\"property\"><span class=\"pre\">property</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">is_postrelease</span></span><em class=\"property\"><span class=\"p\"><span class=\"pre\">:</span></span><span class=\"w\"> </span><a class=\"reference external\" href=\"https://docs.python.org/3/library/functions.html#bool\" title=\"(in Python v3.10)\"><span class=\"pre\">bool</span></a></em><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Version.is_postrelease\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py property\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Version.is_prerelease\">\n<em class=\"property\"><span class=\"pre\">property</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">is_prerelease</span></span><em class=\"property\"><span class=\"p\"><span class=\"pre\">:</span></span><span class=\"w\"> </span><a class=\"reference external\" href=\"https://docs.python.org/3/library/functions.html#bool\" title=\"(in Python v3.10)\"><span class=\"pre\">bool</span></a></em><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Version.is_prerelease\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py property\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Version.local\">\n<em class=\"property\"><span class=\"pre\">property</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">local</span></span><em class=\"property\"><span class=\"p\"><span class=\"pre\">:</span></span><span class=\"w\"> </span><span class=\"pre\">Optional</span><span class=\"p\"><span class=\"pre\">[</span></span><a class=\"reference external\" href=\"https://docs.python.org/3/library/stdtypes.html#str\" title=\"(in Python v3.10)\"><span class=\"pre\">str</span></a><span class=\"p\"><span class=\"pre\">]</span></span></em><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Version.local\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py property\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Version.major\">\n<em class=\"property\"><span class=\"pre\">property</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">major</span></span><em class=\"property\"><span class=\"p\"><span class=\"pre\">:</span></span><span class=\"w\"> </span><a class=\"reference external\" href=\"https://docs.python.org/3/library/functions.html#int\" title=\"(in Python v3.10)\"><span class=\"pre\">int</span></a></em><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Version.major\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py property\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Version.micro\">\n<em class=\"property\"><span class=\"pre\">property</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">micro</span></span><em class=\"property\"><span class=\"p\"><span class=\"pre\">:</span></span><span class=\"w\"> </span><a class=\"reference external\" href=\"https://docs.python.org/3/library/functions.html#int\" title=\"(in Python v3.10)\"><span class=\"pre\">int</span></a></em><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Version.micro\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py property\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Version.minor\">\n<em class=\"property\"><span class=\"pre\">property</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">minor</span></span><em class=\"property\"><span class=\"p\"><span class=\"pre\">:</span></span><span class=\"w\"> </span><a class=\"reference external\" href=\"https://docs.python.org/3/library/functions.html#int\" title=\"(in Python v3.10)\"><span class=\"pre\">int</span></a></em><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Version.minor\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py property\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Version.post\">\n<em class=\"property\"><span class=\"pre\">property</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">post</span></span><em class=\"property\"><span class=\"p\"><span class=\"pre\">:</span></span><span class=\"w\"> </span><span class=\"pre\">Optional</span><span class=\"p\"><span class=\"pre\">[</span></span><a class=\"reference external\" href=\"https://docs.python.org/3/library/functions.html#int\" title=\"(in Python v3.10)\"><span class=\"pre\">int</span></a><span class=\"p\"><span class=\"pre\">]</span></span></em><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Version.post\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py property\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Version.pre\">\n<em class=\"property\"><span class=\"pre\">property</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">pre</span></span><em class=\"property\"><span class=\"p\"><span class=\"pre\">:</span></span><span class=\"w\"> </span><span class=\"pre\">Optional</span><span class=\"p\"><span class=\"pre\">[</span></span><span class=\"pre\">Tuple</span><span class=\"p\"><span class=\"pre\">[</span></span><a class=\"reference external\" href=\"https://docs.python.org/3/library/stdtypes.html#str\" title=\"(in Python v3.10)\"><span class=\"pre\">str</span></a><span class=\"p\"><span class=\"pre\">,</span></span><span class=\"w\"> </span><a class=\"reference external\" href=\"https://docs.python.org/3/library/functions.html#int\" title=\"(in Python v3.10)\"><span class=\"pre\">int</span></a><span class=\"p\"><span class=\"pre\">]</span></span><span class=\"p\"><span class=\"pre\">]</span></span></em><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Version.pre\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py property\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Version.public\">\n<em class=\"property\"><span class=\"pre\">property</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">public</span></span><em class=\"property\"><span class=\"p\"><span class=\"pre\">:</span></span><span class=\"w\"> </span><a class=\"reference external\" href=\"https://docs.python.org/3/library/stdtypes.html#str\" title=\"(in Python v3.10)\"><span class=\"pre\">str</span></a></em><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Version.public\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py property\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Version.release\">\n<em class=\"property\"><span class=\"pre\">property</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">release</span></span><em class=\"property\"><span class=\"p\"><span class=\"pre\">:</span></span><span class=\"w\"> </span><span class=\"pre\">Tuple</span><span class=\"p\"><span class=\"pre\">[</span></span><a class=\"reference external\" href=\"https://docs.python.org/3/library/functions.html#int\" title=\"(in Python v3.10)\"><span class=\"pre\">int</span></a><span class=\"p\"><span class=\"pre\">,</span></span><span class=\"w\"> </span><span class=\"p\"><span class=\"pre\">...</span></span><span class=\"p\"><span class=\"pre\">]</span></span></em><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Version.release\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n</dd></dl>\n\n</section>\n<section id=\"input\">\n<h3>Input<a class=\"headerlink\" href=\"#input\" title=\"Permalink to this headline\">\u00b6</a></h3>\n<dl class=\"py function\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.Input\">\n<span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.histo_resdnn.</span></span><span class=\"sig-name descname\"><span class=\"pre\">Input</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">shape</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">batch_size</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">name</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">dtype</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">sparse</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">tensor</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">ragged</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">type_spec</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"o\"><span class=\"pre\">**</span></span><span class=\"n\"><span class=\"pre\">kwargs</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.Input\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p><cite>Input()</cite> is used to instantiate a Keras tensor.</p>\n<p>A Keras tensor is a symbolic tensor-like object,\nwhich we augment with certain attributes that allow us to build a Keras model\njust by knowing the inputs and outputs of the model.</p>\n<p>For instance, if <cite>a</cite>, <cite>b</cite> and <cite>c</cite> are Keras tensors,\nit becomes possible to do:\n<cite>model = Model(input=[a, b], output=c)</cite></p>\n<dl>\n<dt>Args:</dt><dd><dl class=\"simple\">\n<dt>shape: A shape tuple (integers), not including the batch size.</dt><dd><p>For instance, <cite>shape=(32,)</cite> indicates that the expected input\nwill be batches of 32-dimensional vectors. Elements of this tuple\ncan be None; \u2018None\u2019 elements represent dimensions where the shape is\nnot known.</p>\n</dd>\n</dl>\n<p>batch_size: optional static batch size (integer).\nname: An optional name string for the layer.</p>\n<blockquote>\n<div><p>Should be unique in a model (do not reuse the same name twice).\nIt will be autogenerated if it isn\u2019t provided.</p>\n</div></blockquote>\n<dl class=\"simple\">\n<dt>dtype: The data type expected by the input, as a string</dt><dd><p>(<cite>float32</cite>, <cite>float64</cite>, <cite>int32</cite>\u2026)</p>\n</dd>\n<dt>sparse: A boolean specifying whether the placeholder to be created is</dt><dd><p>sparse. Only one of \u2018ragged\u2019 and \u2018sparse\u2019 can be True. Note that,\nif <cite>sparse</cite> is False, sparse tensors can still be passed into the\ninput - they will be densified with a default value of 0.</p>\n</dd>\n<dt>tensor: Optional existing tensor to wrap into the <cite>Input</cite> layer.</dt><dd><p>If set, the layer will use the <cite>tf.TypeSpec</cite> of this tensor rather\nthan creating a new placeholder tensor.</p>\n</dd>\n<dt>ragged: A boolean specifying whether the placeholder to be created is</dt><dd><p>ragged. Only one of \u2018ragged\u2019 and \u2018sparse\u2019 can be True. In this case,\nvalues of \u2018None\u2019 in the \u2018shape\u2019 argument represent ragged dimensions.\nFor more information about RaggedTensors, see\n[this guide](<a class=\"reference external\" href=\"https://www.tensorflow.org/guide/ragged_tensors\">https://www.tensorflow.org/guide/ragged_tensors</a>).</p>\n</dd>\n<dt>type_spec: A <cite>tf.TypeSpec</cite> object to create the input placeholder from.</dt><dd><p>When provided, all other args except name must be None.</p>\n</dd>\n<dt><a href=\"#id111\"><span class=\"problematic\" id=\"id112\">**</span></a>kwargs: deprecated arguments support. Supports <cite>batch_shape</cite> and</dt><dd><p><cite>batch_input_shape</cite>.</p>\n</dd>\n</dl>\n</dd>\n<dt>Returns:</dt><dd><p>A <cite>tensor</cite>.</p>\n</dd>\n</dl>\n<p>Example:</p>\n<p><code class=\"docutils literal notranslate\"><span class=\"pre\">`python</span>\n<span class=\"pre\">#</span> <span class=\"pre\">this</span> <span class=\"pre\">is</span> <span class=\"pre\">a</span> <span class=\"pre\">logistic</span> <span class=\"pre\">regression</span> <span class=\"pre\">in</span> <span class=\"pre\">Keras</span>\n<span class=\"pre\">x</span> <span class=\"pre\">=</span> <span class=\"pre\">Input(shape=(32,))</span>\n<span class=\"pre\">y</span> <span class=\"pre\">=</span> <span class=\"pre\">Dense(16,</span> <span class=\"pre\">activation='softmax')(x)</span>\n<span class=\"pre\">model</span> <span class=\"pre\">=</span> <span class=\"pre\">Model(x,</span> <span class=\"pre\">y)</span>\n<span class=\"pre\">`</span></code></p>\n<p>Note that even if eager execution is enabled,\n<cite>Input</cite> produces a symbolic tensor-like object (i.e. a placeholder).\nThis symbolic tensor-like object can be used with lower-level\nTensorFlow ops that take tensors as inputs, as such:</p>\n<p><code class=\"docutils literal notranslate\"><span class=\"pre\">`python</span>\n<span class=\"pre\">x</span> <span class=\"pre\">=</span> <span class=\"pre\">Input(shape=(32,))</span>\n<span class=\"pre\">y</span> <span class=\"pre\">=</span> <span class=\"pre\">tf.square(x)</span>&#160; <span class=\"pre\">#</span> <span class=\"pre\">This</span> <span class=\"pre\">op</span> <span class=\"pre\">will</span> <span class=\"pre\">be</span> <span class=\"pre\">treated</span> <span class=\"pre\">like</span> <span class=\"pre\">a</span> <span class=\"pre\">layer</span>\n<span class=\"pre\">model</span> <span class=\"pre\">=</span> <span class=\"pre\">Model(x,</span> <span class=\"pre\">y)</span>\n<span class=\"pre\">`</span></code></p>\n<p>(This behavior does not work for higher-order TensorFlow APIs such as\ncontrol flow and being directly watched by a <cite>tf.GradientTape</cite>).</p>\n<p>However, the resulting model will not track any variables that were\nused as inputs to TensorFlow ops. All variable usages must happen within\nKeras layers to make sure they will be tracked by the model\u2019s weights.</p>\n<p>The Keras Input can also create a placeholder from an arbitrary <cite>tf.TypeSpec</cite>,\ne.g:</p>\n<p><a href=\"#id113\"><span class=\"problematic\" id=\"id114\">``</span></a><a href=\"#id115\"><span class=\"problematic\" id=\"id116\">`</span></a>python\nx = Input(type_spec=tf.RaggedTensorSpec(shape=[None, None],</p>\n<blockquote>\n<div><p>dtype=tf.float32, ragged_rank=1))</p>\n</div></blockquote>\n<p>y = x.values\nmodel = Model(x, y)\n<a href=\"#id117\"><span class=\"problematic\" id=\"id118\">``</span></a>`\nWhen passing an arbitrary <cite>tf.TypeSpec</cite>, it must represent the signature of an\nentire batch instead of just one example.</p>\n<dl>\n<dt>Raises:</dt><dd><p>ValueError: If both <cite>sparse</cite> and <cite>ragged</cite> are provided.\nValueError: If both <cite>shape</cite> and (<cite>batch_input_shape</cite> or <cite>batch_shape</cite>) are</p>\n<blockquote>\n<div><p>provided.</p>\n</div></blockquote>\n<p>ValueError: If <cite>shape</cite>, <cite>tensor</cite> and <cite>type_spec</cite> are None.\nValueError: If arguments besides <cite>type_spec</cite> are non-None while <cite>type_spec</cite></p>\n<blockquote>\n<div><p>is passed.</p>\n</div></blockquote>\n<p>ValueError: if any unrecognized parameters are provided.</p>\n</dd>\n</dl>\n</dd></dl>\n\n</section>\n<section id=\"doctest-skip-parser\">\n<h3>doctest_skip_parser<a class=\"headerlink\" href=\"#doctest-skip-parser\" title=\"Permalink to this headline\">\u00b6</a></h3>\n<dl class=\"py function\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.doctest_skip_parser\">\n<span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.histo_resdnn.</span></span><span class=\"sig-name descname\"><span class=\"pre\">doctest_skip_parser</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">func</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.doctest_skip_parser\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Decorator replaces custom skip test markup in doctests.</p>\n<p>Say a function has a docstring:</p>\n<div class=\"highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">something</span> <span class=\"c1\"># skip if not HAVE_AMODULE</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">something</span> <span class=\"o\">+</span> <span class=\"k\">else</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">something</span> <span class=\"c1\"># skip if HAVE_BMODULE</span>\n</pre></div>\n</div>\n<p>This decorator will evaluate the expresssion after <code class=\"docutils literal notranslate\"><span class=\"pre\">skip</span> <span class=\"pre\">if</span></code>.  If this\nevaluates to True, then the comment is replaced by <code class=\"docutils literal notranslate\"><span class=\"pre\">#</span> <span class=\"pre\">doctest:</span> <span class=\"pre\">+SKIP</span></code>.\nIf False, then the comment is just removed. The expression is evaluated in\nthe <code class=\"docutils literal notranslate\"><span class=\"pre\">globals</span></code> scope of <cite>func</cite>.</p>\n<p>For example, if the module global <code class=\"docutils literal notranslate\"><span class=\"pre\">HAVE_AMODULE</span></code> is False, and module\nglobal <code class=\"docutils literal notranslate\"><span class=\"pre\">HAVE_BMODULE</span></code> is False, the returned function will have\ndocstring:</p>\n<div class=\"highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">something</span> \n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">something</span> <span class=\"o\">+</span> <span class=\"k\">else</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">something</span>\n</pre></div>\n</div>\n</dd></dl>\n\n</section>\n<section id=\"get-bval-indices\">\n<h3>get_bval_indices<a class=\"headerlink\" href=\"#get-bval-indices\" title=\"Permalink to this headline\">\u00b6</a></h3>\n<dl class=\"py function\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.get_bval_indices\">\n<span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.histo_resdnn.</span></span><span class=\"sig-name descname\"><span class=\"pre\">get_bval_indices</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">bvals</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">bval</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">tol</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">20</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.get_bval_indices\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Get indices where the b-value is <cite>bval</cite></p>\n<dl class=\"field-list simple\">\n<dt class=\"field-odd\">Parameters</dt>\n<dd class=\"field-odd\"><dl class=\"simple\">\n<dt><strong>bvals: ndarray</strong></dt><dd><p>Array containing the b-values</p>\n</dd>\n<dt><strong>bval: float or int</strong></dt><dd><p>b-value to extract indices</p>\n</dd>\n<dt><strong>tol: int</strong></dt><dd><p>The tolerated gap between the b-values to extract\nand the actual b-values.</p>\n</dd>\n</dl>\n</dd>\n<dt class=\"field-even\">Returns</dt>\n<dd class=\"field-even\"><dl class=\"simple\">\n<dt>Array of indices where the b-value is <cite>bval</cite></dt><dd></dd>\n</dl>\n</dd>\n</dl>\n</dd></dl>\n\n</section>\n<section id=\"get-fnames\">\n<h3>get_fnames<a class=\"headerlink\" href=\"#get-fnames\" title=\"Permalink to this headline\">\u00b6</a></h3>\n<dl class=\"py function\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.get_fnames\">\n<span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.histo_resdnn.</span></span><span class=\"sig-name descname\"><span class=\"pre\">get_fnames</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">name</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'small_64D'</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.get_fnames\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Provide full paths to example or test datasets.</p>\n<dl class=\"field-list simple\">\n<dt class=\"field-odd\">Parameters</dt>\n<dd class=\"field-odd\"><dl class=\"simple\">\n<dt><strong>name</strong><span class=\"classifier\">str</span></dt><dd><p>the filename/s of which dataset to return, one of:</p>\n<ul class=\"simple\">\n<li><p>\u2018small_64D\u2019 small region of interest nifti,bvecs,bvals 64 directions</p></li>\n<li><p>\u2018small_101D\u2019 small region of interest nifti, bvecs, bvals\n101 directions</p></li>\n<li><p>\u2018aniso_vox\u2019 volume with anisotropic voxel size as Nifti</p></li>\n<li><p>\u2018fornix\u2019 300 tracks in Trackvis format (from Pittsburgh\nBrain Competition)</p></li>\n<li><p>\u2018gqi_vectors\u2019 the scanner wave vectors needed for a GQI acquisitions\nof 101 directions tested on Siemens 3T Trio</p></li>\n<li><p>\u2018small_25\u2019 small ROI (10x8x2) DTI data (b value 2000, 25 directions)</p></li>\n<li><p>\u2018test_piesno\u2019 slice of N=8, K=14 diffusion data</p></li>\n<li><p>\u2018reg_c\u2019 small 2D image used for validating registration</p></li>\n<li><p>\u2018reg_o\u2019 small 2D image used for validation registration</p></li>\n<li><p>\u2018cb_2\u2019 two vectorized cingulum bundles</p></li>\n</ul>\n</dd>\n</dl>\n</dd>\n<dt class=\"field-even\">Returns</dt>\n<dd class=\"field-even\"><dl class=\"simple\">\n<dt><strong>fnames</strong><span class=\"classifier\">tuple</span></dt><dd><p>filenames for dataset</p>\n</dd>\n</dl>\n</dd>\n</dl>\n<p class=\"rubric\">Examples</p>\n<div class=\"doctest highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">dipy.io.image</span> <span class=\"kn\">import</span> <span class=\"n\">load_nifti</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">dipy.data</span> <span class=\"kn\">import</span> <span class=\"n\">get_fnames</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">fimg</span><span class=\"p\">,</span> <span class=\"n\">fbvals</span><span class=\"p\">,</span> <span class=\"n\">fbvecs</span> <span class=\"o\">=</span> <span class=\"n\">get_fnames</span><span class=\"p\">(</span><span class=\"s1\">&#39;small_101D&#39;</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">bvals</span><span class=\"o\">=</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">loadtxt</span><span class=\"p\">(</span><span class=\"n\">fbvals</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">bvecs</span><span class=\"o\">=</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">loadtxt</span><span class=\"p\">(</span><span class=\"n\">fbvecs</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">T</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">affine</span> <span class=\"o\">=</span> <span class=\"n\">load_nifti</span><span class=\"p\">(</span><span class=\"n\">fimg</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">shape</span> <span class=\"o\">==</span> <span class=\"p\">(</span><span class=\"mi\">6</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">102</span><span class=\"p\">)</span>\n<span class=\"go\">True</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">bvals</span><span class=\"o\">.</span><span class=\"n\">shape</span> <span class=\"o\">==</span> <span class=\"p\">(</span><span class=\"mi\">102</span><span class=\"p\">,)</span>\n<span class=\"go\">True</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">bvecs</span><span class=\"o\">.</span><span class=\"n\">shape</span> <span class=\"o\">==</span> <span class=\"p\">(</span><span class=\"mi\">102</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">)</span>\n<span class=\"go\">True</span>\n</pre></div>\n</div>\n</dd></dl>\n\n</section>\n<section id=\"get-sphere\">\n<h3>get_sphere<a class=\"headerlink\" href=\"#get-sphere\" title=\"Permalink to this headline\">\u00b6</a></h3>\n<dl class=\"py function\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.get_sphere\">\n<span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.histo_resdnn.</span></span><span class=\"sig-name descname\"><span class=\"pre\">get_sphere</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">name</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'symmetric362'</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.get_sphere\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>provide triangulated spheres</p>\n<dl class=\"field-list simple\">\n<dt class=\"field-odd\">Parameters</dt>\n<dd class=\"field-odd\"><dl class=\"simple\">\n<dt><strong>name</strong><span class=\"classifier\">str</span></dt><dd><p>which sphere - one of:\n* \u2018symmetric362\u2019\n* \u2018symmetric642\u2019\n* \u2018symmetric724\u2019\n* \u2018repulsion724\u2019\n* \u2018repulsion100\u2019\n* \u2018repulsion200\u2019</p>\n</dd>\n</dl>\n</dd>\n<dt class=\"field-even\">Returns</dt>\n<dd class=\"field-even\"><dl class=\"simple\">\n<dt><strong>sphere</strong><span class=\"classifier\">a dipy.core.sphere.Sphere class instance</span></dt><dd></dd>\n</dl>\n</dd>\n</dl>\n<p class=\"rubric\">Examples</p>\n<div class=\"doctest highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">dipy.data</span> <span class=\"kn\">import</span> <span class=\"n\">get_sphere</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">sphere</span> <span class=\"o\">=</span> <span class=\"n\">get_sphere</span><span class=\"p\">(</span><span class=\"s1\">&#39;symmetric362&#39;</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">verts</span><span class=\"p\">,</span> <span class=\"n\">faces</span> <span class=\"o\">=</span> <span class=\"n\">sphere</span><span class=\"o\">.</span><span class=\"n\">vertices</span><span class=\"p\">,</span> <span class=\"n\">sphere</span><span class=\"o\">.</span><span class=\"n\">faces</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">verts</span><span class=\"o\">.</span><span class=\"n\">shape</span> <span class=\"o\">==</span> <span class=\"p\">(</span><span class=\"mi\">362</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">)</span>\n<span class=\"go\">True</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">faces</span><span class=\"o\">.</span><span class=\"n\">shape</span> <span class=\"o\">==</span> <span class=\"p\">(</span><span class=\"mi\">720</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">)</span>\n<span class=\"go\">True</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">verts</span><span class=\"p\">,</span> <span class=\"n\">faces</span> <span class=\"o\">=</span> <span class=\"n\">get_sphere</span><span class=\"p\">(</span><span class=\"s1\">&#39;not a sphere name&#39;</span><span class=\"p\">)</span> \n<span class=\"gt\">Traceback (most recent call last):</span>\n    <span class=\"o\">...</span>\n<span class=\"gr\">DataError</span>: <span class=\"n\">No sphere called &quot;not a sphere name&quot;</span>\n</pre></div>\n</div>\n</dd></dl>\n\n</section>\n<section id=\"optional-package\">\n<h3>optional_package<a class=\"headerlink\" href=\"#optional-package\" title=\"Permalink to this headline\">\u00b6</a></h3>\n<dl class=\"py function\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.optional_package\">\n<span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.histo_resdnn.</span></span><span class=\"sig-name descname\"><span class=\"pre\">optional_package</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">name</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">trip_msg</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.optional_package\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Return package-like thing and module setup for package <cite>name</cite></p>\n<dl class=\"field-list\">\n<dt class=\"field-odd\">Parameters</dt>\n<dd class=\"field-odd\"><dl class=\"simple\">\n<dt><strong>name</strong><span class=\"classifier\">str</span></dt><dd><p>package name</p>\n</dd>\n<dt><strong>trip_msg</strong><span class=\"classifier\">None or str</span></dt><dd><p>message to give when someone tries to use the return package, but we\ncould not import it, and have returned a TripWire object instead.\nDefault message if None.</p>\n</dd>\n</dl>\n</dd>\n<dt class=\"field-even\">Returns</dt>\n<dd class=\"field-even\"><dl>\n<dt><strong>pkg_like</strong><span class=\"classifier\">module or <code class=\"docutils literal notranslate\"><span class=\"pre\">TripWire</span></code> instance</span></dt><dd><p>If we can import the package, return it.  Otherwise return an object\nraising an error when accessed</p>\n</dd>\n<dt><strong>have_pkg</strong><span class=\"classifier\">bool</span></dt><dd><p>True if import for package was successful, false otherwise</p>\n</dd>\n<dt><strong>module_setup</strong><span class=\"classifier\">function</span></dt><dd><p>callable usually set as <code class=\"docutils literal notranslate\"><span class=\"pre\">setup_module</span></code> in calling namespace, to allow\nskipping tests.</p>\n</dd>\n</dl>\n</dd>\n</dl>\n<p class=\"rubric\">Examples</p>\n<p>Typical use would be something like this at the top of a module using an\noptional package:</p>\n<div class=\"doctest highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">dipy.utils.optpkg</span> <span class=\"kn\">import</span> <span class=\"n\">optional_package</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">pkg</span><span class=\"p\">,</span> <span class=\"n\">have_pkg</span><span class=\"p\">,</span> <span class=\"n\">setup_module</span> <span class=\"o\">=</span> <span class=\"n\">optional_package</span><span class=\"p\">(</span><span class=\"s1\">&#39;not_a_package&#39;</span><span class=\"p\">)</span>\n</pre></div>\n</div>\n<p>Of course in this case the package doesn\u2019t exist, and so, in the module:</p>\n<div class=\"doctest highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">have_pkg</span>\n<span class=\"go\">False</span>\n</pre></div>\n</div>\n<p>and</p>\n<div class=\"doctest highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">pkg</span><span class=\"o\">.</span><span class=\"n\">some_function</span><span class=\"p\">()</span> \n<span class=\"gt\">Traceback (most recent call last):</span>\n    <span class=\"o\">...</span>\n<span class=\"gr\">TripWireError</span>: <span class=\"n\">We need package not_a_package for these functions, but</span>\n<span class=\"go\">``import not_a_package`` raised an ImportError</span>\n</pre></div>\n</div>\n<p>If the module does exist - we get the module</p>\n<div class=\"doctest highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">pkg</span><span class=\"p\">,</span> <span class=\"n\">_</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">=</span> <span class=\"n\">optional_package</span><span class=\"p\">(</span><span class=\"s1\">&#39;os&#39;</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"nb\">hasattr</span><span class=\"p\">(</span><span class=\"n\">pkg</span><span class=\"p\">,</span> <span class=\"s1\">&#39;path&#39;</span><span class=\"p\">)</span>\n<span class=\"go\">True</span>\n</pre></div>\n</div>\n<p>Or a submodule if that\u2019s what we asked for</p>\n<div class=\"doctest highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">subpkg</span><span class=\"p\">,</span> <span class=\"n\">_</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">=</span> <span class=\"n\">optional_package</span><span class=\"p\">(</span><span class=\"s1\">&#39;os.path&#39;</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"nb\">hasattr</span><span class=\"p\">(</span><span class=\"n\">subpkg</span><span class=\"p\">,</span> <span class=\"s1\">&#39;dirname&#39;</span><span class=\"p\">)</span>\n<span class=\"go\">True</span>\n</pre></div>\n</div>\n</dd></dl>\n\n</section>\n<section id=\"set-logger-level\">\n<h3>set_logger_level<a class=\"headerlink\" href=\"#set-logger-level\" title=\"Permalink to this headline\">\u00b6</a></h3>\n<dl class=\"py function\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.set_logger_level\">\n<span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.histo_resdnn.</span></span><span class=\"sig-name descname\"><span class=\"pre\">set_logger_level</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">log_level</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.set_logger_level\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Change the logger of the HistoResDNN to one on the following:\nDEBUG, INFO, WARNING, CRITICAL, ERROR</p>\n<dl class=\"field-list simple\">\n<dt class=\"field-odd\">Parameters</dt>\n<dd class=\"field-odd\"><dl class=\"simple\">\n<dt><strong>log_level</strong><span class=\"classifier\">str</span></dt><dd><p>Log level for the HistoResDNN only</p>\n</dd>\n</dl>\n</dd>\n</dl>\n</dd></dl>\n\n</section>\n<section id=\"sf-to-sh\">\n<h3>sf_to_sh<a class=\"headerlink\" href=\"#sf-to-sh\" title=\"Permalink to this headline\">\u00b6</a></h3>\n<dl class=\"py function\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.sf_to_sh\">\n<span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.histo_resdnn.</span></span><span class=\"sig-name descname\"><span class=\"pre\">sf_to_sh</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">sf</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">sphere</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">sh_order</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">4</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">basis_type</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">full_basis</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">legacy</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">True</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">smooth</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">0.0</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.sf_to_sh\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Spherical function to spherical harmonics (SH).</p>\n<dl class=\"field-list simple\">\n<dt class=\"field-odd\">Parameters</dt>\n<dd class=\"field-odd\"><dl class=\"simple\">\n<dt><strong>sf</strong><span class=\"classifier\">ndarray</span></dt><dd><p>Values of a function on the given <code class=\"docutils literal notranslate\"><span class=\"pre\">sphere</span></code>.</p>\n</dd>\n<dt><strong>sphere</strong><span class=\"classifier\">Sphere</span></dt><dd><p>The points on which the sf is defined.</p>\n</dd>\n<dt><strong>sh_order</strong><span class=\"classifier\">int, optional</span></dt><dd><p>Maximum SH order in the SH fit.  For <code class=\"docutils literal notranslate\"><span class=\"pre\">sh_order</span></code>, there will be\n<code class=\"docutils literal notranslate\"><span class=\"pre\">(sh_order</span> <span class=\"pre\">+</span> <span class=\"pre\">1)</span> <span class=\"pre\">*</span> <span class=\"pre\">(sh_order</span> <span class=\"pre\">+</span> <span class=\"pre\">2)</span> <span class=\"pre\">/</span> <span class=\"pre\">2</span></code> SH coefficients for a symmetric\nbasis and <code class=\"docutils literal notranslate\"><span class=\"pre\">(sh_order</span> <span class=\"pre\">+</span> <span class=\"pre\">1)</span> <span class=\"pre\">*</span> <span class=\"pre\">(sh_order</span> <span class=\"pre\">+</span> <span class=\"pre\">1)</span></code> coefficients for a full\nSH basis.</p>\n</dd>\n<dt><strong>basis_type</strong><span class=\"classifier\">{None, \u2018tournier07\u2019, \u2018descoteaux07\u2019}, optional</span></dt><dd><p><code class=\"docutils literal notranslate\"><span class=\"pre\">None</span></code> for the default DIPY basis,\n<code class=\"docutils literal notranslate\"><span class=\"pre\">tournier07</span></code> for the Tournier 2007 [R35636a4a5d66-2]_[R35636a4a5d66-3]_ basis,\n<code class=\"docutils literal notranslate\"><span class=\"pre\">descoteaux07</span></code> for the Descoteaux 2007 <a class=\"reference internal\" href=\"#r35636a4a5d66-1\" id=\"id119\">[1]</a> basis,\n(<code class=\"docutils literal notranslate\"><span class=\"pre\">None</span></code> defaults to <code class=\"docutils literal notranslate\"><span class=\"pre\">descoteaux07</span></code>).</p>\n</dd>\n<dt><strong>full_basis: bool, optional</strong></dt><dd><p>True for using a SH basis containing even and odd order SH functions.\nFalse for using a SH basis consisting only of even order SH functions.</p>\n</dd>\n<dt><strong>legacy: bool, optional</strong></dt><dd><p>True to use a legacy basis definition for backward compatibility\nwith previous <code class=\"docutils literal notranslate\"><span class=\"pre\">tournier07</span></code> and <code class=\"docutils literal notranslate\"><span class=\"pre\">descoteaux07</span></code> implementations.</p>\n</dd>\n<dt><strong>smooth</strong><span class=\"classifier\">float, optional</span></dt><dd><p>Lambda-regularization in the SH fit.</p>\n</dd>\n</dl>\n</dd>\n<dt class=\"field-even\">Returns</dt>\n<dd class=\"field-even\"><dl class=\"simple\">\n<dt><strong>sh</strong><span class=\"classifier\">ndarray</span></dt><dd><p>SH coefficients representing the input function.</p>\n</dd>\n</dl>\n</dd>\n</dl>\n<p class=\"rubric\">References</p>\n<dl class=\"citation\">\n<dt class=\"label\" id=\"r35636a4a5d66-1\"><span class=\"brackets\"><a class=\"fn-backref\" href=\"#id119\">1</a></span></dt>\n<dd><p>Descoteaux, M., Angelino, E., Fitzgibbons, S. and Deriche, R.\nRegularized, Fast, and Robust Analytical Q-ball Imaging.\nMagn. Reson. Med. 2007;58:497-510.</p>\n</dd>\n<dt class=\"label\" id=\"r35636a4a5d66-2\"><span class=\"brackets\">2</span></dt>\n<dd><p>Tournier J.D., Calamante F. and Connelly A. Robust determination\nof the fibre orientation distribution in diffusion MRI:\nNon-negativity constrained super-resolved spherical deconvolution.\nNeuroImage. 2007;35(4):1459-1472.</p>\n</dd>\n<dt class=\"label\" id=\"r35636a4a5d66-3\"><span class=\"brackets\">3</span></dt>\n<dd><p>Tournier J-D, Smith R, Raffelt D, Tabbara R, Dhollander T,\nPietsch M, et al. MRtrix3: A fast, flexible and open software\nframework for medical image processing and visualisation.\nNeuroImage. 2019 Nov 15;202:116-137.</p>\n</dd>\n</dl>\n</dd></dl>\n\n</section>\n<section id=\"sh-to-sf\">\n<h3>sh_to_sf<a class=\"headerlink\" href=\"#sh-to-sf\" title=\"Permalink to this headline\">\u00b6</a></h3>\n<dl class=\"py function\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.sh_to_sf\">\n<span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.histo_resdnn.</span></span><span class=\"sig-name descname\"><span class=\"pre\">sh_to_sf</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">sh</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">sphere</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">sh_order</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">4</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">basis_type</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">full_basis</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">legacy</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">True</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.sh_to_sf\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Spherical harmonics (SH) to spherical function (SF).</p>\n<dl class=\"field-list simple\">\n<dt class=\"field-odd\">Parameters</dt>\n<dd class=\"field-odd\"><dl class=\"simple\">\n<dt><strong>sh</strong><span class=\"classifier\">ndarray</span></dt><dd><p>SH coefficients representing a spherical function.</p>\n</dd>\n<dt><strong>sphere</strong><span class=\"classifier\">Sphere</span></dt><dd><p>The points on which to sample the spherical function.</p>\n</dd>\n<dt><strong>sh_order</strong><span class=\"classifier\">int, optional</span></dt><dd><p>Maximum SH order in the SH fit.  For <code class=\"docutils literal notranslate\"><span class=\"pre\">sh_order</span></code>, there will be\n<code class=\"docutils literal notranslate\"><span class=\"pre\">(sh_order</span> <span class=\"pre\">+</span> <span class=\"pre\">1)</span> <span class=\"pre\">*</span> <span class=\"pre\">(sh_order</span> <span class=\"pre\">+</span> <span class=\"pre\">2)</span> <span class=\"pre\">/</span> <span class=\"pre\">2</span></code> SH coefficients for a symmetric\nbasis and <code class=\"docutils literal notranslate\"><span class=\"pre\">(sh_order</span> <span class=\"pre\">+</span> <span class=\"pre\">1)</span> <span class=\"pre\">*</span> <span class=\"pre\">(sh_order</span> <span class=\"pre\">+</span> <span class=\"pre\">1)</span></code> coefficients for a full\nSH basis.</p>\n</dd>\n<dt><strong>basis_type</strong><span class=\"classifier\">{None, \u2018tournier07\u2019, \u2018descoteaux07\u2019}, optional</span></dt><dd><p><code class=\"docutils literal notranslate\"><span class=\"pre\">None</span></code> for the default DIPY basis,\n<code class=\"docutils literal notranslate\"><span class=\"pre\">tournier07</span></code> for the Tournier 2007 [R30944dc1667c-2]_[R30944dc1667c-3]_ basis,\n<code class=\"docutils literal notranslate\"><span class=\"pre\">descoteaux07</span></code> for the Descoteaux 2007 <a class=\"reference internal\" href=\"#r30944dc1667c-1\" id=\"id123\">[1]</a> basis,\n(<code class=\"docutils literal notranslate\"><span class=\"pre\">None</span></code> defaults to <code class=\"docutils literal notranslate\"><span class=\"pre\">descoteaux07</span></code>).</p>\n</dd>\n<dt><strong>full_basis: bool, optional</strong></dt><dd><p>True to use a SH basis containing even and odd order SH functions.\nElse, use a SH basis consisting only of even order SH functions.</p>\n</dd>\n<dt><strong>legacy: bool, optional</strong></dt><dd><p>True to use a legacy basis definition for backward compatibility\nwith previous <code class=\"docutils literal notranslate\"><span class=\"pre\">tournier07</span></code> and <code class=\"docutils literal notranslate\"><span class=\"pre\">descoteaux07</span></code> implementations.</p>\n</dd>\n</dl>\n</dd>\n<dt class=\"field-even\">Returns</dt>\n<dd class=\"field-even\"><dl class=\"simple\">\n<dt><strong>sf</strong><span class=\"classifier\">ndarray</span></dt><dd><p>Spherical function values on the <code class=\"docutils literal notranslate\"><span class=\"pre\">sphere</span></code>.</p>\n</dd>\n</dl>\n</dd>\n</dl>\n<p class=\"rubric\">References</p>\n<dl class=\"citation\">\n<dt class=\"label\" id=\"r30944dc1667c-1\"><span class=\"brackets\"><a class=\"fn-backref\" href=\"#id123\">1</a></span></dt>\n<dd><p>Descoteaux, M., Angelino, E., Fitzgibbons, S. and Deriche, R.\nRegularized, Fast, and Robust Analytical Q-ball Imaging.\nMagn. Reson. Med. 2007;58:497-510.</p>\n</dd>\n<dt class=\"label\" id=\"r30944dc1667c-2\"><span class=\"brackets\">2</span></dt>\n<dd><p>Tournier J.D., Calamante F. and Connelly A. Robust determination\nof the fibre orientation distribution in diffusion MRI:\nNon-negativity constrained super-resolved spherical deconvolution.\nNeuroImage. 2007;35(4):1459-1472.</p>\n</dd>\n<dt class=\"label\" id=\"r30944dc1667c-3\"><span class=\"brackets\">3</span></dt>\n<dd><p>Tournier J-D, Smith R, Raffelt D, Tabbara R, Dhollander T,\nPietsch M, et al. MRtrix3: A fast, flexible and open software\nframework for medical image processing and visualisation.\nNeuroImage. 2019 Nov 15;202:116-137.</p>\n</dd>\n</dl>\n</dd></dl>\n\n</section>\n<section id=\"sph-harm-ind-list\">\n<h3>sph_harm_ind_list<a class=\"headerlink\" href=\"#sph-harm-ind-list\" title=\"Permalink to this headline\">\u00b6</a></h3>\n<dl class=\"py function\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.sph_harm_ind_list\">\n<span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.histo_resdnn.</span></span><span class=\"sig-name descname\"><span class=\"pre\">sph_harm_ind_list</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">sh_order</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">full_basis</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.sph_harm_ind_list\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Returns the degree (<code class=\"docutils literal notranslate\"><span class=\"pre\">m</span></code>) and order (<code class=\"docutils literal notranslate\"><span class=\"pre\">n</span></code>) of all the symmetric spherical\nharmonics of degree less then or equal to <code class=\"docutils literal notranslate\"><span class=\"pre\">sh_order</span></code>. The results,\n<code class=\"docutils literal notranslate\"><span class=\"pre\">m_list</span></code> and <code class=\"docutils literal notranslate\"><span class=\"pre\">n_list</span></code> are kx1 arrays, where k depends on <code class=\"docutils literal notranslate\"><span class=\"pre\">sh_order</span></code>.\nThey can be passed to <code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">real_sh_descoteaux_from_index()</span></code> and\n:func:<code class=\"docutils literal notranslate\"><span class=\"pre\">real_sh_tournier_from_index</span></code>.</p>\n<dl class=\"field-list simple\">\n<dt class=\"field-odd\">Parameters</dt>\n<dd class=\"field-odd\"><dl class=\"simple\">\n<dt><strong>sh_order</strong><span class=\"classifier\">int</span></dt><dd><p>even int &gt; 0, max order to return</p>\n</dd>\n<dt><strong>full_basis: bool, optional</strong></dt><dd><p>True for SH basis with even and odd order terms</p>\n</dd>\n</dl>\n</dd>\n<dt class=\"field-even\">Returns</dt>\n<dd class=\"field-even\"><dl class=\"simple\">\n<dt><strong>m_list</strong><span class=\"classifier\">array</span></dt><dd><p>degrees of even spherical harmonics</p>\n</dd>\n<dt><strong>n_list</strong><span class=\"classifier\">array</span></dt><dd><p>orders of even spherical harmonics</p>\n</dd>\n</dl>\n</dd>\n</dl>\n<div class=\"admonition seealso\">\n<p class=\"admonition-title\">See also</p>\n<dl class=\"simple\">\n<dt><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">shm.real_sh_descoteaux_from_index</span></code>, <code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">shm.real_sh_tournier_from_index</span></code></dt><dd></dd>\n</dl>\n</div>\n</dd></dl>\n\n</section>\n<section id=\"unique-bvals-magnitude\">\n<h3>unique_bvals_magnitude<a class=\"headerlink\" href=\"#unique-bvals-magnitude\" title=\"Permalink to this headline\">\u00b6</a></h3>\n<dl class=\"py function\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.unique_bvals_magnitude\">\n<span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.histo_resdnn.</span></span><span class=\"sig-name descname\"><span class=\"pre\">unique_bvals_magnitude</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">bvals</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">bmag</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">rbvals</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.unique_bvals_magnitude\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>This function gives the unique rounded b-values of the data</p>\n<dl class=\"field-list simple\">\n<dt class=\"field-odd\">Parameters</dt>\n<dd class=\"field-odd\"><dl class=\"simple\">\n<dt><strong>bvals</strong><span class=\"classifier\">ndarray</span></dt><dd><p>Array containing the b-values</p>\n</dd>\n<dt><strong>bmag</strong><span class=\"classifier\">int</span></dt><dd><p>The order of magnitude that the bvalues have to differ to be\nconsidered an unique b-value. B-values are also rounded up to\nthis order of magnitude. Default: derive this value from the\nmaximal b-value provided: <span class=\"math notranslate nohighlight\">\\(bmag=log_{10}(max(bvals)) - 1\\)</span>.</p>\n</dd>\n<dt><strong>rbvals</strong><span class=\"classifier\">bool, optional</span></dt><dd><p>If True function also returns all individual rounded b-values.\nDefault: False</p>\n</dd>\n</dl>\n</dd>\n<dt class=\"field-even\">Returns</dt>\n<dd class=\"field-even\"><dl class=\"simple\">\n<dt><strong>ubvals</strong><span class=\"classifier\">ndarray</span></dt><dd><p>Array containing the rounded unique b-values</p>\n</dd>\n</dl>\n</dd>\n</dl>\n</dd></dl>\n\n</section>\n<section id=\"multiplelayerpercepton\">\n<h3><a class=\"reference internal\" href=\"#dipy.nn.model.MultipleLayerPercepton\" title=\"dipy.nn.model.MultipleLayerPercepton\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">MultipleLayerPercepton</span></code></a><a class=\"headerlink\" href=\"#multiplelayerpercepton\" title=\"Permalink to this headline\">\u00b6</a></h3>\n<dl class=\"py class\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.MultipleLayerPercepton\">\n<em class=\"property\"><span class=\"pre\">class</span><span class=\"w\"> </span></em><span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.model.</span></span><span class=\"sig-name descname\"><span class=\"pre\">MultipleLayerPercepton</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">input_shape</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">(28,</span> <span class=\"pre\">28)</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">num_hidden</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">[128]</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">act_hidden</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'relu'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">dropout</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">0.2</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">num_out</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">10</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">act_out</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'softmax'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">loss</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'sparse_categorical_crossentropy'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">optimizer</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'adam'</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.model.MultipleLayerPercepton\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Bases: <a class=\"reference external\" href=\"https://docs.python.org/3/library/functions.html#object\" title=\"(in Python v3.10)\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">object</span></code></a></p>\n<p class=\"rubric\">Methods</p>\n<table class=\"longtable docutils align-default\">\n<colgroup>\n<col style=\"width: 10%\" />\n<col style=\"width: 90%\" />\n</colgroup>\n<tbody>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.model.MultipleLayerPercepton.evaluate\" title=\"dipy.nn.model.MultipleLayerPercepton.evaluate\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">evaluate</span></code></a>(x_test,\u00a0y_test[,\u00a0verbose])</p></td>\n<td><p>Evaluate the model on test dataset.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.model.MultipleLayerPercepton.fit\" title=\"dipy.nn.model.MultipleLayerPercepton.fit\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">fit</span></code></a>(x_train,\u00a0y_train[,\u00a0epochs])</p></td>\n<td><p>Train the model on train dataset.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.model.MultipleLayerPercepton.predict\" title=\"dipy.nn.model.MultipleLayerPercepton.predict\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">predict</span></code></a>(x_test)</p></td>\n<td><p>Predict the output from input samples.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.model.MultipleLayerPercepton.summary\" title=\"dipy.nn.model.MultipleLayerPercepton.summary\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">summary</span></code></a>()</p></td>\n<td><p>Get the summary of the model.</p></td>\n</tr>\n</tbody>\n</table>\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.MultipleLayerPercepton.__init__\">\n<span class=\"sig-name descname\"><span class=\"pre\">__init__</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">input_shape</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">(28,</span> <span class=\"pre\">28)</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">num_hidden</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">[128]</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">act_hidden</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'relu'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">dropout</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">0.2</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">num_out</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">10</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">act_out</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'softmax'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">loss</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'sparse_categorical_crossentropy'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">optimizer</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'adam'</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.model.MultipleLayerPercepton.__init__\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Multiple Layer Perceptron with Dropout.</p>\n<dl class=\"field-list simple\">\n<dt class=\"field-odd\">Parameters</dt>\n<dd class=\"field-odd\"><dl class=\"simple\">\n<dt><strong>input_shape</strong><span class=\"classifier\">tuple</span></dt><dd><p>Shape of data to be trained</p>\n</dd>\n<dt><strong>num_hidden</strong><span class=\"classifier\">list</span></dt><dd><p>List of number of nodes in hidden layers</p>\n</dd>\n<dt><strong>act_hidden</strong><span class=\"classifier\">string</span></dt><dd><p>Activation function used in hidden layer</p>\n</dd>\n<dt><strong>dropout</strong><span class=\"classifier\">float</span></dt><dd><p>Dropout ratio</p>\n</dd>\n<dt><strong>num_out</strong><span class=\"classifier\">10</span></dt><dd><p>Number of nodes in output layer</p>\n</dd>\n<dt><strong>act_out</strong><span class=\"classifier\">string</span></dt><dd><p>Activation function used in output layer</p>\n</dd>\n<dt><strong>optimizer</strong><span class=\"classifier\">string</span></dt><dd><p>Select optimizer. Default adam.</p>\n</dd>\n<dt><strong>loss</strong><span class=\"classifier\">string</span></dt><dd><p>Select loss function for measuring accuracy.\nDefault sparse_categorical_crossentropy.</p>\n</dd>\n</dl>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.MultipleLayerPercepton.evaluate\">\n<span class=\"sig-name descname\"><span class=\"pre\">evaluate</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">x_test</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">y_test</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">verbose</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">2</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.model.MultipleLayerPercepton.evaluate\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Evaluate the model on test dataset.</p>\n<p>The evaluate method will evaluate the model on a test\ndataset.</p>\n<dl class=\"field-list simple\">\n<dt class=\"field-odd\">Parameters</dt>\n<dd class=\"field-odd\"><dl class=\"simple\">\n<dt><strong>x_test</strong><span class=\"classifier\">ndarray</span></dt><dd><p>the x_test is the test dataset</p>\n</dd>\n<dt><strong>y_test</strong><span class=\"classifier\">ndarray shape=(BatchSize,)</span></dt><dd><p>the y_test is the labels of the test dataset</p>\n</dd>\n<dt><strong>verbose</strong><span class=\"classifier\">int (Default = 2)</span></dt><dd><p>By setting verbose 0, 1 or 2 you just say how do you want to\n\u2018see\u2019 the training progress for each epoch.</p>\n</dd>\n</dl>\n</dd>\n<dt class=\"field-even\">Returns</dt>\n<dd class=\"field-even\"><dl class=\"simple\">\n<dt><strong>evaluate</strong><span class=\"classifier\">List</span></dt><dd><p>return list of loss value and accuracy value on test dataset</p>\n</dd>\n</dl>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.MultipleLayerPercepton.fit\">\n<span class=\"sig-name descname\"><span class=\"pre\">fit</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">x_train</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">y_train</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">epochs</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">5</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.model.MultipleLayerPercepton.fit\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Train the model on train dataset.</p>\n<p>The fit method will train the model for a fixed\nnumber of epochs (iterations) on a dataset.</p>\n<dl class=\"field-list simple\">\n<dt class=\"field-odd\">Parameters</dt>\n<dd class=\"field-odd\"><dl class=\"simple\">\n<dt><strong>x_train</strong><span class=\"classifier\">ndarray</span></dt><dd><p>the x_train is the train dataset</p>\n</dd>\n<dt><strong>y_train</strong><span class=\"classifier\">ndarray shape=(BatchSize,)</span></dt><dd><p>the y_train is the labels of the train dataset</p>\n</dd>\n<dt><strong>epochs</strong><span class=\"classifier\">int (Default = 5)</span></dt><dd><p>the number of epochs</p>\n</dd>\n</dl>\n</dd>\n<dt class=\"field-even\">Returns</dt>\n<dd class=\"field-even\"><dl class=\"simple\">\n<dt><strong>hist</strong><span class=\"classifier\">object</span></dt><dd><p>A History object. Its History.history attribute is a record of\ntraining loss values and metrics values at successive epochs</p>\n</dd>\n</dl>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.MultipleLayerPercepton.predict\">\n<span class=\"sig-name descname\"><span class=\"pre\">predict</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">x_test</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.model.MultipleLayerPercepton.predict\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Predict the output from input samples.</p>\n<p>The predict method will generates output predictions\nfor the input samples.</p>\n<dl class=\"field-list simple\">\n<dt class=\"field-odd\">Parameters</dt>\n<dd class=\"field-odd\"><dl class=\"simple\">\n<dt><strong>x_train</strong><span class=\"classifier\">ndarray</span></dt><dd><p>the x_test is the test dataset or input samples</p>\n</dd>\n</dl>\n</dd>\n<dt class=\"field-even\">Returns</dt>\n<dd class=\"field-even\"><dl class=\"simple\">\n<dt><strong>predict</strong><span class=\"classifier\">ndarray shape(TestSize,OutputSize)</span></dt><dd><p>Numpy array(s) of predictions.</p>\n</dd>\n</dl>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.MultipleLayerPercepton.summary\">\n<span class=\"sig-name descname\"><span class=\"pre\">summary</span></span><span class=\"sig-paren\">(</span><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.model.MultipleLayerPercepton.summary\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Get the summary of the model.</p>\n<p>The summary is textual and includes information about:\nThe layers and their order in the model.\nThe output shape of each layer.</p>\n<dl class=\"field-list simple\">\n<dt class=\"field-odd\">Returns</dt>\n<dd class=\"field-odd\"><dl class=\"simple\">\n<dt><strong>summary</strong><span class=\"classifier\">NoneType</span></dt><dd><p>the summary of the model</p>\n</dd>\n</dl>\n</dd>\n</dl>\n</dd></dl>\n\n</dd></dl>\n\n</section>\n<section id=\"singlelayerperceptron\">\n<h3><a class=\"reference internal\" href=\"#dipy.nn.model.SingleLayerPerceptron\" title=\"dipy.nn.model.SingleLayerPerceptron\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">SingleLayerPerceptron</span></code></a><a class=\"headerlink\" href=\"#singlelayerperceptron\" title=\"Permalink to this headline\">\u00b6</a></h3>\n<dl class=\"py class\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.SingleLayerPerceptron\">\n<em class=\"property\"><span class=\"pre\">class</span><span class=\"w\"> </span></em><span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.model.</span></span><span class=\"sig-name descname\"><span class=\"pre\">SingleLayerPerceptron</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">input_shape</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">(28,</span> <span class=\"pre\">28)</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">num_hidden</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">128</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">act_hidden</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'relu'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">dropout</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">0.2</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">num_out</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">10</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">act_out</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'softmax'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">optimizer</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'adam'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">loss</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'sparse_categorical_crossentropy'</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.model.SingleLayerPerceptron\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Bases: <a class=\"reference external\" href=\"https://docs.python.org/3/library/functions.html#object\" title=\"(in Python v3.10)\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">object</span></code></a></p>\n<p class=\"rubric\">Methods</p>\n<table class=\"longtable docutils align-default\">\n<colgroup>\n<col style=\"width: 10%\" />\n<col style=\"width: 90%\" />\n</colgroup>\n<tbody>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.model.SingleLayerPerceptron.evaluate\" title=\"dipy.nn.model.SingleLayerPerceptron.evaluate\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">evaluate</span></code></a>(x_test,\u00a0y_test[,\u00a0verbose])</p></td>\n<td><p>Evaluate the model on test dataset.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.model.SingleLayerPerceptron.fit\" title=\"dipy.nn.model.SingleLayerPerceptron.fit\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">fit</span></code></a>(x_train,\u00a0y_train[,\u00a0epochs])</p></td>\n<td><p>Train the model on train dataset.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.model.SingleLayerPerceptron.predict\" title=\"dipy.nn.model.SingleLayerPerceptron.predict\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">predict</span></code></a>(x_test)</p></td>\n<td><p>Predict the output from input samples.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.model.SingleLayerPerceptron.summary\" title=\"dipy.nn.model.SingleLayerPerceptron.summary\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">summary</span></code></a>()</p></td>\n<td><p>Get the summary of the model.</p></td>\n</tr>\n</tbody>\n</table>\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.SingleLayerPerceptron.__init__\">\n<span class=\"sig-name descname\"><span class=\"pre\">__init__</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">input_shape</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">(28,</span> <span class=\"pre\">28)</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">num_hidden</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">128</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">act_hidden</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'relu'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">dropout</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">0.2</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">num_out</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">10</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">act_out</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'softmax'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">optimizer</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'adam'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">loss</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'sparse_categorical_crossentropy'</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.model.SingleLayerPerceptron.__init__\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Single Layer Perceptron with Dropout.</p>\n<dl class=\"field-list simple\">\n<dt class=\"field-odd\">Parameters</dt>\n<dd class=\"field-odd\"><dl class=\"simple\">\n<dt><strong>input_shape</strong><span class=\"classifier\">tuple</span></dt><dd><p>Shape of data to be trained</p>\n</dd>\n<dt><strong>num_hidden</strong><span class=\"classifier\">int</span></dt><dd><p>Number of nodes in hidden layer</p>\n</dd>\n<dt><strong>act_hidden</strong><span class=\"classifier\">string</span></dt><dd><p>Activation function used in hidden layer</p>\n</dd>\n<dt><strong>dropout</strong><span class=\"classifier\">float</span></dt><dd><p>Dropout ratio</p>\n</dd>\n<dt><strong>num_out</strong><span class=\"classifier\">10</span></dt><dd><p>Number of nodes in output layer</p>\n</dd>\n<dt><strong>act_out</strong><span class=\"classifier\">string</span></dt><dd><p>Activation function used in output layer</p>\n</dd>\n<dt><strong>optimizer</strong><span class=\"classifier\">string</span></dt><dd><p>Select optimizer. Default adam.</p>\n</dd>\n<dt><strong>loss</strong><span class=\"classifier\">string</span></dt><dd><p>Select loss function for measuring accuracy.\nDefault sparse_categorical_crossentropy.</p>\n</dd>\n</dl>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.SingleLayerPerceptron.evaluate\">\n<span class=\"sig-name descname\"><span class=\"pre\">evaluate</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">x_test</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">y_test</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">verbose</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">2</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.model.SingleLayerPerceptron.evaluate\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Evaluate the model on test dataset.</p>\n<p>The evaluate method will evaluate the model on a test\ndataset.</p>\n<dl class=\"field-list simple\">\n<dt class=\"field-odd\">Parameters</dt>\n<dd class=\"field-odd\"><dl class=\"simple\">\n<dt><strong>x_test</strong><span class=\"classifier\">ndarray</span></dt><dd><p>the x_test is the test dataset</p>\n</dd>\n<dt><strong>y_test</strong><span class=\"classifier\">ndarray shape=(BatchSize,)</span></dt><dd><p>the y_test is the labels of the test dataset</p>\n</dd>\n<dt><strong>verbose</strong><span class=\"classifier\">int (Default = 2)</span></dt><dd><p>By setting verbose 0, 1 or 2 you just say how do you want to\n\u2018see\u2019 the training progress for each epoch.</p>\n</dd>\n</dl>\n</dd>\n<dt class=\"field-even\">Returns</dt>\n<dd class=\"field-even\"><dl class=\"simple\">\n<dt><strong>evaluate</strong><span class=\"classifier\">List</span></dt><dd><p>return list of loss value and accuracy value on test dataset</p>\n</dd>\n</dl>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.SingleLayerPerceptron.fit\">\n<span class=\"sig-name descname\"><span class=\"pre\">fit</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">x_train</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">y_train</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">epochs</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">5</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.model.SingleLayerPerceptron.fit\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Train the model on train dataset.</p>\n<p>The fit method will train the model for a fixed\nnumber of epochs (iterations) on a dataset.</p>\n<dl class=\"field-list simple\">\n<dt class=\"field-odd\">Parameters</dt>\n<dd class=\"field-odd\"><dl class=\"simple\">\n<dt><strong>x_train</strong><span class=\"classifier\">ndarray</span></dt><dd><p>the x_train is the train dataset</p>\n</dd>\n<dt><strong>y_train</strong><span class=\"classifier\">ndarray shape=(BatchSize,)</span></dt><dd><p>the y_train is the labels of the train dataset</p>\n</dd>\n<dt><strong>epochs</strong><span class=\"classifier\">int (Default = 5)</span></dt><dd><p>the number of epochs</p>\n</dd>\n</dl>\n</dd>\n<dt class=\"field-even\">Returns</dt>\n<dd class=\"field-even\"><dl class=\"simple\">\n<dt><strong>hist</strong><span class=\"classifier\">object</span></dt><dd><p>A History object. Its History.history attribute is a record of\ntraining loss values and metrics values at successive epochs</p>\n</dd>\n</dl>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.SingleLayerPerceptron.predict\">\n<span class=\"sig-name descname\"><span class=\"pre\">predict</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">x_test</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.model.SingleLayerPerceptron.predict\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Predict the output from input samples.</p>\n<p>The predict method will generates output predictions\nfor the input samples.</p>\n<dl class=\"field-list simple\">\n<dt class=\"field-odd\">Parameters</dt>\n<dd class=\"field-odd\"><dl class=\"simple\">\n<dt><strong>x_train</strong><span class=\"classifier\">ndarray</span></dt><dd><p>the x_test is the test dataset or input samples</p>\n</dd>\n</dl>\n</dd>\n<dt class=\"field-even\">Returns</dt>\n<dd class=\"field-even\"><dl class=\"simple\">\n<dt><strong>predict</strong><span class=\"classifier\">ndarray shape(TestSize,OutputSize)</span></dt><dd><p>Numpy array(s) of predictions.</p>\n</dd>\n</dl>\n</dd>\n</dl>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.SingleLayerPerceptron.summary\">\n<span class=\"sig-name descname\"><span class=\"pre\">summary</span></span><span class=\"sig-paren\">(</span><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.model.SingleLayerPerceptron.summary\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Get the summary of the model.</p>\n<p>The summary is textual and includes information about:\nThe layers and their order in the model.\nThe output shape of each layer.</p>\n<dl class=\"field-list simple\">\n<dt class=\"field-odd\">Returns</dt>\n<dd class=\"field-odd\"><dl class=\"simple\">\n<dt><strong>summary</strong><span class=\"classifier\">NoneType</span></dt><dd><p>the summary of the model</p>\n</dd>\n</dl>\n</dd>\n</dl>\n</dd></dl>\n\n</dd></dl>\n\n</section>\n<section id=\"id127\">\n<h3><a class=\"reference internal\" href=\"#dipy.nn.model.Version\" title=\"dipy.nn.model.Version\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Version</span></code></a><a class=\"headerlink\" href=\"#id127\" title=\"Permalink to this headline\">\u00b6</a></h3>\n<dl class=\"py class\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.Version\">\n<em class=\"property\"><span class=\"pre\">class</span><span class=\"w\"> </span></em><span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.model.</span></span><span class=\"sig-name descname\"><span class=\"pre\">Version</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">version</span></span><span class=\"p\"><span class=\"pre\">:</span></span><span class=\"w\"> </span><span class=\"n\"><a class=\"reference external\" href=\"https://docs.python.org/3/library/stdtypes.html#str\" title=\"(in Python v3.10)\"><span class=\"pre\">str</span></a></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.model.Version\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Bases: <code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">packaging.version._BaseVersion</span></code></p>\n<dl class=\"field-list simple\">\n<dt class=\"field-odd\">Attributes</dt>\n<dd class=\"field-odd\"><dl class=\"simple\">\n<dt><strong>base_version</strong></dt><dd></dd>\n<dt><strong>dev</strong></dt><dd></dd>\n<dt><strong>epoch</strong></dt><dd></dd>\n<dt><strong>is_devrelease</strong></dt><dd></dd>\n<dt><strong>is_postrelease</strong></dt><dd></dd>\n<dt><strong>is_prerelease</strong></dt><dd></dd>\n<dt><strong>local</strong></dt><dd></dd>\n<dt><strong>major</strong></dt><dd></dd>\n<dt><strong>micro</strong></dt><dd></dd>\n<dt><strong>minor</strong></dt><dd></dd>\n<dt><strong>post</strong></dt><dd></dd>\n<dt><strong>pre</strong></dt><dd></dd>\n<dt><strong>public</strong></dt><dd></dd>\n<dt><strong>release</strong></dt><dd></dd>\n</dl>\n</dd>\n</dl>\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.Version.__init__\">\n<span class=\"sig-name descname\"><span class=\"pre\">__init__</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">version</span></span><span class=\"p\"><span class=\"pre\">:</span></span><span class=\"w\"> </span><span class=\"n\"><a class=\"reference external\" href=\"https://docs.python.org/3/library/stdtypes.html#str\" title=\"(in Python v3.10)\"><span class=\"pre\">str</span></a></span></em><span class=\"sig-paren\">)</span> <span class=\"sig-return\"><span class=\"sig-return-icon\">&#x2192;</span> <span class=\"sig-return-typehint\"><a class=\"reference external\" href=\"https://docs.python.org/3/library/constants.html#None\" title=\"(in Python v3.10)\"><span class=\"pre\">None</span></a></span></span><a class=\"headerlink\" href=\"#dipy.nn.model.Version.__init__\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py property\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.Version.base_version\">\n<em class=\"property\"><span class=\"pre\">property</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">base_version</span></span><em class=\"property\"><span class=\"p\"><span class=\"pre\">:</span></span><span class=\"w\"> </span><a class=\"reference external\" href=\"https://docs.python.org/3/library/stdtypes.html#str\" title=\"(in Python v3.10)\"><span class=\"pre\">str</span></a></em><a class=\"headerlink\" href=\"#dipy.nn.model.Version.base_version\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py property\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.Version.dev\">\n<em class=\"property\"><span class=\"pre\">property</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">dev</span></span><em class=\"property\"><span class=\"p\"><span class=\"pre\">:</span></span><span class=\"w\"> </span><span class=\"pre\">Optional</span><span class=\"p\"><span class=\"pre\">[</span></span><a class=\"reference external\" href=\"https://docs.python.org/3/library/functions.html#int\" title=\"(in Python v3.10)\"><span class=\"pre\">int</span></a><span class=\"p\"><span class=\"pre\">]</span></span></em><a class=\"headerlink\" href=\"#dipy.nn.model.Version.dev\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py property\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.Version.epoch\">\n<em class=\"property\"><span class=\"pre\">property</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">epoch</span></span><em class=\"property\"><span class=\"p\"><span class=\"pre\">:</span></span><span class=\"w\"> </span><a class=\"reference external\" href=\"https://docs.python.org/3/library/functions.html#int\" title=\"(in Python v3.10)\"><span class=\"pre\">int</span></a></em><a class=\"headerlink\" href=\"#dipy.nn.model.Version.epoch\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py property\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.Version.is_devrelease\">\n<em class=\"property\"><span class=\"pre\">property</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">is_devrelease</span></span><em class=\"property\"><span class=\"p\"><span class=\"pre\">:</span></span><span class=\"w\"> </span><a class=\"reference external\" href=\"https://docs.python.org/3/library/functions.html#bool\" title=\"(in Python v3.10)\"><span class=\"pre\">bool</span></a></em><a class=\"headerlink\" href=\"#dipy.nn.model.Version.is_devrelease\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py property\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.Version.is_postrelease\">\n<em class=\"property\"><span class=\"pre\">property</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">is_postrelease</span></span><em class=\"property\"><span class=\"p\"><span class=\"pre\">:</span></span><span class=\"w\"> </span><a class=\"reference external\" href=\"https://docs.python.org/3/library/functions.html#bool\" title=\"(in Python v3.10)\"><span class=\"pre\">bool</span></a></em><a class=\"headerlink\" href=\"#dipy.nn.model.Version.is_postrelease\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py property\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.Version.is_prerelease\">\n<em class=\"property\"><span class=\"pre\">property</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">is_prerelease</span></span><em class=\"property\"><span class=\"p\"><span class=\"pre\">:</span></span><span class=\"w\"> </span><a class=\"reference external\" href=\"https://docs.python.org/3/library/functions.html#bool\" title=\"(in Python v3.10)\"><span class=\"pre\">bool</span></a></em><a class=\"headerlink\" href=\"#dipy.nn.model.Version.is_prerelease\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py property\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.Version.local\">\n<em class=\"property\"><span class=\"pre\">property</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">local</span></span><em class=\"property\"><span class=\"p\"><span class=\"pre\">:</span></span><span class=\"w\"> </span><span class=\"pre\">Optional</span><span class=\"p\"><span class=\"pre\">[</span></span><a class=\"reference external\" href=\"https://docs.python.org/3/library/stdtypes.html#str\" title=\"(in Python v3.10)\"><span class=\"pre\">str</span></a><span class=\"p\"><span class=\"pre\">]</span></span></em><a class=\"headerlink\" href=\"#dipy.nn.model.Version.local\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py property\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.Version.major\">\n<em class=\"property\"><span class=\"pre\">property</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">major</span></span><em class=\"property\"><span class=\"p\"><span class=\"pre\">:</span></span><span class=\"w\"> </span><a class=\"reference external\" href=\"https://docs.python.org/3/library/functions.html#int\" title=\"(in Python v3.10)\"><span class=\"pre\">int</span></a></em><a class=\"headerlink\" href=\"#dipy.nn.model.Version.major\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py property\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.Version.micro\">\n<em class=\"property\"><span class=\"pre\">property</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">micro</span></span><em class=\"property\"><span class=\"p\"><span class=\"pre\">:</span></span><span class=\"w\"> </span><a class=\"reference external\" href=\"https://docs.python.org/3/library/functions.html#int\" title=\"(in Python v3.10)\"><span class=\"pre\">int</span></a></em><a class=\"headerlink\" href=\"#dipy.nn.model.Version.micro\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py property\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.Version.minor\">\n<em class=\"property\"><span class=\"pre\">property</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">minor</span></span><em class=\"property\"><span class=\"p\"><span class=\"pre\">:</span></span><span class=\"w\"> </span><a class=\"reference external\" href=\"https://docs.python.org/3/library/functions.html#int\" title=\"(in Python v3.10)\"><span class=\"pre\">int</span></a></em><a class=\"headerlink\" href=\"#dipy.nn.model.Version.minor\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py property\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.Version.post\">\n<em class=\"property\"><span class=\"pre\">property</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">post</span></span><em class=\"property\"><span class=\"p\"><span class=\"pre\">:</span></span><span class=\"w\"> </span><span class=\"pre\">Optional</span><span class=\"p\"><span class=\"pre\">[</span></span><a class=\"reference external\" href=\"https://docs.python.org/3/library/functions.html#int\" title=\"(in Python v3.10)\"><span class=\"pre\">int</span></a><span class=\"p\"><span class=\"pre\">]</span></span></em><a class=\"headerlink\" href=\"#dipy.nn.model.Version.post\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py property\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.Version.pre\">\n<em class=\"property\"><span class=\"pre\">property</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">pre</span></span><em class=\"property\"><span class=\"p\"><span class=\"pre\">:</span></span><span class=\"w\"> </span><span class=\"pre\">Optional</span><span class=\"p\"><span class=\"pre\">[</span></span><span class=\"pre\">Tuple</span><span class=\"p\"><span class=\"pre\">[</span></span><a class=\"reference external\" href=\"https://docs.python.org/3/library/stdtypes.html#str\" title=\"(in Python v3.10)\"><span class=\"pre\">str</span></a><span class=\"p\"><span class=\"pre\">,</span></span><span class=\"w\"> </span><a class=\"reference external\" href=\"https://docs.python.org/3/library/functions.html#int\" title=\"(in Python v3.10)\"><span class=\"pre\">int</span></a><span class=\"p\"><span class=\"pre\">]</span></span><span class=\"p\"><span class=\"pre\">]</span></span></em><a class=\"headerlink\" href=\"#dipy.nn.model.Version.pre\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py property\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.Version.public\">\n<em class=\"property\"><span class=\"pre\">property</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">public</span></span><em class=\"property\"><span class=\"p\"><span class=\"pre\">:</span></span><span class=\"w\"> </span><a class=\"reference external\" href=\"https://docs.python.org/3/library/stdtypes.html#str\" title=\"(in Python v3.10)\"><span class=\"pre\">str</span></a></em><a class=\"headerlink\" href=\"#dipy.nn.model.Version.public\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py property\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.Version.release\">\n<em class=\"property\"><span class=\"pre\">property</span><span class=\"w\"> </span></em><span class=\"sig-name descname\"><span class=\"pre\">release</span></span><em class=\"property\"><span class=\"p\"><span class=\"pre\">:</span></span><span class=\"w\"> </span><span class=\"pre\">Tuple</span><span class=\"p\"><span class=\"pre\">[</span></span><a class=\"reference external\" href=\"https://docs.python.org/3/library/functions.html#int\" title=\"(in Python v3.10)\"><span class=\"pre\">int</span></a><span class=\"p\"><span class=\"pre\">,</span></span><span class=\"w\"> </span><span class=\"p\"><span class=\"pre\">...</span></span><span class=\"p\"><span class=\"pre\">]</span></span></em><a class=\"headerlink\" href=\"#dipy.nn.model.Version.release\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n</dd></dl>\n\n</section>\n<section id=\"id128\">\n<h3>optional_package<a class=\"headerlink\" href=\"#id128\" title=\"Permalink to this headline\">\u00b6</a></h3>\n<dl class=\"py function\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.optional_package\">\n<span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.model.</span></span><span class=\"sig-name descname\"><span class=\"pre\">optional_package</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">name</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">trip_msg</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.model.optional_package\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Return package-like thing and module setup for package <cite>name</cite></p>\n<dl class=\"field-list\">\n<dt class=\"field-odd\">Parameters</dt>\n<dd class=\"field-odd\"><dl class=\"simple\">\n<dt><strong>name</strong><span class=\"classifier\">str</span></dt><dd><p>package name</p>\n</dd>\n<dt><strong>trip_msg</strong><span class=\"classifier\">None or str</span></dt><dd><p>message to give when someone tries to use the return package, but we\ncould not import it, and have returned a TripWire object instead.\nDefault message if None.</p>\n</dd>\n</dl>\n</dd>\n<dt class=\"field-even\">Returns</dt>\n<dd class=\"field-even\"><dl>\n<dt><strong>pkg_like</strong><span class=\"classifier\">module or <code class=\"docutils literal notranslate\"><span class=\"pre\">TripWire</span></code> instance</span></dt><dd><p>If we can import the package, return it.  Otherwise return an object\nraising an error when accessed</p>\n</dd>\n<dt><strong>have_pkg</strong><span class=\"classifier\">bool</span></dt><dd><p>True if import for package was successful, false otherwise</p>\n</dd>\n<dt><strong>module_setup</strong><span class=\"classifier\">function</span></dt><dd><p>callable usually set as <code class=\"docutils literal notranslate\"><span class=\"pre\">setup_module</span></code> in calling namespace, to allow\nskipping tests.</p>\n</dd>\n</dl>\n</dd>\n</dl>\n<p class=\"rubric\">Examples</p>\n<p>Typical use would be something like this at the top of a module using an\noptional package:</p>\n<div class=\"doctest highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span> <span class=\"nn\">dipy.utils.optpkg</span> <span class=\"kn\">import</span> <span class=\"n\">optional_package</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">pkg</span><span class=\"p\">,</span> <span class=\"n\">have_pkg</span><span class=\"p\">,</span> <span class=\"n\">setup_module</span> <span class=\"o\">=</span> <span class=\"n\">optional_package</span><span class=\"p\">(</span><span class=\"s1\">&#39;not_a_package&#39;</span><span class=\"p\">)</span>\n</pre></div>\n</div>\n<p>Of course in this case the package doesn\u2019t exist, and so, in the module:</p>\n<div class=\"doctest highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">have_pkg</span>\n<span class=\"go\">False</span>\n</pre></div>\n</div>\n<p>and</p>\n<div class=\"doctest highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">pkg</span><span class=\"o\">.</span><span class=\"n\">some_function</span><span class=\"p\">()</span> \n<span class=\"gt\">Traceback (most recent call last):</span>\n    <span class=\"o\">...</span>\n<span class=\"gr\">TripWireError</span>: <span class=\"n\">We need package not_a_package for these functions, but</span>\n<span class=\"go\">``import not_a_package`` raised an ImportError</span>\n</pre></div>\n</div>\n<p>If the module does exist - we get the module</p>\n<div class=\"doctest highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">pkg</span><span class=\"p\">,</span> <span class=\"n\">_</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">=</span> <span class=\"n\">optional_package</span><span class=\"p\">(</span><span class=\"s1\">&#39;os&#39;</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"nb\">hasattr</span><span class=\"p\">(</span><span class=\"n\">pkg</span><span class=\"p\">,</span> <span class=\"s1\">&#39;path&#39;</span><span class=\"p\">)</span>\n<span class=\"go\">True</span>\n</pre></div>\n</div>\n<p>Or a submodule if that\u2019s what we asked for</p>\n<div class=\"doctest highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">subpkg</span><span class=\"p\">,</span> <span class=\"n\">_</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">=</span> <span class=\"n\">optional_package</span><span class=\"p\">(</span><span class=\"s1\">&#39;os.path&#39;</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"nb\">hasattr</span><span class=\"p\">(</span><span class=\"n\">subpkg</span><span class=\"p\">,</span> <span class=\"s1\">&#39;dirname&#39;</span><span class=\"p\">)</span>\n<span class=\"go\">True</span>\n</pre></div>\n</div>\n</dd></dl>\n\n</section>\n</section>\n</section>\n", "metatags": "<meta name=\"generator\" content=\"Docutils 0.17.1: http://docutils.sourceforge.net/\" />\n", "rellinks": [["genindex", "General Index", "I", "index"], ["py-modindex", "Python Module Index", "", "modules"], ["reference/dipy.reconst", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">reconst</span></code>", "N", "next"], ["reference/dipy.io", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">io</span></code>", "P", "previous"]], "sourcename": "reference/dipy.nn.rst.txt", "toc": "<ul>\n<li><a class=\"reference internal\" href=\"#\"><code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">nn</span></code></a><ul>\n<li><a class=\"reference internal\" href=\"#module-dipy.nn.histo_resdnn\">Module: <code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">nn.histo_resdnn</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#module-dipy.nn.model\">Module: <code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">nn.model</span></code></a><ul>\n<li><a class=\"reference internal\" href=\"#bench\">bench</a></li>\n<li><a class=\"reference internal\" href=\"#test\">test</a></li>\n<li><a class=\"reference internal\" href=\"#add\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Add</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#dense\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Dense</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#hemisphere\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">HemiSphere</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#historesdnn\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">HistoResDNN</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#model\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Model</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#version\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Version</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#input\">Input</a></li>\n<li><a class=\"reference internal\" href=\"#doctest-skip-parser\">doctest_skip_parser</a></li>\n<li><a class=\"reference internal\" href=\"#get-bval-indices\">get_bval_indices</a></li>\n<li><a class=\"reference internal\" href=\"#get-fnames\">get_fnames</a></li>\n<li><a class=\"reference internal\" href=\"#get-sphere\">get_sphere</a></li>\n<li><a class=\"reference internal\" href=\"#optional-package\">optional_package</a></li>\n<li><a class=\"reference internal\" href=\"#set-logger-level\">set_logger_level</a></li>\n<li><a class=\"reference internal\" href=\"#sf-to-sh\">sf_to_sh</a></li>\n<li><a class=\"reference internal\" href=\"#sh-to-sf\">sh_to_sf</a></li>\n<li><a class=\"reference internal\" href=\"#sph-harm-ind-list\">sph_harm_ind_list</a></li>\n<li><a class=\"reference internal\" href=\"#unique-bvals-magnitude\">unique_bvals_magnitude</a></li>\n<li><a class=\"reference internal\" href=\"#multiplelayerpercepton\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">MultipleLayerPercepton</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#singlelayerperceptron\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">SingleLayerPerceptron</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#id127\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Version</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#id128\">optional_package</a></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n", "display_toc": true, "page_source_suffix": ".rst", "current_page_name": "reference/dipy.nn", "sidebars": ["localtoc.html", "relations.html", "sourcelink.html", "searchbox.html"], "customsidebar": null, "favicon_url": null, "logo_url": null, "alabaster_version": "0.7.12"}